#! /usr/bin/env bash

#    snapback (short for "snapshot backups") manages backups on multiple drives
#
#    Copyright (C) 2018-2019, Human Rights Data Analysis Group (HRDAG)
#    https://hrdag.org
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

version=22			# has to match version= in configure.sh.sample

###############################################################################
## Our naming and coding conventions are documented at the top of libsnap.sh ##
###############################################################################

readonly libsnap_project=git@github.com:HRDAG/libsnap
#
# search for '####' in libsnap.sh to see coding-conventions and environment
source libsnap.sh ||
if which libsnap.sh > /dev/null
   then abort "libsnap.sh needs to end with 'true'"
   else echo "install libsnap.sh from $libsnap_project" >&2; exit 1
fi
#
# We use these constants from libsnap.sh (and change $our_name)
readonly tmp_dir our_path true false is_darwin max_call_stack_args
readonly warning_level2tput_args
# We used these functions from libsnap.sh
readonly -f is-set have-cmd need-cmds set-FS_type--from-path
readonly -f set-inode_size-data_block_size-dir_block_size--from-path
readonly -f set-FS_label--from-FS-device label-drive
readonly -f set-FS_device--from-FS-label set-device_KB--from-block-device
readonly -f set-FS_device--from-path set-mount_dir--from-FS-device
readonly -f set-mount_dir--from-FS-label  set-FS_label--from-mount_dir
readonly -f is-arg_1-in-arg_2 print-call-stack warn
readonly -f abort abort-function assert-not-option echoE echoEV Trace TraceV
readonly -f remember-tracing suspend-tracing restore-tracing
readonly -f print-or-egrep-Usage-then-exit abort-with-action-Usage log
readonly -f header set-absolute_path
readonly -f cd_  have-proc is-process-alive set-popped_word--from-list
readonly -f set-division confirm run-function


for dir in ~/etc /usr/local/etc /etc; do [[ -d $dir/$our_name ]] && break; done
readonly   config_dir=$dir/$our_name
readonly exclude_file=$config_dir/exclude.txt
readonly  config_file=$config_dir/configure.sh

config_file_sample=$config_file.sample
if [[ $our_path == */$our_name/bin/$our_name ]]
   then   git_home=${our_path%/bin/$our_name}
	config_file_sample=$git_home$config_file_sample
fi ;						readonly config_file_sample

[[ -s $config_file_sample ]] ||
   abort "have to install $config_file_sample"

# For each config var, create associative array for per-drive customization.
# [customize-config-variables currently fails when try to customize an array.]
readonly uncustomizable_config_vars="
	    drive_dir_prefix old_crypt_name_prefixes drive_specific_config_file
	    level2CPU_priority_cmd level2IO_priority_cmd
	    is_drive_name_capitalized drive_name_regex admin_drive_name_regex
	    is_drive_name_upper_cased"
config_vars=$(
    # toss functions before looking for variable assignments
    sed -n -r	-e '/(^[ 	]*function\b.*|\(\)) *\{.*\}/d'		\
		-e '/(^[ 	]*function\b.*|\(\)) *\{/,/^[ 	]*\}/d'	\
		-e 's/^[^#=]*\b([^_]\w+)=.*$/\1/p' $config_file_sample | uniq
)							; readonly config_vars
_customizable_arrays=
for var in $config_vars; do _customizable_arrays+="drv_name2$var "; done
declare -A $_customizable_arrays
#
# this grabs variables that control backup and pruning, and may also hold
# customizable functions *set-drive_name & source-drive-specific-config-file
source $config_file || abort "source'd $config_file ended with non-0 status"

[[ $is_drive_name_capitalized || $is_drive_name_upper_cased ]] &&
    shopt -s nocaseglob			# we mostly glob drive names or dirs

readonly PS4		      # remove if some functions want to manipulate it

is-set   coder ||			# custom version in $config_file?
readonly coder=sweikart@gmail.com

[[ -s $exclude_file ]] ||
   abort "install/edit $exclude_file, see included .sample"

readonly Usage="
Usage: $our_name [options] action [options] [args]

  $our_name (snapshot backups) maintains multiple, uniquely-named,
      online and offsite backup drives (partitions), each with separate
      logging and policy (see files in $config_dir/); for the dashboard,
      run: $our_name watch

  Current actions are (you can specify their acronym, see process-action):
    list-drives [-a]: list mounted backup drives; -a adds drives cron ignores
    run-backups   names: backup names ('all' for every mounted backup drive)
    prune-drives  names: prune  names ('all' for every "" ""); see configure.sh
    update-drives [-d] [-s src-names-regex] dst-names: copy missing snapshots
    copy-snapshots [-d] [-q] snapshots name: copy to 'name' mounted drive

    snapshot-size dir: size of non-hard-linked files (ie in no other snapshots)
    w: show full details on all jobs and drives
    watch [-f][-C][-N names] [watch-opts]: dashboard (-f: wide; -C: cron jobs)

    # -signal defaults to -KILL (-9), i.e. terminates job & deletes lock;
    # a glob can be a comma-separated list, a shell glob pattern, or 'all'.
    kill [-signal] job-type-glob  name-glob: job-types are backup, copy, prune
    continue	   job-type-glob  name-glob: as above, but -CONT signal
    suspend	   job-type-glob  name-glob: as above, but -STOP signal
    stop	   job-type-glob  name-glob: as above, but -STOP signal
    ps [ps-opts]  [job-type-glob [name-glob]]: show holder(s) of lock(s)
    reset-priority [names]: reset job priorities on drives (defaults to all)

    add-extN-journal drive_name [FS_device [VG_name]]: fast external journal
    dir-sizes [-f | name]: generates stats for 'mkfs -b'; -f -> choose old file
    mkfs [-f] [mkfs-opts] device name: run mkfs optimized for many snapshots
    copy-drive {src_name | src_dev} dst_name [dst_dev]: duplicate backup drive
    filesystem-geometry [-a|-A|drive-dirs]: show sector, inode, block, etc

    check-snapshot-hard-links names: find snapshots with broken hard links
    mk-Z [date [period]]: create mostly-empty snapshot dirs in Z mount-point
    test-prune: use mk-Z to run pruning regression test in the Z pseudo-drive
    regression-test [tests]: check functionality, see $tmp_dir/?? for results
    chroot-backup date,time [command]: chroot to snapshot on fastest drive
    run [-v var-names] func-name: run func-name, echo contents of var-names

  NOTE: to see what an action would do, use -d option to simulate the action.

  Common options:
	-C: we are being run from cron

	-c: pass -c (--checksum) to rsync
	-n: pass -n (--dry-run ) to rsync
	-v: pass -v (--verbose ) to rsync (and maybe other commands)
	-q: pass -q (--quiet   ) to rsync (and maybe other commands)
	-r rsync-opt: pass rsync-opt to rsync

	-d: Debug shell script (don't run commands, just show them): simulation
	-t: Trace shell script (show commands as they execute)
	-T level: control whether Trace & TraceV functions run echoE & echoEV
"

is_cron=$false cron_opt=
IfRun= Trace= TraceAll= debug_opt= trace_opt=  our_rsync_opts=
our_opts=
while getopts "C cnvqr: dtT: hk"  arg
    do	our_opts+="-$arg ${OPTARG-} "
	case $arg in
	   ( C ) is_cron=$true	cron_opt=-C ;;

	   ( c ) our_rsync_opts+="--checksum "	;;
	   ( n ) our_rsync_opts+="--verbose --dry-run " ;;
	   ( v ) our_rsync_opts+="--verbose "	;;
	   ( q ) our_rsync_opts+="--quiet "	;; # cancels --verbose
	   ( r ) our_rsync_opts+="$OPTARG "	;;

	   ( d ) IfRun="echo -e" debug_opt=-d ;; # put $IfRun b4 'active' cmds
	   ( t ) [[ $Trace ]] && TraceAll=$Trace
		 Trace="set -x"  trace_opt=-t ;;
	   ( T ) Trace_level=$OPTARG Trace_level_opt="-T $OPTARG" ;;

	   (h|k) print-or-egrep-Usage-then-exit "$@" ;;
	   ( * ) abort "$Usage" ;;
	esac
done
let OPTIND=$OPTIND-1
shift $OPTIND
unset arg

[[ $debug_opt ]] && verbose_opt=-v || verbose_opt=

[[ $Trace && $debug_opt ]] && IfRun=:

trap 'set +x; rm -f $tmp_1 $tmp_2 $tmp_3 $tmp_4 $tmp_5; trap EXIT' EXIT

readonly tmp_1=$tmp_dir/$our_name-1-$$	; tmp=$tmp_1
readonly tmp_2=$tmp_dir/$our_name-2-$$
readonly tmp_3=$tmp_dir/$our_name-3-$$
readonly tmp_4=$tmp_dir/$our_name-4-$$
readonly tmp_5=$tmp_dir/$our_name-5-$$

have-cmd lockpid || abort "'make' then install lockpid from $libsnap_project"

shopt -s checkhash			# sometimes move commands for testing
shopt -s extglob			# useful for args to set-glob
shopt -s nullglob			# so don't need to test for no matches
shopt -s globasciiranges		# so weird locales don't mess us up

umask 02				# log and lock dirs are setgid sudo/etc

set -u					# abort if access unset variable

FUNCNEST=100				# catch coding errors

fgrep -q -x "# version=$version" $config_file_sample ||
  $IfRun abort "$config_file_sample version= does not match $our_path"

$TraceAll

##############################################################################
# Miscellaneous variables used by for making and pruning backup snapshots.
##############################################################################

# touched when prune ends; its time is compared to files in $config_dir/
readonly pruned_timestamp=.pruned.ts

readonly our_opts=${our_opts% }
# need to fork and exec ourselves for session control with 'setsid'
readonly    run_backup_exe="$our_path $our_opts run-backup"
readonly   prune_drive_exe="$our_path $our_opts prune-drive"
readonly  update_drive_exe="$our_path $our_opts update-drive"
readonly copy_snapshot_exe="$our_path $our_opts copy-snapshot"

readonly hostname=${HOSTNAME%%.*}

readonly log_dir=/var/log/$our_name

# these are used by log(), besides $log_level
file_for_logging=$log_dir/messages.log	     # set-drive_log_dir-* sets it
log_msg_prefix=' ${action-} ${drive_name-}'  # this gets eval'ed each time

##############################################################################
# Miscellaneous functions used by for making and pruning backup snapshots.
##############################################################################

set-readable_du_size() {
	local -i size=$1

	local suffix=K
	while (( $size >= 1024 ))
	   do	let size/=1024
		case $suffix in		# see: man du
		    ( 'K' ) suffix=M ;;
		    ( 'M' ) suffix=G ;;
		    ( 'G' ) suffix=T ;;
		    ( 'T' ) suffix=P ;;
		    ( 'P' ) suffix=E ;;
		    ( 'E' ) suffix=Z ;;
		    ( 'Z' ) suffix=Y ;;
		esac
	done
	readable_du_size=$size${suffix}B
}
readonly -f set-readable_du_size

# -----------------------------------------------------------------------------

assert-drive_dir-writable() {
	local dir=${1:-$drive_dir}

	[[ -f $dir ]] && dir=${dir%/*}
	$IfRun touch $dir/. ||
	   abort "$dir mounted read-only??  Maybe corrupted, run fsck."
}
readonly -f assert-drive_dir-writable

##############################################################################
# lock management
##############################################################################

readonly lock_dir=/var/lock/$our_name
declare -x -r LOCKPID_DIR=$lock_dir

# use this instead of 'lockpid' when want/need to replace stale lock
function sudo-lockpid() {
	if [[ $1 == -o ]]
	   then local is_optional=$true; shift
	   else local is_optional=$false
	fi

	# we're used when locks maybe stale (sudo-lockpid $lock &> /dev/null);
	# but they usuaully aren't, so "$IfRun lockpid" would only show release
	[[ $debug_opt ]] && return 0

	local lock=${!#}
	[[ $lock == /* ]] || lock=$lock_dir/${lock##*/}
	[[ -w $lock || ( ! -e $lock && -w $lock_dir ) ]] &&
	   { lockpid "$@"; return; }

	is-set can_sudo_lockpid ||
	if sudo -n lockpid -h &> /dev/null
	   then readonly can_sudo_lockpid=$true
	   else readonly can_sudo_lockpid=$false
	fi

	if [[ $action =~ (kill|continue|suspend) ]]
	   then local is_signaling=$true
	   else local is_signaling=$false
	fi
	if [[ $is_signaling || $can_sudo_lockpid || ! $is_optional ]]
	   then local sudo_lockpid="sudo lockpid --pid=$BASHPID"
	   else local sudo_lockpid=lockpid # only reclaim writable locks
	fi
	$sudo_lockpid "$@"
}
readonly -f sudo-lockpid

# --------------------------------------------

rm-stale-locks() {

	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	local lock_path
	for lock_path in $lock_dir/*.pid
	    do	[[ -e $lock_path ]] || continue
		sudo-lockpid -o $lock_path &> /dev/null &&
		sudo-lockpid -r $lock_path # we grabbed it, i.e. it was stale
	done
}
readonly -f rm-stale-locks

# -----------------------------------------------------------------------------

readonly writer_types="backup prune copy"

set-lock_path() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local type=$1 name=${2:-$drive_name}

	[[ $name ]] || abort-function "missing \$2 and \$drive_name null"
	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	lock_path=$lock_dir/$type-$name.pid
	$xtrace
}
readonly -f set-lock_path

# ---------------------------------

# turn comma-separated lists and/or ranges into a single glob
function set-glob() {

	glob=
	local arg
	for arg
	    do	set -f
		[[ $arg == *,*  && $arg !=  '{'* ]] && arg="{$arg"
		[[ $arg == *,*  && $arg != *'}'  ]] && arg="$arg}"
		[[ $arg == *..* && $arg !=  '{'* ]] && arg="{$arg"
		[[ $arg == *..* && $arg != *'}'  ]] && arg="$arg}"
		[[ $arg == *-*  && $arg !=  '['* ]] && arg="[$arg"
		[[ $arg == *-*  && $arg != *']'  ]] && arg="$arg]"
		set +f
		glob+="$arg,"		# append ','. we'll wrap in {}
	done
	glob=${glob%,}
	(( $# > 1 )) && glob="{$glob}"
	[[ $glob == *['[{*?,+@!']* ]]
}
readonly -f set-glob

# ---------------------------------

function set-lock_paths() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $# == [0-2] ]] ||
	    abort-function "$*: must be 0-2 args (can use globs)"
	[[ ${1-} == *.pid ]] && { lock_paths=$1; $xtrace; return 0; }
	local type_glob=${1:-*} name_glob=${2:-${drive_name:-*}}

	set-glob "$type_glob" && type_glob=$glob
	set-glob "$name_glob" && name_glob=$glob

	[[    $type_glob == a*  ]] && type_glob=*
	if [[ $name_glob == all ]]
	   then name_glob=*
	elif [[ $name_glob == /* ]]
	   then local drive_name
		_set-drive_name $name_glob
		name_glob=$drive_name
	elif [[ ${is_drive_name_upper_cased-} ]]
	   then name_glob=${name_glob^^}
	elif [[ ${is_drive_name_capitalized-} && $name_glob != *[[,]* ]]
	   then name_glob=${name_glob^} # only capitalize a single name
	fi

	eval "set -- $lock_dir/$type_glob*-$name_glob.pid"
	lock_paths=$*
	$xtrace
	[[ $lock_paths ]]
}
readonly -f set-lock_paths

# ---------------------------------

xtrace=				  # in case comment-out first line of function

function lock-PID() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $1 == -n ]] && { local name=$2; shift 2; } || local name=$drive_name
	local lock_opts=
	while [[ $1 == -* ]] ; do lock_opts+="$1 "; shift; done
	local type=$1 lock_holder_action=$2

	is-arg_1-in-arg_2 $type $writer_types ||
	   abort-function "'$type' is unknown lock type"
	set-lock_path $type $name
	local lock_file=${lock_path##*/}

	[[ $lock_holder_action == holds* ]] ||
	    lock_holder_action="is $lock_holder_action"

	local our_PID=$BASHPID status_file=$tmp_3
	set -- lockpid --pid=$our_PID --dir=$lock_dir $lock_opts $lock_file
	local lock_cmd=$*
	local lockpid_output=$($IfRun $lock_cmd 2>&1; echo $? > $status_file)
	local status=$(< $status_file)
	rm $status_file

	if [[ $status == 0 ]]
	   then [[ $is_regression_test && $lockpid_output ]] &&
		echo "$lockpid_output" | sed "s@$our_PID@<a_PID>@"
		$xtrace
		return 0
	fi

	local lock_holder_PID=$(echo "$lockpid_output" |
				sed -r 's@.*rocess ([0-9]+) holds.*@\1@')
	if [[ $status == $lockpid_busy_exit_status && $lock_holder_PID ]]
	   then [[ ! $is_cron || $(date '+%H') == 00 || $log_level -gt 0 ]] &&
		log  "process $lock_holder_PID $lock_holder_action"
	elif [[ $lock_opts != *-q* ]]
	   then log "$lock_cmd -> $lockpid_output (status=$status)"
	fi >&2
	$xtrace
	return 1
}
readonly -f lock-PID

# ------------------------------------------------------------------

# When $is_multi_writer_drive == $true, all writer jobs run in parallel, with
# their (relative) I/O and CPU priorities controlled by
# set-job_type2priority_level() .  [Locking and job creation are described in
# the next section.]

# When $is_multi_writer_drive == $false, only one job can be writing to a
# drive at once (any other jobs will be suspended); this section describes the
# policy (and mechanism) to meet that requirement.  For each drive,
# create-jobs() creates a job for a type of writer, and lock()
# creates a lock for each of those jobs ( see writer_types= ).  The
# backup job gets priority (i.e. non-backup jobs will be suspended when a
# backup job is initiated).  When no backup job is running, and copy and prune
# jobs both exist, suspended-prune-as-drive-usage-response decides
# which one should be suspended.
#
# An hourly cron job calls action run-backups (with argument 'all'), which
# calls create-jobs() to create a run-backup() job for each drive;
# each run-backup() job starts a prune-drive() job, and prune-drive() may
# start an update-drive() job.  If the cron job is called more frequently
# than hourly, the off-hour jobs just call reset-priority and prune-drive
# (for drives with too-high usage, suspend any copy and start a prune).
#
# A lock() call for a non-backup lock will get its requested lock immediately
# (so the job will then appear on the dashboard), but will release that lock
# and return 'failed' if a backup is running (it'll wait for the backup to
# finish if called by 'lock -w', e.g. it's a user-initiated action).
# Similarly, a call to continue-jobs() for a non-backup job will be silently
# ignored if a backup is running, and will return 'failed'.

declare -A _lock_type2lock_path
declare -A  lock_type2locked_resource

# Usage: lock [-w] type resource
#    Grab a lock of 'type' on resource (drive-dir or snapshot).
#    If -w and lock is held by other job, Wait for lock to be freed.
#    After grab non-backup lock, waits for no-backup if ! is_multi_writer_drive
function lock() {
#	[[ ${action-} != test ]] && # [[ ${action-} != prune* ]] &&
#	[[ -o xtrace  ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $1 == -w   ]] && { shift; local do_wait=$true; } || local do_wait=
	assert-not-option ${1-}
	[[ $# == [12] ]] || abort-function "[-w] type resource"
	local type=$1 resource=${2:-$drive_name}

	suspend-tracing
	local drive_name drive_dir	# don't mess up caller's values
	 _set-drive_name $resource
	 _set-drive_dir
	restore-tracing drive_name

	local prev_lock_path=${_lock_type2lock_path[$type]-}
	[[ ! $prev_lock_path ]] ||
	   abort "hold $(basename $prev_lock_path), can't grab $type lock file"

	local	    lock_msg="holds '$type' lock for $drive_name"
	local extra_lock_msg="${lock_msg/$type/backup}, so can't $type"

	[[ $do_wait ]] && local wait_opt=--wait || local wait_opt=
	[[ $do_wait || ! $is_cron ]] &&	# interactive user waits for lock
	if [[ $type == backup ]]
	   then declare -i half_backup_period_mins=$backup_period*60/2
		  if [[ $date_time == *-01,00 ]] # kept a very long time?
		   then wait_opt=--wait-expiration=15d # want it, or next month
		elif [[ $date_time == *-16,00 ]] # kept a long time?
		   then wait_opt=--wait-expiration=8d # want it, or next one
		elif [[ $date_time ==    *,00 ]] # kept a fairly long time?
		   then wait_opt=--wait-expiration=12h # want it, or tomorrow's
		   else wait_opt=--wait-expiration=${half_backup_period_mins}m
		fi
		wait_opt+=" --quiet"
	fi
	# if interactive user, want to honor their request eventually
	[[ ! $is_cron ]] && : ${wait_opt:=--wait}

	# be sure to grab primary lock first, so job appears on dashboard
	lock-PID $wait_opt $type "$lock_msg" || { $xtrace; return 1; }
	local primary_lock_path=$lock_path # lock-PID sets lock_path

	! [[ $action == update* && $debug_opt ]] && # not regression-test?
	# this 'if' logic is similar to the logic in _signal-job()
	if ! [[ $is_multi_writer_drive || $type == backup ]]
	   then lock-PID $wait_opt backup "$extra_lock_msg" &&
		lock-PID --release backup "$extra_lock_msg" ||
		   { lockpid --release $primary_lock_path; $xtrace; return 1; }
	fi

	_lock_type2lock_path[$type]=$primary_lock_path
	 lock_type2locked_resource[$type]=$resource

	 $xtrace
	return 0
}
readonly -f lock

# ---------------------------------

unlock() {
#	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=

	local type
	for type
	    do	local lock_path=${_lock_type2lock_path[$type]-}
		[[   $lock_path ]] || abort "don't hold lock of type '$type'"
		RunCmd lockpid --release $lock_path
		unset _lock_type2lock_path[$type]
		unset  lock_type2locked_resource[$type]
	done

	$xtrace
}
readonly -f unlock

##############################################################################
# enumerating/showing/signaling/killing process groups
##############################################################################

process-group-PIDs() {

	local PGID
	for PGID
	    do	# I don't know why this didn't work
		# ps -u root -o pid,pgid | grep " $PGID$" | awk '{ print $1 }'

		# "pstree -p -a" lines start with: <command>,<PID> ...
		pstree -p -a $PGID | sed 's/^[^,]*,\([0-9]*\).*/\1/'
	done
}
readonly -f process-group-PIDs

# ----------------------------------------------------------------------------

function set-job_PGID() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local job_type=$1 lock_path

	set-lock_path $job_type
	if [[ -s $lock_path ]]
	   then set -- $(< $lock_path)
		job_PGID=$1
	   else job_PGID=
	fi
	$xtrace
	[[ $job_PGID ]]
}
readonly -f set-job_PGID

# ----------------------------------------------------------------------------

function set-signal_is_kill() {
	local signal=${1#-}

	case ${signal^^} in
	   ( SIGKILL | KILL | 9 )
		signal_is_kill=$true  ; return 0 ;;
	   ( *)	signal_is_kill=$false ; return 1 ;;
	esac
}
readonly -f set-signal_is_kill

# ----------------------

function set-lock_PID() {
	local lock=$1

	[[ $lock == /* ]] || lock=$lock_dir/${lock##*/}
	lock_PID=
	[[ -s $lock ]] && set -- $(< $lock) && [[ $# == 1 ]] || return 1
	lock_PID=$1
	return 0
}
readonly -f set-lock_PID

# ----------------------

function is-active-lock() {
	set-lock_paths "$@"

	local lock lock_PID
	for lock in $lock_paths
	    do	set-lock_PID $lock && is-process-alive $lock_PID && return 0
	done
	return 1
}
readonly -f is-active-lock

# ----------------------

function have-job() { is-active-lock "$@"; }
readonly -f have-job

# ----------------------

function sudo-kill() {
	local PID=${!#}

	$IfRun kill "$@" 2> /dev/null && return 0 # kill is built-in, so cheap
	is-process-alive ${PID#-} || return 1
	local  kill_msg=$(kill "$@" 2>&1)
	if [[ $kill_msg == *"Operation not permitted"* ]]
	   then sudo kill "$@"
	   else echo "$kill_msg" >&2
		return 1
	fi
}
readonly -f sudo-kill

# ----------------------

# return false if job exists but we didn't kill it, otherwise true
function signal-job() {
	local signal=${1#-}; shift
	if [[ $# == 1 && $1 == *.pid ]]
	   then lock_path=$1		# global variable, caller can use it
		[[ $lock_path == /* ]] || lock_path=$lock_dir/${lock_path##*/}
	   else local job_type=$1 drive_name=${2:-$drive_name}
		suspend-tracing
		_set-drive_name $drive_name
		set-lock_path $job_type
		restore-tracing
	fi

	[[ ! $debug_opt ]] &&
	# use -o, because we don't really need to remove a stale lock
	sudo-lockpid -o --not-hold $lock_path &> /dev/null && # if stale ...
	sudo-lockpid    --release  $lock_path && return 0     # nothing to kill

	set-lock_PID $lock_path || return 0 # is there a valid job to signal?
	sudo-kill -s ${signal^^} -$lock_PID || return 1 # did our kill work?

	set-signal_is_kill $signal || return 0 # (wanted to) terminate job?

	sudo-lockpid -o $lock_path &> /dev/null && # see if it really died
	sudo-lockpid -r $lock_path
	return $?			# is lock-holder still alive?
}
readonly -f signal-job

# ---------------------------------

# The locking & job-management policy is documented in front of function lock()

function _signal-jobs() {
	local signal=$1; shift

	[[ $IfRun ]] && echo "${FUNCNAME[1]} $*" && return 0

	local type
	for type
	    do	have-job $type || continue
		if [[ $signal == *CONT ]]
		   then # this logic is similar to the logic in lock()
			! [[ $is_multi_writer_drive || $type == backup ]] &&
			have-job backup &&
			    return 1  # only 1 writer allowed, bkp has priority
			set-job_PGID $type &&
			set-priority $type $job_PGID
		fi
		signal-job $signal $type
	done
	return 0
}
readonly -f _signal-jobs

# these take multiple types, and work with the current $drive_name
function  suspend-jobs() { _signal-jobs -STOP "$@"; }
function continue-jobs() { _signal-jobs -CONT "$@"; }
readonly -f suspend-jobs continue-jobs

# -------------------------------------------------

function kill-job-on-drives() {
	local signal=-KILL
	[[ $1 == -s    ]] && { signal=-STOP ; shift; }
	[[ $1 == -c    ]] && { signal=-CONT ; shift; }
	[[ ${1-} == -* ]] && { signal=${1^^}; shift; }
	assert-not-option ${1-}

	set-lock_paths "$@" || return 1

	set-signal_is_kill $signal
	local path status=1		# assume nothing we're allowed to kill
	for path in $lock_paths
	    do	if [[ $signal_is_kill ]]
		   then # sometimes it takes multiple kills for update-drive
			local did_loop=$false
			until signal-job $signal $path
			   do	echo -n .
				sleep 0.1
				did_loop=$true
			done
			[[ $did_loop ]] && echo
			status=0
		   else signal-job $signal $path && status=0
		fi
	done

	return $status
}
readonly -f kill-job-on-drives

# -----------------------------------------------------------------------------

function set-lock_PGIDs() {
	local type=$1 names_glob=${names_glob:-*}

	lock_PGIDs=

	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	eval "set -- $lock_dir/$type-$names_glob.pid"

	local lock locks=
	for lock; do [[ -s $lock ]] && locks+="$lock "; done

	[[ $type == prune && ! ( $debug_opt || $show_all ) ]] &&
	    locks=${locks/$type-Z.pid/}

	for lock in $locks
	    do	set -- $(< $lock)
		[[ $# == 1 ]] || continue
		lock_PGIDs+="-$1 "
	done 2> /dev/null	    # a lock might disappear, i.e. $(< ) fails
	[[ $lock_PGIDs ]]
}
readonly -f set-lock_PGIDs

# -----------------------------------------------------------------------------

function ps-locks() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ ${1-} == -R ]] && { local do_rm= ; shift; } || local do_rm=$true
	local ps_opts=
	# $1 type abbrevs are (a)ll, (b)ackup, (c)opy, (p)rune: so not 'ps' opt
	while [[ ${1-} == -* || ${1-} == [^abcp] || $# -ge 3 ]]
	   do ps_opts+="$1 "; shift; done
	[[ $ps_opts   ]] || ps_opts="-o pid,stat,stime,command"
	[[ $is_darwin ]] || ps_opts="-H $ps_opts" no_header_opt=h
	set-lock_paths "$@"

	[[ $do_rm ]] && rm-stale-locks
	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	local status=1			# assume all locks are missing/stale
	for lock in $lock_paths
	    do	header $lock
		[[ -s  $lock ]] || { echo "no such lock"; continue; }
		set -- $(< $lock)
		ps $ps_opts -$1 || ps ${no_header_opt-} $ps_opts $1
		status=$?
	done
	$xtrace
	return $status
}
readonly -f ps-locks

##############################################################################
# miscellaneous
##############################################################################

list-drive-dirs() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ ${1-} == -a ]] &&
	   local list_all_drives=$true && shift ||
	   local list_all_drives=$false

	if [[ -t 0 || -t 1 || -t 2 || $list_all_drives ]]
	   then local regex=$admin_drive_name_regex
	   else local regex=$drive_name_regex # for cron & nohup
	fi
	[[ ${1-} == -A ]] && regex=/ || regex="^$drive_dir_prefix$regex$"
	df --output=target --no-sync -x devtmpfs -x tmpfs |
	   egrep "$regex" | sort -u
	$xtrace
}
readonly -f list-drive-dirs

# ----------------------

function set-drive_dirs() {
	set -- $(list-drive-dirs "$@")
	drive_dirs=$*
	[[ $drive_dirs ]]
}
readonly -f set-drive_dirs

# ---------------------------------

function is-drive-mounted() {
	local drive_dir=$1

	[[ $drive_dir ]] || return 1
	[[ $drive_dir == *[-/]Z ]] && return 0 # Z is testing pseudo-drive
	df | grep -q " $drive_dir$"
}
readonly -f is-drive-mounted

# ----------------------------------------------------------------------------

set-oldest_snapshot() {

	local oldest= FS
	for FS in $(list-drive-dirs)
	    do	suspend-tracing
		set -- $FS/$snapshot_glob
		[[ $# != 0 ]] || continue
		restore-tracing
		[[ $oldest && ${oldest##*/} < ${1##*/} ]] &&
		   continue
		oldest=$1
	done
	[[ -d $oldest ]] || abort "no old backup drives are mounted"
	oldest_snapshot=$oldest
}
readonly -f set-oldest_snapshot

##############################################################################-
# Setup variables for working with a specific backup drive.
##############################################################################-

function set-admin_group {

	is-set admin_group && { [[ $admin_group ]] ; return $?; }

	suspend-tracing
	local env_var env_var_values="${SUDO_USER-} ${USER-} ${LOGNAME-}"
	for env_var in HOME MAIL
	    do	is-set $env_var || continue
		local path=${!env_var}
		env_var_values+=" ${path##*/}"
	done

	local user
	for user in $env_var_values
	    do	[[ $user != root ]] && break
	done
	local users_groups=$(id -G -n $user)

	local group
	for group in sudo wheel admin adm NoNe '' # 'admin' is Darwin / macOS
	    do	is-arg_1-in-arg_2 $group $users_groups && break
	done
	[[ $group == NoNe ]] && admin_group= || admin_group=$group

	readonly admin_group
	restore-tracing group
	[[ $admin_group ]]
}
readonly -f set-admin_group

# ----------------------

fix-drive_dir-perms() {
	local drive_dir=${1:-$drive_dir}

	mkdir -p $drive_dir/.junk	# for sysadmin
	set-admin_group &&
	chgrp $admin_group $drive_dir/{.,.??*} &&
	# this will _not_ make non-empty snapshots deletable by group
	chmod g+w	   $drive_dir/{.,.??*} # for 'u' regression test
}
readonly -f fix-drive_dir-perms

# ----------------------

create-lock_dir-log_dirs() {

	local group=

	[[ -d $log_dir && -d $lock_dir ]] || {
	set-admin_group && group=$admin_group
	sudo mkdir -p --mode=1777 $lock_dir
	sudo mkdir -p	   $log_dir	; [[ $group ]] &&
	sudo chgrp $group  $log_dir $lock_dir &&
	sudo chmod g+w,g+s $log_dir $lock_dir
	}
	[[ -d $log_dir ]] || abort "need sudo privs for initial setup"

	[[ ${drive_log_dir-} ]] || return

	if [[ ! -d $drive_log_dir ]]
	   then set-admin_group && group=$admin_group && group=:$group
		[[ ${drive_dir-} && $UID == 0 ]] && fix-drive_dir-perms
		sudo mkdir -p -m g+w,o-w $drive_log_dir
		[[ $is_regression_test ]] &&
		sudo touch $file_for_logging &&
		sudo chown $LOGNAME$group $drive_log_dir $file_for_logging
	fi
	[[ -d $drive_log_dir ]] || abort "need sudo privs to setup new drive"
}
readonly -f create-lock_dir-log_dirs

# -----------------------------------

is_regression_test=$false

readonly none=NoNe
_last_fully_initialized_drive_name=

# this is normally called by set-drive_name; but you can pass
# a null drive_name to set default file_for_logging & drive_log_dir
set-drive_log_dir-file_for_logging-admin_group-is_regression_test() {
	local  drive_name=${1-}	     # called from set-drive_name, so $1 valid

	if  [[ $_last_fully_initialized_drive_name != ${drive_name:-$none} ]]
	   then _last_fully_initialized_drive_name=${drive_name:-$none}
	   else return			# skip very-long, duplicative setup
	fi

	[[ $drive_name == Z || ( $debug_opt && $is_cron ) ]] &&
	    is_regression_test=$true

	if [[ $drive_name ]]
	   then drive_log_dir=$log_dir/$drive_name
	   else drive_log_dir=$log_dir
	fi
	TraceV 3 drive_log_dir
	file_for_logging=$drive_log_dir/messages.log
	[[ -d $drive_log_dir ]] || create-lock_dir-log_dirs

	customize-and-validate-configuration-variables $drive_name
}
readonly -f set-drive_log_dir-file_for_logging-admin_group-is_regression_test

# ---------------------------------

have-cmd \
source-drive-specific-config-file ||  # configure.sh can replace this function
source-drive-specific-config-file() {
	[[ $# == 0 ]] && return
	local _name=$1  _main_config_file=${2:-${config_file-}}
	set-drive_name $_name
	[[ $_main_config_file ]] || abort "pass config_file as 2nd arg"

	local     _config_file=${_main_config_file/%.sh/-$drive_name.sh}
	if [[ -s $_config_file ]]
	   then drive_specific_config_file=$_config_file; source $_config_file
	   else drive_specific_config_file=		; true
	fi
}
readonly -f source-drive-specific-config-file

# ---------------------------------

readonly allowed_drive_name_dir_chars='-_.a-zA-Z0-9'

have-cmd \
_set-drive_name ||		      # configure.sh can replace this function
# ignore invalid names, fix the case of valid names
_set-drive_name() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $1 == -q ]] && { local is_quiet=$true; shift; } || local is_quiet=
	local  name=${1#$drive_dir_prefix}
	name=${name%/$snapshot_glob*}

	[[ $name == *[^$allowed_drive_name_dir_chars]* ]] && {
	   [[ $is_quiet ]] && return 1
	   abort "drive_name $1 has disallowed chars (can ask $coder to allow)"
	}

	[[ $name =~ ^$admin_drive_name_regex$ ]] ||	  {
	    [[ $is_quiet ]] && return 1
	    abort "'$name' is not a valid drive-name"	; }

	  if [[ $is_drive_name_upper_cased ]]
	   then drive_name=${name^^}
	elif [[ $is_drive_name_capitalized ]]
	   then drive_name=${name^}
	   else drive_name=$name
	fi
	_last_fully_initialized_drive_name= # prevent weird bugs
	$xtrace
}
readonly -f _set-drive_name

# ----------------------

have-cmd \
set-drive_name ||		      # configure.sh can replace this function
# pass: directory (that holds snapshots), filesystem label, or valid name
set-drive_name() {
	[[ $# == 1 && $1 ]] || abort "set-drive_name takes a single argument"
	local name=$1

	if [[ ! $name =~ ^$admin_drive_name_regex$ ]]
	   then if [[ $name == /dev/* ]]
		   then set-FS_label--from-FS-device $name
			set-mount_dir--from-FS-label $FS_label
			drive_dir=$mount_dir
		elif [[ $name != /* ]]
		   then set-mount_dir--from-FS-label $name
			drive_dir=$mount_dir
		   else drive_dir=$name
		fi
		[[  $drive_dir =~					\
		   ^$drive_dir_prefix$admin_drive_name_regex$ ]] ||
		   abort "$name is not drive-dir or FS-label or valid-name"
		name=${drive_dir#$drive_dir_prefix}
	fi
	_set-drive_name $name
	TraceV 3 drive_name

	set-drive_log_dir-file_for_logging-admin_group-is_regression_test \
	   $drive_name
}
readonly -f set-drive_name

# ---------------------------------

_set-drive_dir() {
	local name=${1:-$drive_name}

	drive_dir=$drive_dir_prefix$name
}
readonly -f _set-drive_dir

# ----------------------

is_OK_if_drive_dir_unmounted=$false

function set-drive_dir() {
	local drive_name=$1		# result of set-drive_name, i.e. valid

	[[ $drive_name != */* ]] ||
	  abort "'/' in drive name not (yet)supported, add to drive_dir_prefix"

	_set-drive_dir

	if [[ $is_regression_test && ! -d $drive_dir ]]
	   then	set-admin_group
		[[ $admin_group ]] && local group=:$admin_group || local group=
		sudo mkdir $drive_dir &&
		sudo chmod g+s,g+w $drive_dir &&
		sudo chown $LOGNAME$group $drive_dir ||
		  abort "need sudo privs to setup pseudo-drive 'Z' for testing"
	fi

	if  is-drive-mounted  $drive_dir
	   then have-cmd fix_snapshot_names &&
		fix_snapshot_names $drive_dir # must call last
	   else [[ $is_OK_if_drive_dir_unmounted ]] ||
		    warn "no filesystem mounted on $drive_dir" ||
		    : print-call-stack	# uncomment to debug
		return 1
	fi

	return 0
}
readonly -f set-drive_dir

# -----------------------------------------------------------------------------

declare -A custom_config_var2default_value # set-drive_usage also uses this

customize-config-variables() {
	local drive_name=${1-}

	[[ $drive_name == Z ]] && is_regression_test=$true

	remember-tracing		# since suspend-tracing maybe not run
	local var_name
	[[ ${custom_config_vars-} ]] || {
	# set-drive_log_dir-file_for_logging-admin_group-is_regression_test
	declare -g custom_config_vars="drive_log_dir file_for_logging"
	declare -g custom_config_var_assignments= # to localize with 'local'
	for var_name in $custom_config_vars $config_vars
	    do	is-arg_1-in-arg_2 $var_name $uncustomizable_config_vars &&
		   continue

		is-arg_1-in-arg_2 $var_name $custom_config_vars ||
		is-set $var_name ||
		   abort "need to set '$var_name=' in $config_file"

		is-set $var_name &&
		! [[ $(declare -p $var_name) =~ ^declare.-[aA]?i?r ]] ||
		   continue		# readonly, can't customize

		local default_value=${!var_name}
		custom_config_var2default_value[$var_name]=$default_value
		default_value=${default_value%% *} # excluded_backup_hours
		custom_config_var_assignments+="$var_name=$default_value "

		suspend-tracing
	done
	custom_config_vars=${!custom_config_var2default_value[*]}
	readonly custom_config_var2default_value custom_config_vars
	readonly custom_config_var_assignments ; }
	restore-tracing

	[[ $drive_name ]] || return

	for var_name in $custom_config_vars
	    do	local array_name=drv_name2$var_name
		eval "local drv_names=\${!$array_name[*]}"
		[[ $drv_names ]] || continue
		suspend-tracing

		is-arg_1-in-arg_2 $var_name $uncustomizable_config_vars &&
		   abort "$config_file can't have custom '$var_name'"

		is-arg_1-in-arg_2 $drive_name $drv_names || {
		eval "$var_name=\${custom_config_var2default_value[$var_name]}"
		continue; }

		eval "local custom_value=\${$array_name[\$drive_name]-}"
		eval "$var_name=\$custom_value"
		Trace 2 "$array_name[$drive_name] -> $var_name=$custom_value"
	done
	restore-tracing custom_config_vars
}
readonly -f customize-config-variables

# ------------------------------------------------------------------

validate-config-variables() {

	declare -p $config_vars | grep -v '^declare -'
	[[ ${PIPESTATUS[0]} == 0 ]] ||
	    abort "must assign above variables, see $config_file_sample"

	local var=snapshot_date_time_separator
	[[ ${!var} == ',' ]] ||
	   abort "$var is not implemented, email $coder"
	#
	[[ ! $extra_excludes ]] ||
	   abort "extra_excludes is not implemented, email $coder"
	#
	local bad_punctuation="[-.:0-9]" # you could ask $coder to change this
	[[ $snapshot_date_time_separator != *$bad_punctuation* ]] ||
	   abort "snapshot_date_time_separator can't contain $bad_punctuation"
	#
	[[ $excluded_backup_hours != *[^-\ \	0-9]* ]] ||
	   abort "excluded_backup_hours must be list of (ranges of) numbers"

	[[ $drive_dir_prefix == *[^$allowed_drive_name_dir_chars/]* ]] &&
	   abort "drive_dir_prefix has disallowed chars (ask $coder to allow)"

	set -- $config_file ${drive_specific_config_file-}

	echo " $dirs_to_backup " | grep ' [^/]' &&
	   abort "dirs_to_backup contains a non-absolute path in $*"

	is-arg_1-in-arg_2 $backup_period $valid_backup_periods ||
	   abort "invalid 'backup_period=$backup_period' in $*"

	[[ -s $exclude_file ]] ||
	   abort "'exclude_file=$exclude_file' is empty file (from $*)"

	is-arg_1-in-arg_2 0 $successful_rsync_exit_statuses ||
	   abort "'successful_rsync_exit_statuses=$successful_rsync_exit_statuses' must contain 0 in $*"

	for var_name in drive_name_regex admin_drive_name_regex
	    do	# we'll anchor these variable's values ourselves, when needed
		[[ ${!var_name} != ^* ]] ||
		   abort "remove  leading '^' from $var_name="
		[[ ${!var_name} != *$ ]] ||
		   abort "remove trailing '$' from $var_name="
	done
}
readonly -f validate-config-variables

# ------------------------------------------------------------------

customize-and-validate-configuration-variables() {
	local name=${1-}

	# avoid infinite loop
	set -- ${FUNCNAME[*]} ; shift
	is-arg_1-in-arg_2 $FUNCNAME $* && return

	suspend-tracing

	source-drive-specific-config-file $name

	customize-config-variables $name

	validate-config-variables	# must do this last

	restore-tracing
}
readonly -f customize-and-validate-configuration-variables

##############################################################################
# Manage priorities for backup and prune and update/merge.
##############################################################################

function is-drive-usage-too-high() {
	local drive_dir=${1:-$drive_dir}

	suspend-tracing
	set -- $(df --output=pcent,ipcent $drive_dir | tail -n1)
	[[ $# != 0 ]] || abort "$drive_dir is not mounted"
	local -i block_percent=${1%\%} inode_percent=${2%\%}
	# caller can declare max_drive_usage_percent to use it
	if (( $block_percent > $inode_percent ))
	   then max_drive_usage_percent=b$block_percent
	   else max_drive_usage_percent=i$inode_percent
	fi
	restore-tracing
	(( $block_percent <= $min_FS_usage_percent )) || return 0
	(( $inode_percent <= $min_FS_usage_percent )) || return 0
	return 1
}
readonly -f is-drive-usage-too-high

# --------------------------------------

declare -A job_type2priority_level

# this is mostly relevant when $is_multi_writer_drive
set-job_type2priority_level() {

	if is-drive-usage-too-high
	   then job_type2priority_level=(
		    [prune]=higher
		   [backup]=medium
		     [copy]=lower
		)
	   else job_type2priority_level=(
		   [backup]=higher
		     [copy]=medium
		    [prune]=lower
		)
	fi
}
readonly -f set-job_type2priority_level

# -----------------------

# this sets the 'priority' variable _and_ changes the process priority
function set-priority() {
	local job_type=$1 PGID=${2:-$$}

	set-job_type2priority_level
	priority=${job_type2priority_level[$job_type]}

	local CPU_priority_cmd=${level2CPU_priority_cmd[$priority]}
	local  IO_priority_cmd=${level2IO_priority_cmd[$priority]}

	# test-prune is very noisy in here
	[[ $action == prune-drive* && $drive_name == Z ]] && return 0

	{
	$IfRun $CPU_priority_cmd $PGID && { [[ ! $IO_priority_cmd ]] ||
	$IfRun  $IO_priority_cmd $PGID					; }
	} |
	if [[ $is_regression_test ]]
	   then sed "s@\b$PGID\b@<a_PGID>@"
	   else egrep -v ' new priority '
	fi
	[[ ${PIPESTATUS[0]} == 0 ]]
}
readonly -f set-priority

# -----------------------------------------------------------------------------

function reset-drive-jobs-priorities {

	local type job_PGID priority status=1
	for type in $writer_types
	    do	set-job_PGID $type || continue
		set-priority $type $job_PGID
		status=0
	done
	return $status
}
readonly -f reset-drive-jobs-priorities

# ------------------------------------------

function suspended-prune-as-drive-usage-response() {
	local drive_names=${*:-$drive_name}

	local drive_name status=1
	for drive_name in $drive_names
	    do	_set-drive_name $drive_name
		reset-drive-jobs-priorities || continue

		have-job copy || { continue-jobs prune; continue; }

		if is-drive-usage-too-high
		   then  suspend-jobs copy
			continue-jobs prune # may do nothing if backup running
		   else continue-jobs copy  # may do nothing if backup running
			[[ $is_multi_writer_drive ]] ||
			   { suspend-jobs prune; status=0; }
		fi
	done
	return $status
}
readonly -f suspended-prune-as-drive-usage-response

##############################################################################-
##############################################################################-
# Functions and variables used to prune old backup snapshots.
##############################################################################-
##############################################################################-

function count-rsyncs-using-resource() {
	local regex=$*

	[[ $drive_name == Z || $IfRun ]] && return 0
	return $(COLUMNS=999 ps l -u root | egrep -c "\brsync .*$regex")
}
readonly -f count-rsyncs-using-resource

# -----------------------------------------------------------------------------

function update-snapshots-ls {

	[[ ! $debug_opt ]] &&
	echo $snapshot_glob{,.links} | tr ' ' '\n' |
	    sort > $drive_log_dir/snapshots.ls
	return 0			# so can precede and follow by '&&'
}
readonly -f update-snapshots-ls

# -----------------------------------------------------------------------------

function _is-time-to-prune-drive() {
	local dir=${1:-$drive_dir}

	[[ ! $is_cron || $is_regression_test ]] && return 0 # run by a person?

	[[ $(date '+%H') == 00 ]] && return 0 # time for our daily prune?

	is-drive-usage-too-high   && return 0 # desparately need a prune?

	set -- $dir/*.rm
	[[ $# != 0 ]] && return 0	# have partially-deleted snapshots?

	local pruned_TS=$dir/$pruned_timestamp

	[[ ! -e $pruned_TS ]] && return 0 # never finished a prune?
	[[ $pruned_TS -ot $config_file   ]] && return 0 # newer config?
	[[ $pruned_TS -ot $exclude_file  ]] && return 0 # newer excludes?
	[[ $(find $pruned_TS ! -mtime 0) ]] && return 0	# not pruned recently?

	return 1			# not time to prune
}
readonly -f _is-time-to-prune-drive

# ----------------------

function _should-run-prune {

	[[ ! $is_update ]] || return 0	# for update, we just rmdir empty dirs

	# the following logic is odd, it ensures real-user's request is honored

	if [[ $is_cron ]]
	   then suspended-prune-as-drive-usage-response && return 1
	   else # if user changed backup_period or prune-rate, need to rescan
		kill-job-on-drives prune # kill old job, we'll be new job
	fi

	lock prune || { suspended-prune-as-drive-usage-response; return 1; }

	if [[ $is_cron ]]
	   then _is-time-to-prune-drive || { unlock prune; return 1; }
	   else # this could suspend ourself, which is OK ...
		suspended-prune-as-drive-usage-response # real person, can wait
	fi

	return 0
}
readonly -f _should-run-prune

# -----------------------------------------------------------------------------

function sudo-unless-dir-writable() {
	[[ $1 == -n ]] && { local sudo_opt=$1; shift; } || local sudo_opt=
	local path=${!#}

	[[ $path == */* ]] && local dir=${path%/*} || local dir=.
	if [[ -w $dir ]]
	   then "$@"
	   else sudo $sudo_opt "$@"
	fi
}
readonly -f sudo-unless-dir-writable

# ---------------------------------

_rm-pruned-snapshots() {
	local snapshots_file=$1

	local snapshot

	assert-drive_dir-writable $PWD

	suspend-tracing
	set -- $(< $snapshots_file)
	rm $snapshots_file

	[[ $# != 0 && ! $is_update ]] &&
	if (( $log_level >= 2 ))
	   then [[ $debug_opt ]] ||
		log "will prune these snapshots: " $*
	   else $IfRun \
		log "pruning $# snapshots: will rename to *.rm for deletion"
	fi

	if [[ $is_update && $debug_opt ]]
	   then local sudo=sudo-unless-dir-writable
	   else local sudo=
	fi

	# first, rename snapshots to be pruned, so can see the pruning backlog
	for snapshot
	    do	[[ $is_update && $debug_opt ]] ||		   # speedup
		count-rsyncs-using-resource  $snapshot || continue # in use?
		[[ $snapshot != *.rm && ! -e $snapshot/.keep ]] &&
		[[ -e $snapshot ]] || continue
		if [[ $is_update ]]
		   then  $sudo mv $verbose_opt $snapshot $snapshot.rm
		   else $IfRun mv	       $snapshot $snapshot.rm
		fi
	done

	if [[ $is_update ]]
	   then set -- *.partial.rm	# some from update, some from pruning
		[[ $# != 0 ]] && $sudo rmdir --ignore-fail-on-non-empty $*
		restore-tracing
		return
	fi

	update-snapshots-ls

	set -- $snapshot_glob*.rm
	local snapshot_basenames=$*
	restore-tracing

	if [[ ! -d latest ]]
	   then set -- $snapshot_glob # only the successful snapshots
		[[ -d ${!#} ]] && $IfRun rm -f latest &&
		$IfRun ln -s $(basename ${!#}) latest
	fi

	suspend-tracing
	# put newest ones first, since they have the most hardlinks.
	# use absolute paths, so the 'ps' output is more clear.
	set -- $(echo $drive_dir/*.rm | tr ' ' '\n' | sort -r)
	local number_pruned_snapshots=$#
	restore-tracing number_pruned_snapshots

	$Trace
	# just prune subdirs containing files with massive # of hard-links;
	# except too-high drive usage is more critical than "Too many files".
	set-FS_type--from-path $PWD
	case ${FS_type,,} in
	    ( xfs | btrfs )		# any FS that supports a zillion links
		hard_link_dirs= ;;
	esac
	[[ ${hard_link_dirs-} ]] && ! is-drive-usage-too-high $drive_dir &&
	for snapshot
	    do	local subdir
		for subdir in $hard_link_dirs
		    do	$IfRun rm -rf $snapshot$subdir
		done
		suspend-tracing
	done
	restore-tracing

	# finally, prune the rest of the contents of the *.rm snapshots
	for snapshot
	    do	$IfRun rm -rf $snapshot
		suspend-tracing
	done
	restore-tracing

	update-snapshots-ls

	(( $number_pruned_snapshots > 0 )) &&
	if (( $log_level >= 3 ))
	   then [[ $debug_opt ]] ||
	        log "deleted these pruned snapshots: $snapshot_basenames"
	   else $IfRun \
		log "deleted $number_pruned_snapshots *.rm pruned snapshots"
	fi

	local pruned_TS=$drive_dir/$pruned_timestamp
	[[ $drive_name == Z ||		# regression test?
	   ( ! $debug_opt &&		# ... too slow for real drive
	     # very slow: only run if exclude.txt changed since our last run
	     ( ! -e $pruned_TS ||
		    $pruned_TS -ot $exclude_file ) ) ]] &&
	{
	# prune exclude-globs from _all_ snapshots, very slow
	local exclude_glob file
	for snapshot in $drive_dir/$snapshot_glob*
	    do	[[ $snapshot == *.rm ]] && continue
		grep '^ */' $exclude_file | fgrep -v '**' |
		while read exclude_glob
		    do	set -- $snapshot$exclude_glob
			for file	# can have SPACEs, need to quote it
			   do	[[ -e "$file" ]] && echo "$file"
			done
		done
		suspend-tracing
	done | tr '\n' '\0' | xargs -0 -r $IfRun rm -r # -0: files with SPACEs
	}
	restore-tracing

	$IfRun log "pruned exclude-globs from _all_ snapshots"

	$IfRun sync --file-system $drive_dir &> /dev/null # maybe not supported
}
readonly -f _rm-pruned-snapshots

# --------------------------------------------------------------------
# vars & funcs that implement snapshot date-time format, and pruning #
# --------------------------------------------------------------------

# snapshot basename format is Year-Mo-Da,Hr, all implemented in this section;
#    to implement snapshot_date_time_separator, search for: ,00 ,?? ,$ ,/

readonly     snapshot_glob="[1-9][0-9][0-9]?-??-??,??" # Year-Mo-Da,Hr
readonly max_snapshot_glob="9999-12-31,23"	       # max supported value
readonly snapshot_day_glob=${snapshot_glob%,??}	       # Year-Mo-Da
set-new_name() { new_name=$(echo $1 | sed -r 's/-/,/;s/^(..)(..)/20\1-\2-/'); }
readonly     snapshot_regex=${snapshot_glob//\?/.}
readonly snapshot_day_regex=${snapshot_regex%,??}

set-date_time() { date_time=$(date '+%Y-%m-%d,%H' "$@"); }
set-day--from-secs() {       day=$(date '+%Y-%m-%d' -d "@$1" ); }
set-seconds--from-snapshot() {
	snapshot_date_time=$1

	snapshot_date_time=${snapshot_date_time##*/}	# basename
	snapshot_date_time=${snapshot_date_time%%.*}	# toss .* suffix
	snapshot_date_time=${snapshot_date_time/,/ }:00	# ,hours -> " hours:00"
	seconds=$(date '+%s' -d "$snapshot_date_time")
}
readonly -f set-date_time set-day--from-secs set-seconds--from-snapshot

# --------------------------------------------

shorten-date() {
	case $1 in
	    (  hour ) sed 's/,..$//' ;;	# strip time from snapshot's date-time
	    (   day ) sed 's/-..$//' ;; # strip day from snapshot's date
	    ( month ) sed 's/-..$//' ;; # strip month from year-month
	    (  year ) sed   's/.$//' ;; # turn year into decade
	esac | uniq
}
readonly -f shorten-date

declare -r -A type2date_suffix_glob=(
	 [NONE]=""
	 [hour]=",??"
	  [day]="-??,??"
	[month]="-??-??,??"
	 [year]="?-??-??,??"
)
[[ ${snapshot_glob%${type2date_suffix_glob[year]}} != \
   "$snapshot_glob" ]] ||
	abort "snapshot_glob has to end with type2date_suffix_glob[year]"

set-prune_glob() {
	local type=$1 glob=$2

	local date_suffix_glob=${type2date_suffix_glob[$type]}
	local date_prefix_glob=${snapshot_glob%$date_suffix_glob}
	case $type in
	   (  hour ) local date_suffix_type=NONE  ;;
	   (   day ) local date_suffix_type=hour  ;;
	   ( month ) local date_suffix_type=day   ;;
	   (  year ) local date_suffix_type=month ;;
	esac
	date_suffix_glob=${type2date_suffix_glob[$date_suffix_type]}
	prune_glob=$date_prefix_glob$glob$date_suffix_glob{,.*}
}
readonly -f set-prune_glob

readonly valid_backup_periods="1 2 4 8 12 24" # also in configure.sh comment

declare -r -A backup_period2minimal_snapshot_glob=(
    [1]="$snapshot_glob"
    [2]="$snapshot_day_glob,?[02468]"
    [4]="$snapshot_day_glob,{[02][048],1[26]}"
    [8]="$snapshot_day_glob,{00,08,16}"
   [12]="$snapshot_day_glob,{00,12}"
   [24]="$snapshot_day_glob,00"
)
#
# the [hour] chunks are the complement of the previous map's values
is-set        type2prune_type_globs ||	# custom version in $config_file?
declare -r -A type2prune_type_globs=(
# the ones these globs skip: hour=00, day=01, month=01, year=00
# period after prune: 2                4                 ~8          ~12   all
   [hour]=",?[13579]         ,{[02][26],1[048]}       ,{04,20}    ,{08,16} ,12"
    [day]="-{?[3579],[1-3]1} -{[02][26],1[048],30} -{04,12,20,28} -{08,24} -16"
  [month]="-{0[3579],11}          -{02,08,12}         -{04,10}       -06"
   [year]="  [13579]                 {2,6}              {4,8}"
)

function set-type2date_span {

    type2date_span=(
	 [hour]=$days_per_span_for_hour_prune
	  [day]=$months_per_span_for_day_prune
	[month]=$years_per_span_for_month_prune
	 [year]=$decades_per_span_for_year_prune
    )
}
readonly -f set-type2date_span

# ----------------------------------------------------------------------------
# end of: vars & funcs that implement snapshot date-time format, and pruning #
# ----------------------------------------------------------------------------

declare -A backup_period2minimal_snapshot_regex
#
for _period in ${!backup_period2minimal_snapshot_glob[*]}
    do	  value=${backup_period2minimal_snapshot_glob[$_period]}
	value=${value//\?/.}
	value=${value//\{/(}
	value=${value//\}/)}
	value=${value//,/|}
	value=${value/|/,} 		# restore $snapshot_date_time_separator
	backup_period2minimal_snapshot_regex[$_period]=$value
done
unset _period
readonly backup_period2minimal_snapshot_regex

set-date_span-scaled() {

	date_span=$( echo "$date_span $pruning_span_scale_factor" |
		     awk '{ printf "%.0f\n", $1 * $2 }' )
}
readonly -f set-date_span-scaled

# --------------------------------------------

reverse-sorted-snapshot-basenames() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=

	echo $snapshot_glob*  |		# prune everything
	   tr ' ' '\n' | sort -u -r |
	   grep -v '\.rm$'		# _rm-pruned-snapshots handles *.rm
	$xtrace
}
readonly -f reverse-sorted-snapshot-basenames

# --------------------------------------------

_oldest_snapshot=

prune-type-to-file() {
	local type=${1%s} file_of_snapshots_to_prune=$2; shift 2
	set -- $(echo $* | tr ' ' '\n' | cut -d. -f1 | shorten-date $type)
	local remaining_reverse_sorted_snapshot_dates=$*

	local -A type2date_span
	set-type2date_span	# run after call to customize-config-variables
	local date_span=${type2date_span[$type]}
	set-date_span-scaled
	local prune_type_globs=${type2prune_type_globs[$type]}
	local date_suffix_glob=${type2date_suffix_glob[$type]}
	[[ $type == hour ]] && _oldest_snapshot=$drive_dir/${!#},00

	Trace 5 "\n==> $type prune <=="
	local -i period=$backup_period
	local prune_glob
	while set-popped_word--from-list prune_type_globs
	    do	local prune_type_glob=$popped_word
		set -- $remaining_reverse_sorted_snapshot_dates

		# might want to delete *all* the snapshots left to be pruned
		if [[ $date_span == 0 ]]
		   then shift	      # don't delete span we previously pruned
			for date
			    do	echo $date*
			done
			break

		fi

		Trace 4 "\n  LOOP $type: $# dates left: ${1-} ${2-} ... ${!#}"
		! _do-skip-newest-span-of-days $type || shift $date_span ||
		    shift $# # shift does nothing if try to shift more than $#
		remaining_reverse_sorted_snapshot_dates=$*
		local first_prune_date=${1-}
		[[ $first_prune_date ]] || break

		set-prune_glob $type "$prune_type_glob"
		TraceV 5 date_suffix_glob first_prune_date \
			  prune_type_glob prune_glob
		eval "set -- $prune_glob"
		Trace 5 "\n Matched  $# snapshots: ${1-} ${2-} ${3-} ... ${!#}"

		# skip over the snapshot prune-matches that aren't old enough
		set -- $(echo $* | tr ' ' '\n' | sort -r)
		while [[ $# != 0 ]]
		   do	[[ $1 == $drive_dir/[^1-9]* ]] && shift && continue
			local day_hour=${1##*/}
			local date=${day_hour%$date_suffix_glob*}
			[[   $date > $first_prune_date ]] || break
			shift
		done
		[[ -d ${1-} ]] || continue
		# delete all the old-enough prune matches
		Trace 5 "\nDeleting ~$# snapshots: $1 ${2-} ${3-} ... ${!#}"
		echo ${*%$_oldest_snapshot*} # don't delete oldest snapshot
	done >> $file_of_snapshots_to_prune

	echo $remaining_reverse_sorted_snapshot_dates
}
readonly -f prune-type-to-file

# ----------------------

function _do-skip-newest-span-of-days() {
	local type=$1

	[[ $type != hour* ]] && return 0

	# if $backup_period had been too short and we lengthened it,
	#   we delete recent snapshots that "shouldn't" have been created,
	#   by not shifting remaining-days until we've pruned the "spurious"
	if   (( period <=  1 )) ; then return 0
	elif (( period <=  2 )) ; then period=1
	elif (( period <=  4 )) ; then period=2
	elif (( period <=  8 )) ; then period=4
	elif (( period <= 24 )) ; then period=8
				  else period=24
	fi
	Trace 5 "period now $period, didn't shift"
	return 2			# higher than 'shift' error status
}
readonly -f _do-skip-newest-span-of-days

# ---------------------------------------------------------

# The locking & job-management policy is documented in front of function lock()

# for the goals of this function, see prune-variable comments in configure.sh
function prune-drive() {
	[[ $1 == -u ]] && { local is_update=$true; shift; } || local is_update=
	assert-not-option ${1-}
	local drive_name=$1 drive_dir

	suspend-tracing
	set-drive_name $drive_name
	set-drive_dir  $drive_name || return 1
	restore-tracing

	_should-run-prune || return 1

	set-priority prune

	local  snapshots_to_prune_file=$tmp_4
	rm -f $snapshots_to_prune_file

	cd_ $drive_dir	# so can safely kill job with: fuser -k -M $drive_dir

	$Trace
	set -- $(reverse-sorted-snapshot-basenames)
	# prune-type-to-file returns dates remaining, to check for more pruning
	set -- $(prune-type-to-file hour  $snapshots_to_prune_file $*)
	set -- $(prune-type-to-file day   $snapshots_to_prune_file $*);#$Trace
	set -- $(prune-type-to-file month $snapshots_to_prune_file $*);#set +x
	set -- $(prune-type-to-file year  $snapshots_to_prune_file $*)

	_rm-pruned-snapshots $snapshots_to_prune_file # it deletes the file
	rm -f $snapshots_to_prune_file

	[[ $is_update ]] && return 0

	$IfRun touch $drive_dir/$pruned_timestamp # touch even if did nothing

	unlock prune
}
readonly -f prune-drive

##############################################################################-
##############################################################################-
# Functions and variables used to create new backup snapshots.
##############################################################################-
##############################################################################-

# -----------------------------------------------------------------------------
# functions to setup --link-dest args to rsync
# -----------------------------------------------------------------------------

function _have-full-snapshot {

	set -- ${new_snapshot%/$snapshot_glob*}/$snapshot_glob
	[[ $# != 0 ]]
}
readonly -f _have-full-snapshot

# ---------------------------------

set-num_full_link_dests() {

	# need at least 2 --link-dest args in case the sysadmnin borked one,
	# and a few hours worth in case a file was deleted then recovered;
	# don't make this too large, it slows recovery from "Too many links"
	if (( $backup_period == 1 ))
	   then declare -g -i num_full_link_dests=4
	   else declare -g -i num_full_link_dests=2
	fi
}
readonly -f set-num_full_link_dests

# ----------------------

set-link_dest_opts() {
	local new_snapshot=$1; shift

	while [[ ! -d ${1-} || ${1-} == $new_snapshot* ]]
	   do	[[ $# != 0 ]] || return	# we might not have any snapshots
		shift
	done
	[[ -d ${1-} ]] || return

	set-num_full_link_dests

	suspend-tracing
	local -i goody_snapshots=0 links_snapshots=0 junky_snapshots=0
	_have-full-snapshot || junky_snapshots=-10 # big src, slow/flakey dst?
	local snapshot
	for snapshot in $*
	    do	[[ -d  $snapshot ]] || continue
		set -- $snapshot/*
		[[ $# != 0 ]] || continue # update's empty snapshot?
		# don't consider *.partial or *.links to be adequate;
		# rsync allows 20 --link-dest options max (10 per direction)
		case $snapshot in
		    (*.links) (( ++links_snapshots > 3 )) && continue ;;
		    (*.*    ) (( ++junky_snapshots > 2 )) && continue ;;
		    ( *     ) (( ++goody_snapshots > $num_full_link_dests )) &&
				 break ;;
		esac
		link_dest_opts="$link_dest_opts --link-dest=$PWD/$snapshot"
	done
	restore-tracing link_dest_opts
}
readonly -f set-link_dest_opts

# ------------------------------------------------------------------

set-link_dest_opts--for-run-backup() {
	local new_snapshot=${1##*/}

	suspend-tracing
	# want the .links snapshots too, so quickly recover from
	#    'Too many links' by just copying the file
	# want a .partial to get the latest stuff, but won't "count" it
	set -- $(echo $snapshot_glob{,.links,.partial} |
		 tr ' ' '\n' | sort -r)
	restore-tracing

	set-link_dest_opts $new_snapshot $*
}
readonly -f set-link_dest_opts--for-run-backup

# ------------------------------------------------------------------

set-link_dest_opts--for-copy-snapshot() {
	local new_snapshot=${1##*/}

	suspend-tracing
	# want the .links snapshots too, so quickly recover from
	#    'Too many links' by just copying the file
	# want a .partial to get the latest stuff, but won't "count" it
	set -- $(echo $snapshot_glob{,.links,.partial} |
		 tr ' ' '\n' | sort -r |
		 while  read  snapshot
		    do	[[   $snapshot < $new_snapshot ]] || continue
			echo $snapshot
		 done)
	restore-tracing
	set-link_dest_opts $new_snapshot $* # newest to oldest

	set -- $(echo $snapshot_glob{,.links,.partial} |
		 tr ' ' '\n' |
		 while  read  snapshot
		    do	[[   $snapshot > $new_snapshot ]] || continue
			echo $snapshot
		 done)
	restore-tracing
	set-link_dest_opts $new_snapshot $* # oldest to newest
}
readonly -f set-link_dest_opts--for-copy-snapshot

# -----------------------------------------------------------------------------
# misc functions to support run-rsync
# -----------------------------------------------------------------------------

set-excluded_hours() {

	set -- $(
	for hour
	    do	[[ $hour == 0?   ]] && hour=${hour#0}
		[[ $hour =~ ^0+$ ]] && continue # pruning needs midnight backup
		[[ $hour == *-*  ]] || { echo $hour; continue; }
		[[ $hour != *-*-* ]] || abort "bad $var_name range"
		[[ $hour != 0-* ]] ||abort "$var_name range can't start with 0"
		[[ $hour != *-0 ]] ||abort "$var_name range can't end with 0"
		first=${hour%-*} last=${hour#*-}
		if (( $first <= $last ))
		   then eval "echo {$first..$last}"
		   else eval "echo {$first..23} {1..$last}" # exclude midnight
		fi
	done
	)
	excluded_hours=$*
}
readonly -f set-excluded_hours

# ---------------------------------

function _is-time-to-run-backup {

	[[ ! $is_cron || $is_regression_test ]] && return 0 # run by a person?

	set -- $(date '+%k %M')
	local current_hour=$1 current_minute=$2

	(( $current_hour == 0 && $current_minute == 5 )) &&
	   update-snapshots-ls &&
	   ( $our_path w > $log_dir/cron-w.txt ) &

	# we're called more than hourly (to reset priorities, and to prune)
	(( $current_minute == 0 )) || [[ $debug_opt ]] || return 1

	set-excluded_hours $excluded_backup_hours
	is-arg_1-in-arg_2 $current_hour $excluded_hours && return 1
	(( $current_hour % $backup_period == 0 )) && return 0

	return 1
}
readonly -f _is-time-to-run-backup

# -------------------------------------------------------

set-hours--from-minutes() {
	if [[ $1 == -* ]]
	   then local decimal_digits_opt=$1  minutes=$2
	   else local decimal_digits_opt=-2  minutes=$1
	fi

	local division
	set-division $decimal_digits_opt $minutes 60
	hours=$division
}
readonly -f set-hours--from-minutes

set-hours--from-minutes 10
[[ $hours == 0.17 ]] || abort "10 minutes != $hours hours"

# ----------------------

set-seconds--from-msecs() {
	if [[ $1 == -* ]]
	   then local decimal_digits_opt=$1  msecs=$2
	   else local decimal_digits_opt=-2  msecs=$1
	fi

	local division
	set-division $decimal_digits_opt $msecs 1000
	seconds=$division
}
readonly -f set-seconds--from-msecs

# ---------------------------------

readonly rsync_time_subdir=stats/rsync-minutes

archive-rsync-time-data() {

	rsync_time_dir=$drive_log_dir/$rsync_time_subdir
	mkdir -p $rsync_time_dir
	cd $rsync_time_dir &&
	set -- *.txt &&
	if [[ $# != 0 ]]
	   then set-date_time -r .
		dir=.${date_time%,*}
		$IfRun mkdir -p $dir
		$IfRun mv -v *.txt $PWD/$dir/
	fi
	cd $OLDPWD
}
readonly -f archive-rsync-time-data

# ----------------------

is-set	      days_to_keep ||		# custom version in $config_file?
declare -r -i days_to_keep=3		# ensure more than weekend-only data

record-rsync-time() {
	local snapshot=${1##*/}

	local -i minutes=$(( ($SECONDS + 30) / 60 ))
	set-hours--from-minutes $minutes
	rsync_hours=$hours

	# $rsync_time_subdir/* used to set backup_period, so don't save copy
	[[ ! $is_copy_snapshot ]] || return

	local file=$drive_log_dir/$rsync_time_subdir/$snapshot.txt
	$IfRun mkdir -p ${file%/*}
	local link=$log_dir/$rsync_time_subdir/$drive_name
	$IfRun mkdir -p ${link%/*}
	[[ -e $link ]] ||
	$IfRun ln -s ../../$drive_name/$rsync_time_subdir $link

	local cmd="echo $minutes > $file"
	if [[ $debug_opt ]]
	   then echo "$cmd"
	   else eval "$cmd"
	fi || return 1

	local -i number_files_per_day=24/$backup_period
	local -i number_files_to_keep=$number_files_per_day*$days_to_keep
	set -- ${file%/*}/$snapshot_glob.txt
	while (( $# > $number_files_to_keep ))
	    do	$IfRun rm $1
		shift
	done
}
readonly -f record-rsync-time

# -------------------------------------------------------

_links-error-msg() {
	local msg=$*

	# since contents of $() are run in subshell, have to echo results
	local -i max_src_links=$(
	local -i max_src_links=0
	bzcat $log | tr -d '"' | cut -d' ' -f3 |
	while read dst_file
	    do	src_file=${dst_file#$drive_dir/$snapshot_glob.partial}
		[[ -f $src_file ]] || continue
		set -- $(ls -l $src_file)
		((   $max_src_links >= $2 )) && continue
		      max_src_links=$2
		echo $max_src_links
	done | tail -n1
	)

	local -i link_dest_wait=$(( num_full_link_dests * backup_period ))
	set -- *.rm
	msg="$msg; Worst case, tried to add $max_src_links links to a snapshot file; these files will eventually appear in a new snapshot after $link_dest_wait hours; $# snapshots waiting to be pruned, newer prunes subtract ~$max_src_links links"

	[[ $hostname != eleanor ]] &&
	msg="$msg; Edit prune variables in $config_file to reduce # snapshots"

	echo "$msg"
}
readonly -f _links-error-msg

# ---------------------------------

_handle-rsync-results() {
	local new_snapshot=$1 status=$2 log=$3

	if [[ -s $log ]]
	   then [[ $IfRun ]] && { bzcat $log; rm $log; }
	   else rm -f $log
	fi

	# uncomment next line to debug link_fail_count code with -d option
	# echo 'link failed: Too many links (31)' | bzip2 >> $log; status=31

	local error_msg=

	if is-arg_1-in-arg_2 $status "$successful_rsync_exit_statuses"
	   then $IfRun mv $new_snapshot.partial $new_snapshot &&
		[[ $new_snapshot != *.links ]] &&
		set -- $snapshot_glob && [[ $# != 0 ]] &&
		$IfRun rm -f latest && $IfRun ln -s ${!#} latest &&
		update-snapshots-ls
		record-rsync-time $new_snapshot
		[[ $new_snapshot == *,00 || $log_level -gt 0 ||
		   ! $is_cron || $debug_opt ]] &&
		$IfRun log \
	  "created $new_snapshot (at $priority priority) in $rsync_hours hours"
	   else set -- $(bzcat $log 2>/dev/null | # might be empty file
			 grep -c ': Too many links (31) *$')
		local  link_fail_count=$1 # see test, above
		if (( $link_fail_count == 0 ))
		   then local err=$(bzcat $log | tail -n2)
			((  $(echo "$err" | wc -l) > 1 )) &&
			err=$(echo "$err" | sed '1s/.*: //' |
						tr '\n' '|' | sed 's/|/; /')
			error_msg="...; ${err}rsync exit status=$status"
		   else error_msg="$link_fail_count 'Too many links'"
			error_msg=$(_links-error-msg "$error_msg")
			$IfRun mv $new_snapshot.partial $new_snapshot.links
			record-rsync-time $new_snapshot
		fi
		if is-arg_1-in-arg_2 $status "$no_log_rsync_exit_statuses" ||
		   (( $(bzcat $log | wc -l) == 0 ))
		   then rm -f $log
			error_msg="$error_msg; Partial snapshot still useful"
		   else error_msg="$error_msg; See $log"
		fi
	fi

	if [[  $error_msg ]]
	   then	[[ $Trace || $drive_name == Z ]] && # Z = debug "drive"
		log "$error_msg" ||
		log "$error_msg" |& tee -a /dev/stderr | sed 's/; /\n/g' |
		   $IfRun mail -s "$our_name: errors" $sysadmin_email_addresses
	   else rm -f $log
	fi
}
readonly -f _handle-rsync-results

# ----------------------

function run-rsync() {
	if [[ $1 == -c ]]
	   then shift
		local is_copy_snapshot=$true
	   else local is_copy_snapshot=$false
	fi
	assert-not-option ${1-}
	local dst_snapshot=${!#}
	local src_dirs=${*%$dst_snapshot}

	local date_time=${dst_snapshot##*/}
	local log=$tmp_dir/$drive_name-${date_time%%.*}.bz2

	assert-drive_dir-writable ${dst_snapshot%/*}

	if [[ $dst_snapshot == *.partial ]]
	   then local partial_dst=$dst_snapshot
	   else local partial_dst=$dst_snapshot.partial
		# if we (partially) created this snapshot earlier, reuse it
		local suffix
		for   suffix in '' '.links'
		    do	local  useful_dst=$dst_snapshot$suffix
			[[ -d $useful_dst ]] &&
			   $IfRun mv $useful_dst $partial_dst && break
		done
	fi

	[[ ! $is_copy_snapshot ]] &&   # copy keeps original mtime
	{		     # ensure $dst_snapshot has current time
	[[ $debug_opt ]] ||  # use 'sleep 9' to wait for rsync to modify mtime
	until [[ -e $partial_dst || -e $dst_snapshot ]] ; do sleep 9; done
	[[ -d $partial_dst ]] && $IfRun \
	touch $partial_dst		# in case we crash before next 'touch'
	} &

	suspend-tracing
	local link_dest_opts=
	if [[ ! $is_copy_snapshot ]]
	   then set-link_dest_opts--for-run-backup    $dst_snapshot
	   else set-link_dest_opts--for-copy-snapshot $dst_snapshot
	fi
	restore-tracing link_dest_opts

	shopt -u nullglob   # nullglob disappears --exclude=$drive_dir_prefix*

	# drive_dir_prefix and rsync_backup_opts come from $config_file
	local relative_opt= excludes=
	[[ ! $is_copy_snapshot ]] &&
	relative_opt=--relative  excludes="--exclude=$drive_dir_prefix*/*
					   --exclude-from=$exclude_file"
	SECONDS=0			# time the rsync
	$Trace
	$IfRun rsync $rsync_backup_opts	\
		     $our_rsync_opts	\
		     $relative_opt	\
		     $link_dest_opts	\
		     $excludes		\
			$src_dirs $partial_dst/ |& bzip2 -9 > $log
	local status=${PIPESTATUS[0]}	# https://stackoverflow.com/a/20738063

	shopt -s nullglob

	[[ ! $is_copy_snapshot ]] &&
	$IfRun touch $partial_dst	# 'when we finished', not mdate of src

	_handle-rsync-results $dst_snapshot $status $log

	$IfRun sync --file-system $dst_snapshot* &> /dev/null # optional

	return $status
}
readonly -f run-rsync

# -------------------------------------------------------

function run-backup-rsync() {
	local date_time=$1

	set-priority backup

	local new_snapshot=$drive_dir/$date_time

	cd_ $drive_dir	# so can safely kill job with: fuser -k -M $drive_dir

	suspend-tracing
	eval "run-rsync $dirs_to_backup $new_snapshot" # might need globbing
	restore-tracing				       # this preserves $?
}
readonly -f run-backup-rsync

# ----------------------

# The locking & job-management policy is documented in front of function lock()

function run-backup() {
	local drive_name=$1 drive_dir

	set-drive_name $drive_name
	set-drive_dir  $drive_name || return 1

	local date_time
	set-date_time

	if ! _is-time-to-run-backup
	   then $IfRun create-jobs prune
		return
	fi
	if [[ $is_multi_writer_drive ]]
	   then $IfRun create-jobs prune
	fi

	# grab backup lock before prune, so don't suspend prune if the sysadmin
	# suspended the backup and continued the prune (is it still relevant?)
	lock -w backup || return 1	# wait for lock, so don't skip backup

	[[ ! $is_multi_writer_drive ]] &&
	suspend-jobs copy prune

	run-backup-rsync $date_time
	local status=$?

	unlock backup

	[[ ! $is_multi_writer_drive ]] &&
	$IfRun create-jobs prune	# also manages copy job

	return $status
}
readonly -f run-backup

##############################################################################-
##############################################################################-
# Functions and variables used to copy snapshots between backup drives.
##############################################################################-
##############################################################################-

assert-not-in-cron-jobs() {

	local name  drive_name
	for name
	    do	set-drive_name $name
		[[ $drive_name =~ ^$drive_name_regex$ ]] || continue
		local regex=drive_name_regex
		$IfRun abort "remove $drive_name from $regex= in $config_file"
	done
}
readonly -f assert-not-in-cron-jobs

# -----------------------------------------------------------------------------

function bad-copy() {
	local msg=$*

	[[ $is_quiet || $is_update || $debug_opt ]] ||
	   abort "$msg; use -q to not abort"

	[[ ! $debug_opt || $is_update ]] || echo "copy-snapshot: $msg"

	return 1
}
readonly -f bad-copy

# ---------------------------------

declare -A drive_name2backup_type

set-backup_type() {
	local drive_name=$1	  # fastest if it's a drive_name not drive_dir

	backup_type=${drive_name2backup_type[$drive_name]-}
	[[ $backup_type ]] && return	# was it in the cache?

	[[   ${custom_config_var_assignments-} ]] &&
	local $custom_config_var_assignments # don't trash caller's values
	set-drive_name $drive_name	# calls customize-config-variables
	backup_type="$dirs_to_backup|$exclude_file|$extra_excludes"
	drive_name2backup_type[$drive_name]=$backup_type # cache it
}
readonly -f set-backup_type

# ---------------------------------

function matches-dst_backup_type() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local drive_dir=$1 drive_name

	_set-drive_name $drive_dir
	set-backup_type $drive_name
	$xtrace
	[[ $backup_type == $dst_backup_type || $debug_opt ]]
}
readonly -f matches-dst_backup_type

# ----------------------

function is-src_snapshot-useful() {
	local src_snapshot=$1

	[[ -d $src_snapshot ]] || bad-copy "no snapshot '$1'" || return 1
	local  src_basename=${src_snapshot##*/}
	[[ $src_basename == $snapshot_glob ||
	   $src_basename == $snapshot_glob.links ]] ||
	   bad-copy "$src_snapshot is not a reliable snapshot" || return 1
	[[ $src_basename =~ $dst_minimal_snapshot_regex(|\..*) ]] ||
	   bad-copy "$src_snapshot doesn't fit $dst_name's backup_period=" ||
	   return 1

	matches-dst_backup_type ${src_snapshot%/*} && return 0

       bad-copy "$src_snapshot & $dst_drive_name backup characteristics differ"
}
readonly -f is-src_snapshot-useful

# ---------------------------------

function is-dst_snapshot-needed() {
	local dst_snapshot=$1

	set -- ${dst_snapshot%.*}*	# a version might exist
	[[ $# == 0    ]] && return 0
	[[ $# == 1    ]] ||
	   bad-copy "'$*' exist, (mv then) delete worst one" || return 1
	[[ $1 != *.rm ]] ||
	   bad-copy "destination is waiting to be pruned" || return 1

	local ext=${1##*.} junk_dir=${dst_snapshot%/*}/.junk
	[[ ! -d $1 ]] &&
	   $IfRun mv $1 $junk_dir/ && { warn "junk in $junk_dir"; return 0; }
	! [[ ${1##*/} != *.* || $ext == links || $ext == partial ]] &&
	   $IfRun mv $1 $junk_dir/ && { warn "junk in $junk_dir"; return 0; }

	[[ ${1##*/} != *.* && ${dst_snapshot##*/} == *.* ]] && {
	[[ ! $is_quiet ]] && log "${dst_snapshot##*/} not needed"; return 1; }
	[[ $1 != $dst_snapshot ]] && return 0
	[[ $is_quiet || $action == update* ]] ||
	    log "$dst_snapshot already exists"; return 1
}
readonly -f is-dst_snapshot-needed

# ---------------------------------

function copy-snapshot() {
	[[ $1 == -s* ]] && { local src=${1#-s}   ; shift; } || local src=
	[[ $1 == -q ]] && { local is_quiet=$true ; shift; } || local is_quiet=
	[[ $1 == -u ]] && { local is_update=$true; shift; } || local is_update=
	assert-not-option -o ${1-}
	[[ $src     ]] && set -- $src $1
	(( $# >= 2  )) || abort-function "src(s) dst_drive_name"
	local src_snapshot=${1%/} dst_drive_name=${!#}
	local src_snapshots=${*%$dst_drive_name}
	src_snapshot=${src_snapshot%/.keep}
	local drive_name=$drive_name drive_dir=${drive_dir-} # protect caller
	copy_snapshot_args=		# holds result when $is_update

	$Trace
	[[ ${dst_minimal_snapshot_regex-} ]] || { # don't repeat dst setup
	set-drive_dir $dst_drive_name || abort "$dst_drive_name not mounted"
	dst_dir=$drive_dir
	local regex=${backup_period2minimal_snapshot_regex[$backup_period]}
	dst_minimal_snapshot_regex=$regex
	set-backup_type $dst_drive_name
	dst_backup_type=$backup_type	   ; }

	[[ $src_snapshot == /* && ! -L $src_snapshot ]] || {
	# the above criteria is alway satisfied by update, so we're 'copy' ...
	local absolute_path
	set-absolute_path $src_snapshot
	src_snapshot=$absolute_path
	src_snapshots=$absolute_path ; } # ... so only a single src

	local dst_snapshot=$dst_dir/${src_snapshot##*/}

	is-dst_snapshot-needed $dst_snapshot || return 1
	is-src_snapshot-useful $src_snapshot || return 1

	TraceV 2 src_snapshot dst_snapshot

	[[ ${debug_copy-} ]] &&
	    echo "copy $src_snapshot/\$dirs to $dst_dir/" && return 0

	[[ $is_update ]] &&
	    copy_snapshot_args="$src_snapshots $dst_snapshot" && return 0

	copy-snapshot-rsync $src_snapshot $dst_snapshot
}
readonly -f copy-snapshot

# -------------------------------------------------------

# The locking & job-management policy is documented in front of function lock()

# The following is similar to the second half of run-backup-rsync;
# it's called by copy-snapshot and update-drive, to do the real work.
function copy-snapshot-rsync() {
	local src_snapshot=$1 dst_snapshot=$2

	suspend-jobs prune # hourly cron will continue prune if drive space low

	set-priority copy

	cd_ ${dst_snapshot%/*}	     # can kill job with: fuser -k -M $dst_dir
	run-rsync -c $src_snapshot/. $dst_snapshot; local status=$?
	cd_ $OLDPWD
	return $status
}
readonly -f copy-snapshot-rsync

# -----------------------------------------------------------------------------

declare -A drive_name2do_suspend

set-drive_name2do_suspend() {

	[[   ${custom_config_var_assignments-} ]] &&
	local $custom_config_var_assignments # for customize-config-variables

	local drive drive_name
	for drive in $(list-drive-dirs -a)
	    do	_set-drive_name $drive
		suspend-tracing
		customize-config-variables $drive_name
		restore-tracing
		if [[ $is_multi_writer_drive ]]
		   then local do_suspend=0
		   else local do_suspend=1
		fi
		drive_name2do_suspend[$drive_name]=$do_suspend
	done
}
readonly -f set-drive_name2do_suspend

# ---------------------------------

# the "fastest" snapshot is on drive that's: 1. not suspendable; else 2. not
# running a backup; else 3. not being pruned; else 4. hosting the smallest
# number of rsync commands.
fastest-snapshots() {

	local drive_name drive_dir	       # don't change caller's values

	local snapshot
	for snapshot
	    do	_set-drive_name $snapshot
		local do_suspend=${drive_name2do_suspend[$drive_name]}

		local -i writer_count=0
		for writer in backup copy prune
		    do	have-job $writer && writer_count+=1
		done

		_set-drive_dir
		count-rsyncs-using-resource " $drive_dir/"
		local rsync_count=$?

		local ss=$snapshot
		echo "$do_suspend|$writer_count|$rsync_count|$ss"
	done | sort -t\| -n |		# numeric sort
	# cat; return			# uncomment to debug with action 'test'
	cut -d\| -f4
}
readonly -f fastest-snapshots

# --------------------------------------------

set-excluded_drive_dirs_regex() {

	if [[ $debug_opt && ${flakey_drive_names_regex-} ]]
	   then excluded_drive_dirs_regex=$flakey_drive_names_regex
	   else excluded_drive_dirs_regex=NoThInG
	fi
}
readonly -f set-excluded_drive_dirs_regex

# --------------------------------------------

sorted-useful-srcs() {
	[[ $1 == -s* ]] && { src_names_regex=${1#-s}; shift; }
	assert-not-option ${1-}
	[[ $# == 1   ]] || abort "need to specify one drive name"

	suspend-tracing
	set-drive_name $1
	set-drive_dir  $drive_name
	restore-tracing

	if [[ ${src_names_regex-} ]]
	   then   if [[ $is_drive_name_upper_cased ]]
		   then src_names_regex=${src_names_regex^^}
		elif  [[ $is_drive_name_capitalized ]]
		   then src_names_regex=${src_names_regex^} # fails if regex
		fi
	fi

	set-backup_type $drive_name
	set-excluded_drive_dirs_regex

	dst_backup_type=$backup_type
	local drive_dirs=$(
		set -- $(
		# -a so include drives excluded from backups
		set -- $(list-drive-dirs -a | fgrep -v -x $drive_dir |
				egrep -v "\b$excluded_drive_dirs_regex$" |
				egrep "$drive_dir_prefix${src_names_regex-.}")
		for drive_dir
		    do	matches-dst_backup_type $drive_dir && echo $drive_dir
		done
		)
		echo $*
	)

	period=$backup_period
	min_snapshot_glob=${backup_period2minimal_snapshot_glob[$period]}
	[[ $min_snapshot_glob ]] ||
	    abort "backup_period2minimal_snapshot_glob is broken"

	set -f
	set -- $(echo root$drive_dir_prefix$drive_name_regex/snap |
		 tr / ' ')
	set +f
	let snapshot_key=$# drive_name_key=$#-1
	local sort_key_args="--key=$snapshot_key --key=$drive_name_key"

	TraceV 1 drive_dirs min_snapshot_glob sort_key_args

	cd $drive_dir || exit 1	# so can kill job with: fuser -k -M $drive_dir

	$Trace

	for dir in $drive_dirs
	    do	suspend-tracing
		echo $dir/$min_snapshot_glob{,.links}   # useful ones
		echo $dir/$snapshot_glob{,.links}/.keep # ones never pruned
		echo $dir/$max_snapshot_glob # token to terminate loop
		restore-tracing
	done | tr ' ' '\n' |
	sort --field-separator=/ $sort_key_args # > /dev/null; abort "test"
}
readonly -f sorted-useful-srcs

# -----------------------------------------------------------------------------

remove-empty-partial-snapshots() {
	local drive_dir=$1

	cd_ $drive_dir
	set -- *.partial
	[[ $# != 0 ]] &&
	# 'sudo -n' because we're called by 'watch' and 'w'
	sudo-unless-dir-writable -n rmdir $* &> /dev/null # optional
	cd_ $OLDPWD
}
readonly -f remove-empty-partial-snapshots

# ---------------------------------

cleanup-after-updates() {
	local drive_dirs=${*:-$(list-drive-dirs -a)}

	local drive_dir drive_name	# protect caller's values
	for drive_dir in $drive_dirs
	    do	_set-drive_name $drive_dir
		set-lock_path copy	# update could be running
		(
		sudo-lockpid -o $lock_path &> /dev/null &&	  {
		$IfRun remove-empty-partial-snapshots $drive_dir
		sudo-lockpid -r $lock_path			; }
		) &			# do them in parallel
	done
	wait				# 'w' wants us to have finished
}
readonly -f cleanup-after-updates

# --------------------------------------------

wait-for-full-snapshots() {
	local min_full_snapshots=$1

	while true
	   do	set -- $drive_dir/$snapshot_glob
		(( $# > $min_full_snapshots )) && return # an extra one: safety
		sleep 1h
	done
}
readonly -f wait-for-full-snapshots

# ---------------------------------

set-srcs_dst_file() {

	srcs_dst_file=$tmp_dir/$_our_name-update-$drive_name.args
}
readonly -f set-srcs_dst_file

# ----------------------

update-drive() {
	set-drive_name ${!#}		# sorted-useful-srcs handles options
	set-drive_dir $drive_name

	# need to grab the copy lock in debug mode, pruning runs mv & rmdir
	IfRun= lock copy > /dev/null || exit 1	# can run for days
	suspended-prune-as-drive-usage-response # we might get suspended

	remove-empty-partial-snapshots $drive_dir

	# make sure that we're not using partially-created snapshots
	# in rsync's --link-dest options
	set-num_full_link_dests
	wait-for-full-snapshots $num_full_link_dests

	if [[ $UID == 0 ]]
	   then local sudo=
	   else local sudo=sudo-unless-dir-writable
	fi

	set-srcs_dst_file
	local date_time prev_date_time=
	local src_snapshot src_snapshots= is_keep
	local -A date_time2is_keep
	sorted-useful-srcs "$@" |	# this checks/sets drive_* globals
	while read src_snapshot
	    do	if [[ $src_snapshot == */.keep ]]
		   then src_snapshot=${src_snapshot%/.keep}
			is_keep=$true
		   else is_keep=$false
		fi
		[[ -d $src_snapshot ]] || continue
		# oddness: we get multiple src snapshots with the same date
		date_time=${src_snapshot##*/}
		date_time=${date_time%%.*}
		[[ $is_keep ]] && date_time2is_keep[$date_time]=$true
		if [[  $prev_date_time &&
		       $prev_date_time != $date_time ]]
		   then prev_date_time=$date_time # new date, process prev ones
		   else [[ $prev_date_time ]] ||
			prev_date_time=$date_time
			[[ -d $src_snapshot ]] &&
			src_snapshots+=" $src_snapshot" # put SPACE in front
			continue
		fi

		[[ $src_snapshots ]] &&
		copy-snapshot -u $src_snapshots $drive_name # loads a var
		 src_snapshots=$src_snapshot # prepare to process new date
		set -- $copy_snapshot_args   # variable set by copy-snapshot
		[[ $# != 0 ]] || continue    # src might not have been needed

		local    dst_snapshot=${!#}
		date_time=${dst_snapshot##*/}
		date_time=${date_time%%.*}
		[[ ! -d $dst_snapshot.links ]] &&
		$sudo mkdir $verbose_opt -p $dst_snapshot.partial >&2 #to prune
		[[ ${date_time2is_keep[$date_time]-} ]] &&
		    echo > $dst_snapshot.partial/.keep && [[ $verbose_opt ]] &&
		echo touch $dst_snapshot.partial/.keep >&2
		echo "$@"
	done > $srcs_dst_file
	[[  -s $srcs_dst_file ]] || { rm $srcs_dst_file; return 1; }

	prune-drive -u $drive_name	# just prunes empty .partial dirs

	set-drive_name2do_suspend
	local args dst_snapshot=
	while read args
	    do	[[ $args ]] || abort "blank line in $srcs_dst_file"
		set -- $args
		local   dst_snapshot=${!#}
		[[ -d  $dst_snapshot ]] && continue # undeleted?
		set -- $dst_snapshot*
		[[ $# != 0 ]] || continue # was it pruned away?
		set -- $(fastest-snapshots ${args%$dst_snapshot}) # pass srcs
		[[ $# != 0 ]] && $IfRun copy-snapshot-rsync $1 $dst_snapshot
	done   <  $srcs_dst_file
	$IfRun rm $srcs_dst_file

	remove-empty-partial-snapshots $drive_dir

	IfRun= unlock copy
}
readonly -f update-drive

##############################################################################-
##############################################################################-
# Run multiple jobs, each in a separate session (unique PGID, stored in lock).
##############################################################################-
##############################################################################-

function set-drive_dirs--from-user-args() {
	[[ ${1-} == -[aA] ]] && { local all_opt=$1; shift; } || local all_opt=

	unset drive_names		# we might not set this ...

	if [[ $# == 0 || ${1,,} == all || $1 == '*' ]]
	   then set-drive_dirs $all_opt
		return $?
	fi

	set-glob "$@" && eval "set -- $drive_dir_prefix$glob"

	drive_dirs=
	for drive_dir
	    do	_set-drive_name -q $drive_dir  &&
		_set-drive_dir     $drive_name || continue
		suspend-tracing
		set -- $drive_dir/$snapshot_glob*
		restore-tracing
		[[ $# != 0 ]] || [[ $(df $drive_dir) == *$drive_dir* ]] &&
		    drive_dirs+="$drive_dir "
	done
	drive_dirs=${drive_dirs% }
	[[ $drive_dirs ]]
}
readonly -f set-drive_dirs--from-user-args

# ---------------------------------

function set-drive_names--from-user-args() {
	 set-drive_dirs--from-user-args "$@" || return $?

	drive_names=
	local drive_dir drive_name
	for drive_dir in $drive_dirs
	    do	_set-drive_name $drive_dir
		  drive_names+="$drive_name "
	done
	drive_names=${drive_names% }
	[[ $drive_names ]]
}
readonly -f set-drive_names--from-user-args

# ---------------------------------

# The locking & job-management policy is documented in front of function lock()

# Create a unique job on each specified drive (default $drive_name).
# Each job has its own session: lock files will hold PGID (process-group ID),
# making 'kill'/'suspend' and 'ps' and 'watch' (dashboard) easy to manage.
# We run backups simultaneously, so they all share the cached source files;
# we run prunes  simultaneously, since a prune's I/O stays on its own drive;
# we run copy's  simultaneously, cuz uses fastest-snapshots to find idle src.
# See action update-drives for the weird dance we perform when passed options;
# see action copy-snapshots for handling an arbitrary number of source args.
create-jobs() {
	local type=$1; shift
	local opts= are_recursing=$false
	while [[ ${1-} == -[^r]* ]] ; do opts+="$1 "; shift; done
	[[ ${1-} == -r ]] && { are_recursing=$true; shift; }

	if [[ $# == 0 ]]
	   then set -- ${drive_name-}
	elif [[ $1 == all || $1 == '*' ]]
	   then set-excluded_drive_dirs_regex
		set -- $(list-drive-dirs |
			     egrep -v "\b$excluded_drive_dirs_regex$")
	   else set-drive_names--from-user-args "$@"
		set -- $drive_names
	fi
	if [[ $# == 0 ]]
	   then [[ $is_cron ]] && exit 0
		abort-function "$type: pass a (non-excluded) drive name"
	fi

	[[ ! $debug_opt ]] &&
	set -- $(echo $* | tr ' ' '\n' | tac) # 'ps' shows newest process first

	# *_exe variables include options to snapback (e.g. -d and -t)
	case $type in
	   ( backup ) function=run-backup     exe=$run_backup_exe    ;;
	   ( copy   ) function=copy-snapshot  exe=$copy_snapshot_exe ;;
	   ( prune  ) function=prune-drive    exe=$prune_drive_exe   ;;
	   ( update ) function=update-drive   exe=$update_drive_exe  ;;
	   (   *    ) abort "action '$type' is not supported" ;;
	esac

	if [[ $are_recursing ]]
	   then $Trace
		$function $opts $1
		exit $?
	fi

	[[ $UID == 0 || $* == Z ]] || $IfRun abort "run with sudo"

	[[ ! $debug_opt && $* != [Zz] && -t 1 ]] && echo -e "
	NOTE: your $action command will run as a separate, disconnected job;
	      and it might wait for a lock before it can start.  See it with:

		$_our_name watch
"
	$Trace
	for name
	    do	# [[ $name == *[aA] ]] && set -x	  # uncomment to debug
		_set-drive_name $name && name=$drive_name # cleanup for 'ps'
		if [[  ! $debug_opt   && $name != Z ]]
		   then trap '' HUP
			# Want new process-group so can ps/kill independently.
			setsid \
			$exe $opts -r $name &
		   else $exe $opts -r $name # run in foreground, for testing
			echo
		fi
		set +x			# uncomment to just debug one drive
	done
}
readonly -f create-jobs

##############################################################################-
##############################################################################-
# 'watch' action.
##############################################################################-
##############################################################################-

set-stats_format() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local drive_dirs=$*

	is-set stats_format && { $xtrace; return; }

	local -i format_width
	local format=
	local drive_dir drive_name
	for drive_dir in $drive_dirs
	    do	_set-drive_name $drive_dir
		format_width=${#drive_name}+5
		format+="%-${format_width}s "
	done
	stats_format=${format% }
	TraceV 1 stats_format
	$xtrace
}
readonly -f set-stats_format

# ---------------------------------

set-rsync_hour_avgs-rsync_hour_maxs() {
	local all_drive_dirs=${all_drive_dirs:=$(list-drive-dirs)}

	set-stats_format $all_drive_dirs
	local hour_avgs= hour_maxs=
	local dir drive_name format=
	for dir in $all_drive_dirs
	    do	_set-drive_name $dir
		local name=$drive_name
		local  dir=$log_dir/$name/$rsync_time_subdir
		set -- $dir/$snapshot_glob.txt
		if [[ $# != 0 ]]
		   then local -i mins max_mins=0
			local file sum=
			for file
			    do	mins=$(< $file)
				sum+="$mins+"
				(( max_mins<mins )) &&
				   max_mins=mins
			done
			local -i total=${sum%+}
			local -i avg=$(( ($total+($#/2)) / $# ))
			set-hours--from-minutes -1 $avg # want 1 decimal point
			hour_avg=$hours
			set-hours--from-minutes -1 $max_mins
			hour_max=$hours
		   else hour_avg= hour_max=
		fi
		hour_avgs+="$name=$hour_avg "
		hour_maxs+="$name=$hour_max "

	done

	printf -v rsync_hour_avgs "$stats_format" $hour_avgs
	printf -v rsync_hour_maxs "$stats_format" $hour_maxs
	rsync_hour_avgs=${rsync_hour_avgs% }
	rsync_hour_maxs=${rsync_hour_maxs% }
}
readonly -f set-rsync_hour_avgs-rsync_hour_maxs

# -----------------------------------------------------------------------------

set-drive_usage() {
	local all_drive_dirs=${all_drive_dirs:=$(list-drive-dirs)}

	set-stats_format $all_drive_dirs
	customize-config-variables
	local var_name=min_FS_usage_percent; local \
	    default_min_FS_usage=${custom_config_var2default_value[$var_name]-}

	local max_drive_usage_percent warning_string
	for drive_dir in $all_drive_dirs
	    do	# a speedup to avoid (slow) call to set-drive_name
		_set-drive_name $drive_dir
		[[ $default_min_FS_usage ]] &&
		min_FS_usage_percent=${drv_name2min_FS_usage_percent[$drive_name]-$default_min_FS_usage}

		is-drive-usage-too-high && local warn=$true || local warn=
		local     type=${max_drive_usage_percent:0:1}
		local  percent=${max_drive_usage_percent#?}
		((  ${#percent} ==   1 )) && percent=0$percent
		if [[ $percent  == 100 && $watch_opt ]]
		   then set-warning_string error FULL
			percent=$warning_string
		elif [[ $warn && $watch_opt ]]
		   then set-warning_string warning $percent%$type
			percent=$warning_string
		   else percent=$percent%$type
		fi
		_set-drive_name $drive_dir
		percents+="$drive_name=$percent "
	done
	printf -v drive_usage "$stats_format" $percents
}
readonly -f set-drive_usage

# -----------------------------------------------------------------------------

_set-age() {
	local snapshot=$1

	set-seconds--from-snapshot $snapshot
	local -i snap_secs=$seconds
	age=$(( ($SECONDS - $snap_secs)/(24*60*60) ))
}
readonly -f _set-age

# ------------------

_setup-ages() {

	_set-age $1    ; oldest_age=$age
	_set-age ${!#} ; newest_age=$age
}
readonly -f _setup-ages

# ---------------------------------

_set-colorized_new() {
	local new=${1-}

	local warning_string=
	case $new in
	    ( '' ) set-warning_string error   NONE ;;
	    ( 0  ) true				   ;;
	    ( 1  ) set-warning_string warning $new ;;
	    ( *  ) set-warning_string error   $new ;;
	esac
	# "printf %7s" doesn't handle terminfo escape sequence
	if [[ $warning_string && $new ]] # NONE fills the assigned slot
	   then (( ${#new} <= 1 )) && warning_string+='_'
		(( ${#new} <= 2 )) && warning_string+='_'
		(( ${#new} <= 3 )) && warning_string+='_'
	fi
	colorized_new=${warning_string:-$new}
}
readonly -f _set-colorized_new

# ---------------------------------

_recalculate-stats-vars() {

	set-stats_format $all_drive_dirs
	local nums= oldies= newies=
	for dir in $all_drive_dirs
	    do	_set-drive_name $dir
		local name=$drive_name
		cd $dir || abort "cd $dir"
		ending=${type2date_suffix_glob[$ignored_date_ending_type]}
		suspend-tracing
		set -- $snapshot_glob$suffix
		restore-tracing
		[[ $# != 0 ]] && {
		local snapshot snap prev_snap= snaps=
		for snapshot
		    do	snap=${snapshot%$ending$suffix}
			[[ $prev_snap != $snap ]] && snaps+="$snap "
			    prev_snap=$snap
			suspend-tracing
		done
		set -- $snaps
		}
		restore-tracing

		nums+="$name=$# "

		[[ $dates ]] || continue
		if [[ $# != 0 ]]
		   then _setup-ages $*
			local old=$oldest_age	new=$newest_age
		   else local old=		new=
		fi
		if [[ ! $suffix && $watch_opt ]] # checking complete snapshots?
		   then _set-colorized_new $new # warn if newest not today
			new=$colorized_new
		fi
		oldies+="$name=$old "
		newies+="$name=$new "
	done
	cd $OLDPWD || abort "cd $OLDPWD"

	printf -v stats_number     "$stats_format" $nums    ; [[ $dates ]] && {
	printf -v stats_oldest_age "$stats_format" $oldies
	printf -v stats_newest_age "$stats_format" $newies		    ; }
}
readonly -f _recalculate-stats-vars

# ----------------------

readonly watch_cache_dir=$log_dir/stats/watch
readonly cached_drive_dirs_file=$watch_cache_dir/drive-dirs.txt

function _is-stats-cache-fresh {

	if [[ $drive_dirs != "$(< $cached_drive_dirs_file)" ]]
	   then rm -f $cached_drive_dirs_file $watch_cache_dir/*/*,*.txt
		return 1
	fi

	local dir drive_name
	for dir in $drive_dirs
	    do	[[ $number_cache_file -nt $dir/. ]] || return 1
	done

	return 0
}
readonly -f _is-stats-cache-fresh

# ----------------------

setup-snapshot-stats() {
	local suffix=$1
	local ignored_date_ending_type=${2:-NONE} # NONE used in prune arrays

	[[ $suffix ]] &&
	   local suffix_name=${suffix/\*/STAR} || local suffix_name=NONE
	suffix_name=${suffix_name#/}
	suffix_name=${suffix_name#.} ; local \
	 cache_name="suffix=$suffix_name,ignored=$ignored_date_ending_type.txt"
	local  lock_name=stats-$suffix_name,$ignored_date_ending_type.pid

	[[ $suffix == .rm ]] && suffix=*$suffix
	[[ $ignored_date_ending_type == NONE && $suffix_name != keep ]] &&
	   local dates=$true || local dates=$false

	local     number_cache_file=$watch_cache_dir/number/$cache_name
	local oldest_age_cache_file=$watch_cache_dir/oldest-age/$cache_name
	local newest_age_cache_file=$watch_cache_dir/newest-age/$cache_name
	local drive_dirs=$all_drive_dirs
	if _is-stats-cache-fresh && [[ $watch_opt ]]
	   then stats_number=$(< $number_cache_file)
		[[ $dates ]] && {
		stats_oldest_age=$(< $oldest_age_cache_file)
		stats_newest_age=$(< $newest_age_cache_file)
		}
		# echo -n C:		# uncomment to ensure cache is working
		return
	fi

	_recalculate-stats-vars

	[[ $watch_opt ]] || return	# don't cache non-colorized 'w' data

	# it takes ~0.05 secs/drive to calculate stats, called 9 times: cache
	[[ -w $log_dir  ]] || return # might not have write access to the cache
	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	local lockpid_args="--dir=$lock_dir $lock_name"
	lockpid $lockpid_args > /dev/null || return

	mkdir -p ${number_cache_file%/*} ${oldest_age_cache_file%/*} \
					 ${newest_age_cache_file%/*}
	echo "$drive_dirs" > $cached_drive_dirs_file
	echo "$stats_number"	 >     $number_cache_file   ; [[ $dates ]] && {
	echo "$stats_oldest_age" > $oldest_age_cache_file
	echo "$stats_newest_age" > $newest_age_cache_file		    ; }

	lockpid --release $lockpid_args
}
readonly -f setup-snapshot-stats

# -----------------------------------------------------------------------------

set-max_drive_name_len() {
	local drive_dirs=${*:-$(list-drive-dirs -a)}

	declare -g -i max_drive_name_len=0

	local drive_dir drive_name
	for drive_dir in $drive_dirs
	    do	_set-drive_name $drive_dir
		(( max_drive_name_len<${#drive_name} )) &&
		   max_drive_name_len=${#drive_name}
	done
}

# -------------------------------------------------------

declare -i min_full_columns=94

function run-df() {
	local drive_dirs=${*:-$(list-drive-dirs -a)}

	echo
	local df_fields=source,fstype,size,avail,used,pcent,iused,ipcent,target
	(( ${cols:-99} >= $min_full_columns )) || df_fields=${df_fields/,size/}
	df --block-size=G --output=$df_fields $drive_dirs
}
readonly -f run-df

# --------------------------------------------

function run-lsblk() {
	local drive_dirs=${*:-$(list-drive-dirs -a)}

	have-cmd lsblk || return 1

	local dir devices=
	for dir in $drive_dirs
	    do	set-FS_device--from-path $dir &&
		devices+="$FS_device "
	done

	echo
	# fields that don't work: rm,model
	lsblk_fields=name,fstype,type,rota,size,state,sched,opt-io,mountpoint
	lsblk --output=$lsblk_fields --sort mountpoint  $devices 2>/dev/null ||
	lsblk --output=$lsblk_fields			$devices
}
readonly -f run-lsblk

# -----------------------------------------------------------------------------

function trim {

	# when prune excludes, prune & cron-job can both have a multi-arg 'rm'
	sed -e 's@\( rm [^0-9]*[0-9][^ ]* \).*@\1...@'	\
	    -e "s@ --pid=[0-9]* --dir=$lock_dir @ @"	\
	    -e "s@ --pid=[0-9]* @ @"	\
	    -e "s@ --quiet @ @"		\
	    -e 's@/bin/bash /@/@'	\
	    -e 's@ bash /@ /@'		\
	    -e 's@ /usr/local/bin/@ @'	\
	    -e "s@ $HOME/@ ~/@g"
	return 0
}
readonly -f trim

# --------------------------------------------

function trim-backup {

	trim |
	sed -e 's@run-backup -r @run-backup @g' \
	    -e 's@ --.* @ $opts -R $dirs @' \
	    -e "s@$drive_dir_prefix@@g"	# remove prefix last
	return 0
}
readonly -f trim-backup

# --------------------------------------------

function trim-prune {

	trim |
	sed -e 's@prune-drive -r @prune-drive @g'
	return 0
}
readonly -f trim-prune

# --------------------------------------------

function trim-copy-update {

	set -- $rsync_backup_opts	# standardize whitespace

	local cpss="$_our_name c"
	trim |
	# makes *.links copy wrap: -e "s@ $* /@ \$opts /@" \
	# makes *.links copy wrap: -e 's@ --.* --link-dest=[^ ]* /@ $opts /@' \
	sed -e '/update-drive/s@ -r @ @g' \
	    -e '/update-drive/s@ -s@ -s @' \
	    -e 's@ --.* --link-dest=[^ ]* /@ /@' \
	    -e "/[0-9]   $_our_name/d" \
	    -e "s@ $* /@ /@" \
	    -e "/$cpss/s@\($_our_name[^0-9]*[^ ]*\)..*\(.\) *\$@\1 ... \2@" \
	    -e 's@/[^/]*/\. /@/$snap/. /@' \
	    -e "s@$drive_dir_prefix@@g"	# remove prefix last
	return 0
}
readonly -f trim-copy-update

# ------------------------------------------------------------------

watch() {
	local watch_opt= ps_opt= cron_opt= names=
	[[ ${1-} == -w ]] && { watch_opt=-w; shift; } # internal option
	[[ ${1-} == -f ]] && {    ps_opt=-f; shift; }
	[[ ${1-} == -C ]] && {  cron_opt=-C; shift; }
	[[ ${1-} == -f ]] && {    ps_opt=-f; shift; }
	[[ ${1-} == -N ]] && {     names=$2; shift 2; }
	assert-not-option -o ${1-}

	if [[ $action == watch ]]
	   then cleanup-after-updates &	# don't wait for it to finish, slow
		local all_opts="$ps_opt $cron_opt"
		if [[ $names ]]
		   then set-drive_names--from-user-args $names
			all_opts+=" -N ${drive_names// /,}"
		fi
		# >= 0.5 is best for watching wchan (-C w/sudo access)
		[[ ${SSH_TTY-} ]] && n=0.5 || n=0.5
		exec \
		watch -c -d -p ${*:- -n $n} $our_path $our_opts w -w $all_opts
		abort "exec failed"
	fi

	set -- $(list-drive-dirs -a)
	[[ $# != 0 ]] || { echo "No mounted backup drives found."; exit; }
	local all_drive_dirs=$* drive_dirs=
	local do_tput=$true show_all=$false
	[[ $watch_opt ]] || ps_opt=-f cron_opt=-C show_all=$true do_tput=$false
	[[ $watch_opt ]] || trap '' HUP
	[[ $watch_opt ]] || cleanup-after-updates $all_drive_dirs # wait for it
	[[ $watch_opt && $Trace ]] && exec 2>$tmp_dir/$_our_name-w.$BASHPID
	SECONDS=$(date '+%s')		# for _set-age()
	if [[ $names ]]
	   then local name_list=
		for name in ${names//,/ }
		    do	_set-drive_name $name
			_set-drive_dir
			drive_dirs+="$drive_dir "
			name_list=$name_list,$drive_name
		done
		names=${name_list#,}
		# show_all=$true   cron_opt=-C
	   else : ${show_all=$false}
		drive_dirs=$all_drive_dirs
	fi
	[[ $names ]] && names_glob="{$names}" &&
	    names_msg=" for $names " || names_msg=

	TraceV 1 names drive_dirs names_glob ps_opt cron_opt show_all

	# ------------------------------------------------------------------
	# dynamically determine 'ps' fields based on screen column width
	# ------------------------------------------------------------------

	$Trace
	if [[ $watch_opt ]]
	   then set -f; set -- $(stty -a); set +f
		local -i rows=${5%;} cols=${7%;}
	   else local -i rows=9999   cols=9999
	fi
	set-max_drive_name_len $drive_dirs
	min_full_columns+=max_drive_name_len-1
	if (( $cols >= $min_full_columns )) || [[ $ps_opt == -f ]]
	   then is_wide=$true
	   else is_wide=$false
	fi
	export COLUMNS=9999		# for 'ps'

	# --------------------------------------------------------------------

	# min fits in 80-column screen; grep's expect ends with cputime,command
	  ps_min_keywords=pid,pgid,%mem,stat,cputime,command
	ps_min_header="  PID  PGID %MEM STAT     TIME COMMAND"
	#
	  ps_max_keywords=pid,pgid,start,%mem,%cpu,stat,cputime,command
	ps_max_header="  PID  PGID  STARTED %MEM %CPU STAT     TIME COMMAND"

	if [[ $is_wide ]]
	   then ps_keywords=$ps_max_keywords  ps_header=$ps_max_header
	   else ps_keywords=$ps_min_keywords  ps_header=$ps_min_header
	fi

	case $OSTYPE in
	    ( linux* ) ps_H_opt=-H  ps_f_opt=f  ;;
	    ( *bsd*  ) ps_H_opt=-d  ps_f_opt=-d ;; # works on FreeBSD, at least
	    (   *    ) ps_H_opt=    ps_f_opt=   ;;
	esac

	# trailing '=' in "$ps_keywords=" means "don't print header"
	ps_() { ps $ps_H_opt -o $ps_keywords= "$@"; }

	# ---------------------------------

	set -- $drive_dirs
	local -i num_drives=$#

	set-lock_PGIDs backup && {
	bkp_rsync_cmds=$(ps_ $lock_PGIDs |
			   sed -n '/[0-9]   rsync/s/   rsync/ rsync/p')
	local -i num_bkp_rsyncs=$(echo "$bkp_rsync_cmds" | wc -l) ; } || {
	local -i num_bkp_rsyncs=0 ;	 bkp_rsync_cmds= ; }

	! set-lock_PGIDs prune && prune_cmds= ||
	prune_cmds=$(ps_ $lock_PGIDs 2>/dev/null  |
			fgrep -e ' rm ' -e ' prune-' -e ' pd ' -e ' lockpid ' |
			trim-prune)

	# both update-drive and copy-snapshot use the copy lock
	! set-lock_PGIDs copy && copy_rsync_cmds= ||
	copy_rsync_cmds=$(ps_ $lock_PGIDs |
			   egrep -e "[0-9] .*$_our_name.* [cu]" \
				 -e " [l]ockpid " \
				 -e " [s]leep "	\
				 -e "[0-9]     rsync" |
			     sed -e 's/   rsync/ rsync/')
			   #     -e 's/   lockp/ lockp/') # -> harder to notice
	#
	rsync_or_rm_cmd_PGIDs_file=$tmp_1
	ps -u root -o pgid,command |
	   awk '/[ /]rm / || /[ /]rsync / {print $1}' > \
	       $rsync_or_rm_cmd_PGIDs_file
	cron_job_regex=' -C run-backups? ' # put into configure.sh ??
	set -- $(ps -u root -o pgid,command |
			egrep "$cron_job_regex" |
			fgrep -w -f $rsync_or_rm_cmd_PGIDs_file |
			awk '$0 !~ /setsid / {print $1}' | sort -u -n)
	cron_PGIDs=$*
	rm $rsync_or_rm_cmd_PGIDs_file

	# --------------------------------------------------------

	# only show un-asked cron jobs if no rsync details to show
	[[ ($cron_opt || ! $bkp_rsync_cmds$copy_rsync_cmds) && $# != 0 ]] && {

	# widest -f -C line is child rsync: 79 cols + wchan + drive mountpoint
	widest_wchan_value=call_rwsem_down_read_failed # linux-3.2
	widest_wchan_value=balance_dirty_pages.isra.17 # linux-3.2
	widest_wchan_value=balance_dirty_pages.isra.24 # linux-4.x
is-set		 max_ps_wchan_width ||
	local -i max_ps_wchan_width=${#widest_wchan_value}+1
	local -i wchan_width=10		# min useful
	local -i overhead=26		# pid,pgid,%mem,%cpu,state,command
	[[ ! $is_darwin ]] && let overhead-=6 # have forest, don't need pgid?
	# " |       \_ rsync $opts -R $dirs /2019-07-07,00.partial/" ...
	local -i max_rsync=56		# deepest child, no drive name

	local -i max_name_len=max_drive_name_len
	if (( cols > overhead + max_rsync + max_name_len ))
	   then ps_wchan_width=$((cols - overhead - max_rsync - max_name_len))
		(( ps_wchan_width>$max_ps_wchan_width )) &&
		   ps_wchan_width=$max_ps_wchan_width
		ps_keywords=$ps_max_keywords
	   else ps_keywords=$ps_min_keywords
	fi
	[[ ! $is_darwin ]] && ps_keywords=${ps_keywords/,pgid,/,}

	set -- $(process-group-PIDs $cron_PGIDs)
	[[ $is_wide ]] && wchan=wchan:$ps_wchan_width || wchan=
	[[ $wchan ]] && sudo -n ps &> /dev/null && sudo=sudo || sudo= wchan=
	[[ $wchan     ]] && ps_keywords=${ps_keywords/,stat,/,$wchan,stat,}
			    ps_keywords=${ps_keywords/,%mem,sta/,%mem,%cpu,sta}
	# deduct the width of the ps record with minimum fields but max wchan
	let cols-=overhead+max_ps_wchan_width+max_rsync+max_drive_name_len
	(( cols >=  3 )) || ps_keywords=${ps_keywords/,stat,/,state,}
	(( cols >= 12 )) || ps_keywords=${ps_keywords/,cputime,/,}
	(( cols >= 21 )) || ps_keywords=${ps_keywords/,start,/,}
	(( cols >= 27 )) && ps_keywords=${ps_keywords/pid,/pid,pgid,}
			   ps_keywords=${ps_keywords/,pgid,pgid,/,pgid,/}
	#  option f for "forest"
	cron_cmds=$($sudo ps $ps_f_opt -o $ps_keywords $*)

	} || cron_cmds=

	# ---------------------------------------------------------

	# prune-drive (PD) includes parent of  'rm'   process (also in -C)
	#  copy-snap  (CS) includes parent of 'rsync' process (also in -C)
	local -i PD=$(echo    "$prune_cmds"   | fgrep -c 'prune-drive')
	(( PD > 0 )) && PD=$((PD*2 + 4)) # add in 'rm' plus section-overhead
	local -i CS=$(echo "$copy_rsync_cmds" | egrep -c '(update|copy)-')
	(( CS > 0 )) && CS=$((CS*2 + 4)) # add in 'rsync' plus section-overhead
	local -i RB=$num_bkp_rsyncs
	(( RB > 0 )) && let RB+=3+4+3	# default + (details section + 1 rsync)
	(( RB > 0 )) && let RB+=2	# hack, to ensure we see one full rsync
	TraceV 1 PD CS RB && let rows-=3
	# min overhead: 1 watch line, 1 blank line, 6 lines of stats,
	#   4 lines of empty backup section.
	# the copy (CS) section is only printed if there's some activity.
	local -i min_rows=$((  8 + 4 + PD + CS + RB )); [[ $cron_opt ]] &&
		 min_rows+=$(( 4 + 5*num_bkp_rsyncs + PD ))
	local -i min_df_rows=$(( min_rows + 2 + num_drives ))
	(( $Trace_level > 0 )) && let rows-=3 # for the next TraceV
	TraceV 1 rows min_rows min_df_rows


	# ------------------------------------------------------------------
	# now we're ready to start showing stuff to the user
	# ------------------------------------------------------------------

	local -i min_for_rare=$(( min_df_rows + 6 + 7 + 6 ))
	[[ ! -s /etc/sudoers.d/$_our_name &&
	   ( $rows -gt $min_for_rare || $show_all ) ]] && {
		header -E "to not fill the log with frequent 'sudo ps'"
		echo
		option_1="install etc/sudoers.d/$our_name"
		option_2="put its contents into /etc/sudoers"
		echo -e "$option_1, or $option_2"

		header "statistics"
		echo
		let rows-=6		# only adjust for optional sections
	}

	# ------------------------------------------------------------------

	set-rsync_hour_avgs-rsync_hour_maxs
	echo "Average hours to create rsync snapshot:  $rsync_hour_avgs"
	echo "Maximum hours to create rsync snapshot:  $rsync_hour_maxs"
	set-drive_usage
	echo "Drive maximum (b)lock or (i)node usage:  $drive_usage"
	setup-snapshot-stats .rm
	echo "# pruned .rm snapshots awaiting: rm -r:  $stats_number"
	setup-snapshot-stats .partial
	echo "# .partial snaps pending update (+err):  $stats_number"
	setup-snapshot-stats ''
	echo "  Age of newest good snapshot, in days:  $stats_newest_age"

	# --------------------------------------------

	local -i rows_used=7		# stats plus 1 blank line
	(( $rows >= ($min_rows + $rows_used) )) || [[ $show_all ]] && {
	echo				# first row used
	setup-snapshot-stats .rm
	echo "  Age of newest pending prune, in days:  $stats_newest_age"
	setup-snapshot-stats .links
	echo " Number .links (failed 'ln') snapshots:  $stats_number"
	echo "Days since newest 'Too many links' err:  $stats_newest_age"
	setup-snapshot-stats .partial
	echo "    Days since newest snapshot.partial:  $stats_newest_age"
	setup-snapshot-stats /.keep	# doesn't set oldest/newest_age
	echo "Numbr snaps never pruned (have /.keep):  $stats_number"
	setup-snapshot-stats ''
	echo "  Number complete/successful snapshots:  $stats_number"
	let rows-=$rows_used
	}

	# --------------------------------------------

	local -i rows_used=6		# stats plus 1 blank line
	(( $rows >= ($min_df_rows + $rows_used) )) || [[ $show_all ]] && {
	echo				# first row used
	echo "  Age of oldest good snapshot, in days:  $stats_oldest_age"
	setup-snapshot-stats '' hour
	echo "  Total number  days  w/good snapshots:  $stats_number"
	setup-snapshot-stats '' day
	echo "  Total number months w/good snapshots:  $stats_number"
	setup-snapshot-stats '' month
	echo "  Total number years  w/good snapshots:  $stats_number"
	setup-snapshot-stats '*'
	echo "  Total snapshots (good, partial, .rm):  $stats_number"
	let rows-=$rows_used
	}

	# ------------------------------------------------------------------

	if [[ $show_all ]]
	   then filesystem-geometry $drive_dirs
	   else	(( $rows >= $min_df_rows )) &&
		run-df $drive_dirs &&
		let rows-=$num_drives+2

		# --------------------------------------------

		(( $rows >= $min_df_rows )) && [[ ! $copy_rsync_cmds ]] &&
		run-lsblk $drive_dirs &&
		let rows-=$num_drives+2
	fi

	# ------------------------------------------------------------------

	# if prune in cron section, don't usually also show it in prune section
	echo "$cron_cmds" | sed -n 's/.*prune-drive/prune-drive/p' > $tmp_1
	[[ ! $show_all ]] &&
	   prune_cmds=$(echo "$prune_cmds" | fgrep -v -f $tmp_1) &&
	   let rows+=$(wc -l < $tmp_1)
	rm $tmp_1

	# FIXME: want to show snapback cmd if child is lockpid not rm
	let snapback_cmd_count="($PD-4)/2" # 4 is section overhead
	(( $rows < ( $min_rows + $snapback_cmd_count ) )) &&
	   fgrep_opt="-e prune-drive" && # just want 'rm' commands
		let rows+=$snapback_cmd_count || fgrep_opt=
	prune_cmds=$(echo "$prune_cmds" |fgrep -v -w -e xargs -e tr $fgrep_opt)

	[[ $prune_cmds || $show_all ]] && {
	header "prune-drive ($_our_name parent may be hidden to save rows)"
	echo
	}

	if [[ $prune_cmds ]]
	   then echo "$ps_header"
		echo "$prune_cmds"
	elif [[ $show_all ]]
	   then echo -e "No pruning is being done$names_msg."
	fi

	# ------------------------------------------------------------------

	[[ $copy_rsync_cmds && ( $show_all || ! $cron_opt ) ]] && {
	header "copy (update-drive or copy-snapshots)"
	echo
	echo "$ps_header"
	echo "$copy_rsync_cmds" | trim-copy-update
	}

	# ------------------------------------------------------------------

	# for some reason, appending newlines does nothing?!
	[[ $is_wide ]] && var_name=" (\$rsync_backup_opts)" || var_name=
	rsync_abbrev_msg="
	  default opts=\"$rsync_backup_opts\"$var_name
	  default dirs=\"$dirs_to_backup\" (\$dirs_to_backup)"
	rsync_abbrev_msg=${rsync_abbrev_msg//	/} # strip leading TAB

	header "cron's run-backups' lead rsync processes (abbreviated)"
	[[ $bkp_rsync_cmds ]] && {
	echo "$rsync_abbrev_msg"; echo
	echo "$ps_header"
	echo "$bkp_rsync_cmds" | trim-backup # | sort $rsync_sort_opts
	} || echo -e "\nNo backups are running$names_msg."

	# ------------------------------------------------------------------

	# show process tree of master cron job(s)
	[[ $cron_cmds ]] && {
	set -- $(ps -o stime= $cron_PGIDs | sort -u)
	stime=$*
	regex=${cron_job_regex%%s*}
	header "$stime: '$regex' cron job(s), PGID='$cron_PGIDs'"; echo
	(( $rows < $min_rows )) && echo "${rsync_abbrev_msg#?}" && echo
	echo "$cron_cmds" | trim-backup
	}

	# ------------------------------------------------------------------

	[[ $bkp_rsync_cmds ]] && {
	header "cron's run-backups' lead rsync processes (full details)"
	echo
	echo "$ps_header"
	echo "$bkp_rsync_cmds" | sed "s@ $HOME/@ ~/@g"
	}

	# ------------------------------------------------------------------

	[[ $copy_rsync_cmds ]] && {
	header "copy (e.g. update) rsync processes (full details)"
	echo
	echo "$ps_header"
	echo "$copy_rsync_cmds" | sed -n "s@ $HOME/@ ~/@g; /\brsync /p"
	}
}
readonly -f watch

##############################################################################-
##############################################################################-
# Functions for monitoring/creating/altering filesystems.
##############################################################################-
##############################################################################-

readonly status_dir=/run/$our_name

# if make check_period_msecs smaller, we'll check each drive more frequently
# (but also consume more CPU, because 1 fork per drive per check-period)
is-set        check_period_msecs ||	# can set custom value in $config_file
declare -r -i check_period_msecs=200

is-set        min_hung_msecs ||		# can set custom value in $config_file
declare -r -i min_hung_msecs=2000
is-set        min_slow_msecs ||		# can set custom value in $config_file
declare -r -i min_slow_msecs=200	# it's also the disk read timeout ...
# set-seconds--from-msecs $min_slow_msecs
# readonly disk_read_timeout=$seconds

declare -r -i   msec_increment=10
set-division 3 $msec_increment 1000
readonly         sec_increment=$division

_monitor-drives() {

	local response_dir=$status_dir/response-msecs

	for dir
	    do	 _set-drive_name $dir || abort "bad $dir"
		name=$drive_name
		[[ ${name2PID[$name]-} ]] && continue	   # hung drive?
		( set -- $dir/*.nul ) & name2PID[$name]=$! # not, test it
		name2msecs[$name]=0	# we just started the test
		for file in $status_dir/{hung,slow}/$name
		    do	echo $false > $file
		done
		echo 0 > $response_dir/test-run/$name
	done

	local -i msecs=0
	# for speed, the following loop nevever forks (except 'sleep' at end)
	while (( $msecs < $check_period_msecs )) # not waited long?
	   do	set -- ${!name2PID[*]}		 # any slow drives?
		[[ $# == 0 ]] && break		 # if not, time to re-test
		for name
		    do	if ! kill -0 ${name2PID[$name]} 2> /dev/null # done?
			   then unset  name2PID[$name]
				continue
			fi

			# drive is (a little bit?) slow

			local  count_file=$response_dir/counter/$name
			[[ -s $count_file ]] || echo 0 > $count_file
			local -i count=$(< $count_file)
			count+=1
			echo $count > $count_file

			hung_msecs=${name2msecs[$name]}
			name2msecs[$name]+=$msec_increment
			echo $hung_msecs > $response_dir/test-run/$name

			  if (( $hung_msecs >= $min_hung_msecs ))
			   then echo $true  > $status_dir/hung
				echo $true  > $status_dir/slow
			elif (( $hung_msecs >= $min_slow_msecs ))
			   then echo $false > $status_dir/hung
				echo $true  > $status_dir/slow
			   else echo $false > $status_dir/hung
				echo $false > $status_dir/slow
			fi
		done

		sleep   $sec_increment
		msecs+=$msec_increment
	done
}
readonly -f _monitor-drives

# ---------------------------------

readonly drive_monitor_lock_path=$lock_dir/monitor.pid

monitor-drives() {
	local dirs=${*-}		# only for testing

	lockpid -q $drive_monitor_lock_path || exit 0 # probably running

	trap '' HUP			# we want to run forever

	for sub_dir in slow hung response-msecs/{average,counter,test-run}
	    do	mkdir -p $status_dir/$sub_dir
	done

	SECONDS=0
	local -A -i name2PID name2msecs
	while true			# monitor forever
	    do	_monitor-drives ${dirs:-$(list-drive-dirs -a)} # new drive?
	done
}
readonly -f monitor-drives

# -----------------------------------------------------------------------------

# for each name (can be 'all'), kill any backups/pruning/etc & unmount drive
function unmount-drives() {
	[[ $1 == -q  ]] && { shift; is_OK_if_drive_dir_unmounted=$true; }
	assert-not-option ${1-}
	[[ $* == all ]] && set -- $(list-drive-dirs)

	$Trace
	# do this early, since takes a while for processes to die
	for name
	    do	$IfRun kill-job-on-drives all $name
	done

	[[ $debug_opt ]] && local output=/dev/stdout || local output=/dev/null
	local name drive_name drive_dir status=0
	for name
	    do	set-drive_name $name
		set-drive_dir $drive_name
		is-drive-mounted $drive_dir || continue
		sudo umount -h &> /dev/null || warn "need sudo privs" || break
		umount_cmd="$IfRun sudo umount -v $drive_dir"
		for (( i = 1; i <= 99; i++ )) # wait for kill to finish
		    do	$umount_cmd && break
			$IfRun sleep 0.1
		done &> $output
		is-drive-mounted $drive_dir || continue
		$umount_cmd || status=$? # this time, show the error message
	done
	return $status
}
readonly -f unmount-drives

# -----------------------------------------------------------------------------

# Optional function to allocate an external filesystem log/journal
# on fast storage (SSD, or always-plugged-in flash memory stick),
# for use with rotational hard disks.
# Rewrite this function if you're not using LVM.
have-cmd set-FS_external_log &&
function set-FS_external_log() {
	[[ ${1-} == -f ]] && { do_force=$true; shift; } || do_force=$false
	local FS_label=$1 VG=${2:-$FS_log_VG} # FS_log_VG in $config_file

	[[ $VG ]] &&
	[[ $do_want_external_log ||	# defined in $config_file
	   $do_force                ]] || { FS_external_log= && return 1; }

	       FS_external_log=/dev/$VG/${FS_label}_log
	[[ -b $FS_external_log ]] && return 0

	$IfRun lvcreate --size 128M --name $FS_external_log $VG ||
	    FS_external_log=
	[[ $FS_external_log ]]
}

# -----------------------------------------------------------------------------

# add-extN-journal drive_name [FS_device [VG_name]]: fast external journal
function add-extN-journal() {
	[[ ${1-} == -M ]] && { local  do_mount=  ; shift; } || local do_mount=t
	[[ ${1-} == -f ]] && { local force_opt=$1; shift; } || local force_opt=
	[[ $# == [1-4] ]] ||
	   abort "{-l FS_label | drive_name} [device [VG-name]]"
	if [[ $1 == -l ]]
	   then shift;  local FS_label=$1
	   else local name=$1 FS_label=
	fi
	assert-not-option -o ${1-}
	local FS_device=${2-} VG_name=${3-}

	[[ $UID == 0 ]] || $IfRun abort "run with sudo"

	[[ ! $FS_label ]] && {
	is_OK_if_drive_dir_unmounted=$true
	set-drive_name $1
	set-drive_dir $drive_name
	mount_dir=$drive_dir
	set-FS_label--from-mount_dir $mount_dir ; }
							[[ $FS_device ]] ||
	set-FS_device--from-FS-label $FS_label
	[[ ${mount_dir-} ]] ||
	   set-mount_dir--from-FS-label  $FS_label ||
	   set-mount_dir--from-FS-device $FS_device
	TraceV 1 force_opt FS_label FS_device VG_name mount_dir

	sudo tune2fs -l $FS_device | grep -q '^Journal ' &&	  {
	warn "removing internal journal can take many minutes"
	$IfRun tune2fs $force_opt -O ^has_journal $FS_device	; }

	set-FS_external_log $force_opt $FS_label $VG_name ||
	warn "invalid set-FS_external_log, or $config_file says log unwanted"||
	   { $IfRun tune2fs -j $FS_device; return $?; }
	label=${FS_external_log##*/}

	$Trace

	RunCmd mke2fs -v -b 4096 -O journal_dev -L $label $FS_external_log

	suspend-tracing
	RunCmd -d unmount-drives -q ${mount_dir:-$FS_device}
	restore-tracing
	mount | fgrep -w $FS_device && $IfRun abort "must: umount $FS_device"

	RunCmd tune2fs -J device=LABEL=$label $FS_device
	$IfRun tune2fs -l $FS_device | grep -i "journal [id]"
	local status=${PIPESTATUS[0]}

	[[ $do_mount ]] || return $status

	mount_options=$common_mount_options,$extN_mount_options
	RunCmd mount -v -t ext4 -o ${mount_options%,} $FS_device $mount_dir
}
readonly -f add-extN-journal

# -----------------------------------------------------------------------------

set-total_dir_MB-avg_dir_KB() {
	local file=${1%.bz2}.bz2

	isize=$(echo $file | sed -r 's/.*-inode=([0-9]+)-.*/\1/')
	set -- $( bzcat $file |
		  awk --assign isize=$isize --field-separator K \
			'{ space += ($1*1024) + isize; count += 1 }
			 END { printf "%.1f %.2f\n",
					space/(1024*1024),
					space/(1024*count)}' )
	total_dir_MB=$1 avg_dir_KB=$2
}
readonly -f set-total_dir_MB-avg_dir_KB

# --------------------------------------------

# dir-sizes [-f | name]: generates stats for 'mkfs -b'; -f -> choose old file
dir-sizes() {
	set-drive_log_dir-file_for_logging-admin_group-is_regression_test
	readonly sizes_dir=$drive_log_dir/dir-sizes
	mkdir -p -m g+w,o-w $sizes_dir || abort "need to use sudo"
	cd_ $sizes_dir

	suffix=ls-s-d

	if [[ $# == 0 ]]
	   then echo -e "\nThe actual drive-space consumed by a directory is"
		echo -e "the size of: its directory block(s) plus its inode:\n"
		set -- *.$suffix.bz2
		[[ -f $1 ]] ||
		   abort "no saved data files, you need to run: $our_name name"
		for file
		    do	set-total_dir_MB-avg_dir_KB $file || continue
			space="all dirs use $total_dir_MB MB/snapshot"
			  avg="$avg_dir_KB KB/dir"
			printf "%46s: %s\n" "$space ($avg)" ${file%%.*}
		done | sort -k4n	# sort by total size
		echo
		exit
	fi

	if [[ $1 == -f ]]
	   then set -- $(/bin/ls *.$suffix.bz2 | sed 's/\.bz2//')
		[[ -f $1.bz2 ]] || abort "don't have any old data files"
		PS3="specify file number: "
		select file
		   do	[[ $file ]] && break
		done || exit 1
	   else file=  name=${1-}
		[[ $# == 1 && $name && $name != -* ]] ||
		   abort-with-action-Usage
		set-drive_name $1
	fi
	assert-not-option ${1-}

	[[ $file ]] || {

	_set-drive_dir
	if [[ -d $drive_dir/latest ]]
	   then excludes=   dirs_to_backup=$drive_dir/latest/.  where=
	   else excludes="--exclude=$drive_dir_prefix*
			  --exclude-from=$exclude_file"
		   problem="missing '$drive_dir/latest' snapshot symlink"
		solution_1="you can hit CTRL-C, and either: create symlink"
		solution_2="use 'dirs_to_backup' variable to check root drive"
		warn "$problem: $solution_1, or $solution_2"
		where=-root
	fi

	dir=${dirs_to_backup%% *}
	set-FS_type--from-path $dir
	set-inode_size-data_block_size-dir_block_size--from-path $dir
	type=$FS_type dirblock=$dir_block_size inode=$inode_size
	file=$type-dirblock=$dirblock-inode=$inode-$drive_name$where.$suffix
	TraceV 1 dirs_to_backup file

	[[ ! $debug_opt ]] ||
	   abort "use '-T 1' or '-t' instead of '-d' (-d only works with -f)"
	[[ $UID == 0 ]] || abort "need to use sudo"

	rsync --dry-run --verbose --recursive --relative \
		  $excludes		      \
		--include='*/' --exclude='*'  \
		      $dirs_to_backup  /tmp/  |
	   grep '^/' |
	   # head -n 100 |		# uncomment to speedup debugging
	   tr '\n' '\0' | xargs -0 ls --block-size=K -sd |
	   sed -r 's/^ *([0-9]+K) +/\1|/' | # pipe-separate fields
	   sort -t '|' -k1n,1 -k2	  | # for histogram & compression
	   awk  -F '|' '{ printf "%6s\t%s\n", $1, $2 }' | # more readable
	   bzip2 -9 > $file.partial.bz2 && mv $file.partial.bz2 $file.bz2
	   [[ $? == 0 && ${PIPESTATUS[0]} == 0 ]] ||
	      abort "something bad happened"
	}

	file=${file%.bz2}
	header $file

	set -- $(bzcat $file.bz2 | wc -l)
	local -i dir_count=$1
	local -i median_line=$dir_count/2
	set -- $(bzcat $file.bz2 | sed -n ${median_line}p)
	printf "\n%7s directories.\n" $dir_count
	bzcat $file.bz2 |
	awk '    { KB += $1; count += 1 }
	     END { printf "Average directory size is %.1f KB\n",
				KB/count }'

	echo -e " Median directory size is ${1%K} KB ...\n"
	$Trace
	(( $dir_count > 100 )) && {
	local -i decile_count=$(( ($dir_count + 5) / 10 )) i
	local -i decile_median_line=decile_count/2
	for i in {0..9}
	    do	set -- $(bzcat $file.bz2 | sed -n ${decile_median_line}p)
		echo "Decile $i has median directory size of ${1}B"
		decile_median_line+=decile_count
	done
	echo
	}

	echo "--> histogram of directory sizes <--"
	echo "  count size"
	echo "  ----- ----"
	bzcat $file.bz2 | cut -f1 | uniq -c | sort -nr | head
	echo -e "    ...\n"

	set-total_dir_MB-avg_dir_KB $file.bz2
	echo "BUT...  The actual drive-space consumed by a directory is"
	echo "the size of its directory block(s) plus the size of its inode:"
	space="$total_dir_MB MB/snapshot"
	  avg="$avg_dir_KB KB/dir"
	echo -e "\n  all directories consume $space ($avg)\n\n"
}
readonly -f dir-sizes

# -----------------------------------------------------------------------------

filesystem-geometry() {
	set-drive_dirs--from-user-args "$@"

	run-df    $drive_dirs
	run-lsblk $drive_dirs
	echo

	local dash="------" dsh="---------------"
	local dash="======" dsh="==============="
	local    format="%-15s   %-8s%8s %8s %8s %8s %8s %8s\n"
	local f=$format strp="stripe " wdth="width  "
      printf "$f" ""   ""	""	""	""	"dir " "$strp"  "$strp"
      printf "$f" Mount	FS-type	sector	inode	block	block  "unit  "	"$wdth"
      printf "$f" $dsh ==$dash	$dash	$dash	$dash	$dash	==$dash	==$dash
	format=${format/\%25s/%-15s  %8s}
	local drive_name drive_dir	# protect caller's values
	for drive_dir in $drive_dirs
	    do	set-FS_type--from-path $drive_dir
		_set-drive_name $drive_dir
		set-FS_device--from-path $drive_dir
		[[ -L $FS_device ]] &&
		set-absolute_path $FS_device && FS_device=$absolute_path
		[[ $FS_device == /dev/mapper/* ]] && dev= ||
		dev=$(echo $FS_device | sed 's@.*/@@; /^[^-]*$/s/[0-9]*$//')
		case $FS_type in
		    ( ext? )
			# output _sometimes_ contains SPACEs (e.g. for inode=)
			RunCmd sudo tune2fs -l $FS_device > $tmp_1
			[[ ! $dev ]] && sector= ||
			sector=$(< /sys/block/$dev/queue/physical_block_size)
			inode=$(sed -n 's/^Inode size:.* //p' $tmp_1)
			block=$(sed -n 's/^Block size:.* //p' $tmp_1)
			dir_block=$block
			sunit=
			swidth=
			;;
		    ( xfs  )
			RunCmd xfs_info $drive_dir > $tmp # $tmp_1
		       sector=$(sed -nr '/at/s/.* sectsz=([^ ]+) .*/\1/p' $tmp)
			inode=$(sed -nr '/^m/ s/.* isize=([^ ]+) .*/\1/p' $tmp)
			block=$(sed -nr '/^d/ s/.* bsize=([^ ]+) .*/\1/p' $tmp)
		    dir_block=$(sed -nr '/^n/ s/.* bsize=([^ ]+) .*/\1/p' $tmp)
			sunit=$(sed -nr '/swi/s/.* sunit=([^ ]+) .*/\1/p' $tmp)
		       swidth=$(sed -nr '/^ /s/.* swidth=([^ ]+) .*/\1/p' $tmp)
			sunit="$sunit blks"
		       swidth="$swidth blks"
			;;
		    (  *   )
			printf "%-15s   %s is unknown FS type\n" \
				$drive_name $FS_type
			continue
			;;
		esac
		printf "$format" $drive_dir $FS_type \
		    "$sector" "$inode" "$block" "$dir_block" "$sunit" "$swidth"
	done
	rm $tmp_1
}
readonly -f filesystem-geometry

# -----------------------------------------------------------------------------

# Here's how to setup a brand new drive to be an encrypted drive

# If brand new drive, find its device name with: ls -lt /dev/sd?
# Save the device name and drive name: device=/dev/sdX  drive=Y
# Verify it's a new drive (which has partition table): fdisk -l $device
# See if someone is using it: fuser -v $device
# cryptsetup luksFormat $device /etc/snapcrypt/keys/keyfile.bin
#   (be SURE you type "YES" not "yes")
# Make sure encryption succeeded: fdisk -l $device # want no partitions
# Then run: snapcrypt open $device $drive (mount will fail).
# Then create new rule in /etc/snapcrypt/drives.rules .
# If have existing backup drives that are no bigger, use copy-drive .

# mkfs [-f] [mkfs-opts] device [name]: mkfs 1st/smallest drive (see comments)
function mkfs-backup-drive() {
	set-date_time
	line_1="if you're using a partition or LV that already has backups,"
	line_2="you can keep them, if you rename them as /Year-Mo-Da,Hr/ , "
	line_3="e.g. 'now' looks like /$date_time/ ; don't run 'mkfs',"
	line_4="just re-label the partition and change its record in /etc/fstab"
	line_5="(which is not needed if the partition is auto-mounted)."
	warn "$line_1\n   $line_2\n   $line_3\n   $line_4\n   $line_5"

	[[ ${1-} == -f ]] && shift || [[ $mkfs_cmd_opts == mkfs.xfs* ]] || {
	   echo "If this is your first or smallest drive, use the -f option;"
	   echo "otherwise, use the very-fast 'copy-drive' action instead."
	   abort-with-action-Usage
	} >&2
	mkfs_opts=$(echo " $*" | sed -r 's@^(.*) /dev/.*@\1@')
	set  --   $(echo " $*" | sed -r 's@.* /dev/@/dev/@')
	[[ $# == [12] ]] || abort-with-action-Usage
	local device=$1 name=${2-}
	TraceV 3 mkfs_opts device name
	[[ $device = /* ]] || device=/dev/$device
	[[ -b $device ]] || $IfRun abort "$device not a block device"

	if [[ $name ]]
	   then _set-drive_name $name
	   else _set-drive_name $device
	fi
	local name=$drive_name drive_dir
	[[ ${name,,} != all ]] ||
	    abort_function "name '$name' is a reserved word"
	_set-drive_dir

	mkfs_cmd=${mkfs_cmd_opts%% *}
	 FS_type=${mkfs_cmd#*.}
	[[ $FS_type != $mkfs_cmd ]] || abort "ask $coder to fix FS_type logic"
	local _mkfs_cmd_opts="$mkfs_cmd_opts "
	_mkfs_cmd_opts+="$mkfs_opts "

	set-FS_label--from-mount_dir $drive_dir

	# Since most files are shared between many snapshots, most of our
	# inodes are directories; so directory size determines space usage, so
	# we should choose a block size that will result in the smallest space
	# usage by directories (unless we only backup files that change often,
	# and they're large enough that ext* needs to use indirect blocks).
	# On my Ubuntu laptop, 1 KB blocks result in roughly half the
	# directory drive space used by 2 KB blocks, so the default block size
	# is 1KB.  On HRDAG's Ubuntu server using XFS, 1 KB blocks and 2 KB
	# blocks result in the same amount of directory space usage (and 4 KB
	# results in 20% more), since most directories need 0 drive blocks
	# (because their contents fit in the inode); so 2 KB blocks are
	# optimal for XFS, since they'll result in better performance.

	# To determine your actual average directory size, e.g. for ext4:
	#    # choose a filesystem type with mkfs_cmd_opts= in configure.sh
	#    snapback mkfs -b 1024 <drive-name>	# first time, use smallest -b
	#    # configure dirs_to_backup= and excludes
	#    snapback run-backup <drive-name>
	#    snapback dir-sizes  <drive-name>
	#
	#    snapback mkfs -b 2048 <drive-name> # overwrite older FS
	#    ...
	# If the FS stores small dirs in the inode, you might mess with isize.

	# ALSO, by making the block size smaller with ext*, you'll be able to
	# have more inodes if you have a lot of small files, see:
	# https://askubuntu.com/a/1104944 .  Having small blocks might reduce
	# performance on a rotational hard drive (unless you're using extents
	# and rsync's --preallocate), but probably won't affect performance on
	# an SSD or flash memory stick (unless you're using ext* and you have
	# lots of files with indirect blocks).

	# this block of code is only relevant to ext*
	[[ $_mkfs_cmd_opts != mkfs.[^e]* ]] && {
	local block_size=1024		# optimal, see above long comment
	set -- $_mkfs_cmd_opts
	while [[ $# != 0 ]]
	   do	[[ $1 == -b       ]] && block_size=${2-}
		[[ $1 == -b[0-9]* ]] && block_size=${1#-b}
		shift
	done
	local valid_block_sizes="1024 2048 4096"
	is-arg_1-in-arg_2 $block_size $valid_block_sizes ||
	   abort "ext* block size must be one of: $valid_block_sizes"
	local blocks_per_inode=1
	let    bytes_per_inode=$blocks_per_inode*$block_size
	TraceV 3 block_size bytes_per_inode
	}

	# There's no need to store small-files or file's extended-attributes
	# in inodes: The extra blocks used for small-files or out-of-inode
	# extended-attributes will be shared between snapshots, since file
	# inodes are shared between snapshots.  So, we want small inodes.
	# EXCEPT: If most of the backed-up _directories_ have
	# extended-attribute-blocks, then select an inode size that will hold
	# the average set of extended-attributes.  If you want to backup
	# nanosecond timestamps or file creation time on ext*, then use >= 256;
	# otherwise, use 128.

	# https://lwn.net/Articles/645722/ : 4/15: fixed ext4 extent corruption
	# https://en.wikipedia.org/wiki/Linux_kernel#Releases_4.x.y
	if [[ $FS_type == ext4 && $(uname -r) > 4.2.7 ]]
	   then local ext4_extent_opt="-O extent"
	   else local ext4_extent_opt=
	fi

	set -- $_mkfs_cmd_opts
	[[ $# != 0 ]] || abort "need to set mkfs_cmd_opts= in $config_file"
	local cmd=$1; shift; local opts="$* "  log_opt=
	  if [[ $cmd == mkfs.xfs ]]
	   then FS_type=xfs
		have-cmd mkfs.xfs || $IfRun abort "install xfsprogs"
		# The above comment predicts isize=256; but CRCs need size=512,
		# and 90% of HRDAG's server's dirs fit in a size=512 inode;
		# using isize=1024 resulted in 40% more directory drive space.
		# For servers with bigger dirs, experiment with different
		# mkfs opts (on your fastest drive) and the dir-sizes action.
		#
		# See much-earlier long comment for discussion of block size.
		[[ $opts == *"-b size="* ]] || opts+="-b size=4096 "
		[[ $opts == *"-n size="* ]] || opts+="-n size=4096 "
		[[ $opts == *"-i size="* ]] || opts+="-i size=512 "
		[[ $opts == *maxpct=*    ]] || opts+="-i maxpct=0 "
		mount_opts="$XFS_mount_options"
		set-FS_external_log $FS_label &&
		logdev="logdev=$FS_external_log" &&
		log_opt="-l $logdev"  mount_opts=$mount_opts,$logdev
	elif [[ $cmd == mkfs.ext? ]]
	   then FS_type=${cmd#*.}
	elif [[ $cmd == mke2fs ]]
	   then FS_type=$(echo $opts | sed -r 's/.*\W-t\W*(\w+)\b.*/\1/')
		[[ $FS_type ]] || FS_type=ext4
	elif [[ $cmd != mk* ]]
	   then abort "the value of 'mkfs_cmd_opts' should start with 'mk'"
	   else abort "don't support '$cmd $opts', email $coder"
	fi
	#
	if ! [[ $FS_type == ext? && $debug_opt && $UID == 0 ]]
	   then local mkfs_debug_opt=
	   else local mkfs_debug_opt=-n
		warn "running mkfs.$FS_type in debug mode ..."
	fi
	if [[ $FS_type == ext? ]]
	   then opts+="-v "
		[[ $opts != *-T* ]] && {
		[[ $opts != *-b* ]]	&& opts+="-b $block_size "
		[[ $opts != *-i* ]]	&& opts+="-i $bytes_per_inode "
		[[ $opts != *-I* ]]	&& opts+="-I 128 "	; }
		[[ $opts != *-m* ]]	&& opts+="-m .1 "
		[[ $opts != *extent* ]] && opts+="$ext4_extent_opt "
		[[ $FS_type == ext4  ]] &&
		mount_opts="$extN_mount_options"
		set-FS_external_log  $FS_label &&
		log_label=$(basename $FS_external_log)	&&
		$IfRun mke2fs -v -b $block_size -O journal_dev \
			 -L $log_label $FS_external_log &&
		log_opt="-J device=$FS_external_log"
	fi

	df -m | grep " $drive_dir$" &&
	  $IfRun abort "there's already a filesystem mounted on $drive_dir"
	[[ $FS_type == xfs && $opts == *' -N '* ]] || {
	[[ -d $drive_dir ]] &&
	  $IfRun abort "directory $drive_dir/ exists: is name '$name' in use?"
	df -m | grep "^$device[ 	]" &&
	  $IfRun abort "that device is mounted; to *DESTROY* its contents,
			first run: umount $device"
	}

	[[ $UID == 0 ]] || $IfRun abort "run with sudo"

	[[ $mount_opts ]] && mount_opts=,$mount_opts
	mount_opts=$common_mount_options$mount_opts
	rec="\n\n\tLABEL=$FS_label\t$drive_dir\t$FS_type\t$mount_opts 0 2"
	warn "sample record for /etc/fstab (optional with 'snapcrypt'):$rec"

	[[ $mkfs_debug_opt ]] && IfRun=
	cmd="$cmd ${opts# } $log_opt $mkfs_debug_opt -L $FS_label $device"
	header "$cmd"
	RunCmd  $cmd
	archive-rsync-time-data
	[[ $mkfs_debug_opt ]] && IfRun=echo
	$IfRun mkdir -p $drive_dir
	RunCmd mount -v -t $FS_type -o $mount_opts $device $drive_dir
	fix-drive_dir-perms $drive_dir

	echo -e "\nTo populate newly-created drive, run:\n
	nohup $_our_name update-drive $drive_name	# creates new job"

       warn "DON'T FORGET to add \`$name' to drive_name_regex= in $config_file"
       return 0
}
readonly -f mkfs-backup-drive

# -----------------------------------------------------------------------------

_assert-dst-big-enough() {

	local msg
	if set-device_KB--from-block-device $src_device
	   then declare -i src_KB=$device_KB
		set-device_KB--from-block-device $dst_device
		local -i KB_missing=$(( src_KB - device_KB ))
		(( KB_missing > 0 )) || return 1
		local -i MB=KB_missing/1024
		local -i GB=MB/1024 &&
		msg="$dst_name's $dst_device is too-small by $MB MB ($GB GB)"
		abort "$msg;\n  specify -D to *not* use 'dd' (use dump/retore)"
	   else msg="$dst_device MUST be as-large as $src_name's $src_device"
		warn "the new $msg"
	fi
}
readonly -f _assert-dst-big-enough

# --------------------------------------------

# these 3 variables are global variables initialized elsewhere
set-drive_name-FS_device-drive_dir-FS_label() {
	local name=$1 device=${2-}

	[[ $device$name ]] || abort "need 1 non-null argument"

	[[ $name == /dev/* ]] && device=$name && name=

	[[ $name ]] && set-drive_name $name && name=$drive_name
	[[ !  $device ]] &&
	   set-FS_label--from-mount_dir $drive_dir_prefix$name &&
	   set-FS_device--from-FS-label $FS_label && device=$FS_device
	[[ -b $device ]] || abort "$device is not a block device"

	if [[ ! $name ]]
	   then set-FS_label--from-FS-device $device
		name=$FS_label
	fi

	FS_device=$device
	_set-drive_name $name
	_set-drive_dir
	set-FS_label--from-mount_dir $drive_dir

	TraceV 1 device name drive_name FS_device drive_dir FS_label
}
readonly -f set-drive_name-FS_device-drive_dir-FS_label

# ---------------------------------

copy-backup-drive() {
	action_opts=
	while [[ ${1-} == -* ]] ; do action_opts+="$1 "; shift; done
	[[ $# != 0 ]] ||
	abort "[-f] [-D] [-M] [-F] {src_name | src_dev} {dst_name dst_dev | '' dst_dev | dst_name}"
	local src=$1 dst_name=$2 dst_device=${3-}

	[[ -t 1 ]] || $IfRun abort "don't use 'nohup', we'll run 'nohup'"

	$Trace
	set-drive_name-FS_device-drive_dir-FS_label $src
	local src_name=$drive_name
	local src_device=$FS_device
	local src_drive_dir=$drive_dir
	local src_FS_label=$FS_label

	set-drive_name-FS_device-drive_dir-FS_label "$dst_name" $dst_device
	local dst_name=$drive_name
	local dst_device=$FS_device
	local dst_drive_dir=$drive_dir
	local dst_FS_label=$FS_label

	set-FS_type--from-path $src_device
	if [[ $FS_type == xfs ]] || is-arg_1-in-arg_2 -D $action_opts # not dd?
	   then warn "'dump | restore' can take weeks; it's probably better to run another 'mkfs', then enable backups plus run 'update-drive $dst_name'"
	   else _assert-dst-big-enough
		# show the user a sample fstab record
		IfRun=echo mkfs-backup-drive -f $dst_device $dst_name |&
		  # search for the last two fields in the fstab record
		  egrep -B 3 "[[:space:]][0-9]+[[:space:]]+[0-9]+[[:space:]]*$"
	fi

	set --	$our_path $our_opts finish-$action $action_opts \
		$src_device $src_drive_dir \
		$dst_device $dst_drive_dir
	local cmd=$*

	if [[ $debug_opt ]]
	   then header "$_our_name ${cmd#* }"
		exec $cmd || abort "$cmd -> $?"
	fi

	local output_file=$dst_FS_label.out
	echo -e "
	nohup'ing commands to copy partition '$src_name' to '$dst_name';
	this takes about a day per TB of drive space.  Now running
	'exec tail -f $output_file'; you can hit CTRL-C when you get bored.
	"
	nohup $cmd > $output_file &
	local copy_PID=$!
	sleep 0.1; set -x; exec tail --pid=$copy_PID -f $output_file
}
readonly -f copy-backup-drive

# ------------------------------------------------------------------

_prepare-for-dump-restore() {
	if [[ ${1-} == -S ]]		# src doesn't need to be mounted?
	   then is-drive-mounted $src_drive_dir || local src_name=
		local src_drive_dir=
	fi

	local FS_type src_FS_type
	set-FS_type--from-path $src_device
	src_FS_type=$FS_type
	set-FS_type--from-path $dst_device
	[[ $src_FS_type == $FS_type ]] ||
	   $IfRun abort "FS_type of $dst_device must be '$src_FS_type'"

	assert-not-in-cron-jobs $src_name $dst_name

	local drive
	for drive in $src_drive_dir $dst_drive_dir
	    do	is-drive-mounted $drive || $IfRun abort "mount drive $drive"
	done

	kill-job-on-drives all {$src_name,$dst_name}

	if [[ ${drive_name_regex-} ]]
	   then local where=drive_name_regex=
	   else local where=cron
	fi
	warn "as soon as dump finishes, you can add it back to $where"
}
readonly -f _prepare-for-dump-restore

# ---------------------------------

show-iostat() {
	local device=$1

	$IfRun iostat -y -m -d $device | grep -v -e '^Linux' -e '^$'
}
readonly -f show-iostat

# ---------------------------------

function _dump-restore-xfs-backup-drives {

	_prepare-for-dump-restore

	$IfRun set -x

	$IfRun xfs_freeze -f $src_drive_dir

	if [[ -d $dst_drive_dir/xfsrestorehousekeepingdir ]]
	   then local restore_opt=-R
	   else local restore_opt=
	fi

	trap '' INT			# don't interrupt xfsdump or xfsrestore
	show-iostat $dst_device
	time $IfRun    xfsdump -J -p 600       - $src_drive_dir |
	     $IfRun xfsrestore -J $restore_opt - $dst_drive_dir
	local status=$?
	show-iostat $dst_device

	$IfRun xfs_freeze -u $src_drive_dir

	return $status
}
readonly -f _dump-restore-xfs-backup-drives

# ---------------------------------

function _dump-restore-extN-backup-drives {

	_prepare-for-dump-restore -S

	have-cmd dump || abort "need to install the 'dump' command"

	$IfRun set -x

	# https://stackoverflow.com/questions/37488629/how-to-use-dump-and-restore-to-clone-a-linux-os-drive
	cd_ $dst_drive_dir
	trap '' INT			# don't interrupt dump or restore
	show-iostat $dst_device
	time $IfRun   dump -a0f - $src_device |
	     $IfRun restore -rf -
	local status=$?
	show-iostat $dst_device

	return $status
}
readonly -f _dump-restore-extN-backup-drives

# --------------------------------------------

_copy-extN-backup-drive() {

	is-arg_1-in-arg_2 -f $action_opts ||
	for drive_dir in $src_drive_dir $dst_drive_dir; do
	if is-drive-mounted $drive_dir
	   then set -- $(list-drive-dirs |
			 fgrep -v -w -e $src_drive_dir -e $dst_drive_dir)
		[[ $# == 0 ]] &&
		msg="
	There are no other backup partitions mounted besides the ones used to
        copy $src_drive_dir to $dst_drive_dir ; if you let me unmount these
	partition(s), no new backups will be made for many hours (or days).

	You might instead run '$_our_name mkfs' on the new drive, leave the old
	drive mounted, and run:

		cd $src_drive_dir
		nohup rsync -aSHX * $dst_drive_dir/ &

	To instead unmount both drives and do a fast 'dd'," ||	msg="
	$src_drive_dir is mounted;"
		abort "\n$msg re-run copy-drive with -f to Force unmount."
	fi; done

	unmount-drives -q $src_drive_dir $dst_drive_dir ||
	   $IfRun abort "unmount the drive that failed to 'umount'"

	# -------------------------------------------------------

	$IfRun set -x
	time RunCmd dd if=$src_device of=$dst_device bs=1M
	[[ $Trace ]] || set +x

	$IfRun tune2fs -U $(uuidgen) $dst_device

	label-drive $dst_device $dst_drive_dir

	if sudo tune2fs -l $src_device | grep -q "^Journal dev" || # external?
	   [[ $do_want_external_log ]]
	   then add-extN-journal -M $dst_name $dst_device ||
		   abort "need to fix journal on $src_device: $_our_name aej"
	fi

	local mount_options=$common_mount_options,$extN_mount_options
	mount_options=${mount_options%,}

	is-arg_1-in-arg_2 -M $action_opts || # don't want to re-Mount src?
	RunCmd mount -v -t $FS_type -o$mount_options $src_device $src_drive_dir

	is-arg_1-in-arg_2 -F $action_opts || # don't want Fsck?
	time RunCmd -m "better check $src_device ?!" \
	e2fsck -f -p -t -t $dst_device

	$IfRun mkdir -p $dst_drive_dir
	RunCmd -m "make mount happen, then run resize2fs" \
	mount -v -t $FS_type -o $mount_options $dst_device $dst_drive_dir

	RunCmd resize2fs $dst_device	# do this _after_ mount, for speed
}
readonly -f _copy-extN-backup-drive

# --------------------------------------------

# finish-copy-drive: copy, label & UUID, replace journal, fsck, mount, resize
function finish-copy-backup-drive() {
	action_opts=
	while [[ ${1-} == -* ]] ; do action_opts+="$1 "; shift; done
	local cmd=$(echo "$Usage" |
		    grep copy-drive | sed "s/^ */$_our_name -d /; s/:.*//")
	[[ $# == 4 ]] || abort "to see args, run: $cmd"

	local src_device=$1 src_drive_dir=$2
	local dst_device=$3 dst_drive_dir=$4

	local src_name=${src_drive_dir#$drive_dir_prefix}
	local dst_name=${dst_drive_dir#$drive_dir_prefix}

	customize-and-validate-configuration-variables $dst_name

	[[ $UID == 0 ]] || $IfRun abort "run with sudo"

	set-FS_type--from-path $src_device
	case $FS_type in
	   ( ext?) if is-arg_1-in-arg_2 -D $action_opts
		      then _dump-restore-extN-backup-drives
		      else _copy-extN-backup-drive
		   fi ;;
	   ( xfs ) _dump-restore-xfs-backup-drives  ;;
	   (  *  ) abort "write FS function call for $FUNCNAME, email $coder";;
	esac ||
	   abort "the copy seems to have failed with $?, check .out file"
	set +x

	local var=drive_name_regex
	warn "DON'T FORGET: add $src_name & $dst_name to $var= in $config_file"
	return 0
}
readonly -f finish-copy-backup-drive

##############################################################################-
##############################################################################-
# Random maintenance functions.
##############################################################################-
##############################################################################-

function check-snapshot-hard-links() {
	local name=$1

	[[ ${very_old_immutable_files-} ]] ||
	   abort "setup very_old_immutable_files= in $config_file"

	set-drive_name $name
	set-drive_dir  $drive_name
	cd_ $drive_dir

	set-inum() {
		[[ -r $1 ]] || abort "run with sudo"
		set -- $(ls -i -d $1 2>/dev/null)
		inum=$1
		[[ $inum ]]
	}

	set -- $snapshot_glob*

	local -A file2inum
	for old_file in $very_old_immutable_files
	    do	$IfRun sudo -n chattr +i $old_file &> /dev/null # optional
		file=$1$old_file
		set-inum $file ||
		  abort "$drive_name: $file missing from oldest snapshot $1"
		file2inum[$old_file]=$inum
	done
	$Trace
	partials=
	while [[ $# != 0 ]]
	    do	found_good_link=$false
		for old_file in $very_old_immutable_files
		    do	old_inum=${file2inum[$old_file]}
			set-inum $1$old_file
			[[ $old_inum == $inum ]] || continue
			found_good_link=$true
			break
		done
		[[ $found_good_link ]] && partials= && shift && continue
		[[ $1 == *.partial  ]] && partials+="$1 " &&
						       shift && continue

		$IfRun mkdir -p .rm
		set -- $partials $*
		warn "$drive_name: the following have broken hard-links: $*"
		return 1
	done
	echo "$drive_name: no broken hard-links!"
}
readonly -f check-snapshot-hard-links

# -----------------------------------------------------------------------------
# regression tests for "old" (installed) vs "tst" (workspace) snapback
# -----------------------------------------------------------------------------

chroot-backup() {
	local date_time=$1; shift; local command=${*-}

	local drive_dir snapshots=
	[[ $date_time == /* ]] && snapshots=$date_time ||
	for drive_dir in $(list-drive-dirs -a)
	    do	local  snapshot=$drive_dir/$date_time
		[[ -d $snapshot ]] && snapshots+="$snapshot "
	done
	[[ $snapshots ]] || abort "can't find snapshot matching $date_time"

	set -- $snapshots
	[[ $# == 1 ]] || { set-drive_name2do_suspend
			   set -- $(fastest-snapshots $snapshots) ; }
	local chroot_dir=$1

	$Trace
	have-proc && {
	$IfRun sudo mount -o bind /proc    $chroot_dir/proc
	$IfRun sudo mount -o bind /dev     $chroot_dir/dev
	$IfRun sudo mount -o bind /dev/pts $chroot_dir/dev/pts
	$IfRun sudo mount -t tmpfs tmpfs   $chroot_dir/dev/shm
	$IfRun sudo mount -t tmpfs tmpfs   $chroot_dir/run
	$IfRun sudo mount -t sysfs sys     $chroot_dir/sys		; true
	} ||
	$IfRun sudo mount -t devfs devfs   $chroot_dir/dev # Darwin/BSD

	[[ $is_regression_test ]] || echo "Have to remount drive, slow ..."
	$Trace
	$IfRun sudo mount -o remount,dev,suid	  $(dirname $chroot_dir)
	$IfRun sudo chroot $chroot_dir $command
	$IfRun sudo mount -o remount,nodev,nosuid $(dirname $chroot_dir)

	have-proc && {
	for dir in proc dev/pts dev/shm dev run sys
	    do	$IfRun sudo umount $chroot_dir/$dir
	done								; true
	} ||    $IfRun sudo umount $chroot_dir/dev # Darwin/BSD
}
readonly -f chroot-backup

# -----------------------------------------------------------------------------

_show-test-header() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	header "$* (first number is sorted md5sum, second is unsorted)"
	$xtrace
}
readonly -f _show-test-header

# ---------------------------------

_show-test-results() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local output_file=$1

	[[ -s $output_file ]] &&
	echo "$(sort $output_file | md5sum) $(md5sum $output_file)"
	$xtrace
}
readonly -f _show-test-results

# --------------------------------------------

_run-debug-cmds() {
	local test=$1; shift
	local args=$*

	local tmp_o=$tmp_dir/o$test	# holds output from "old" cmd
	local tmp_t=$tmp_dir/t$test	# holds output from "tst" cmd

	local old_cmd_="$old_cmd -C -d $trace_opt $args"
	local tst_cmd_="$tst_cmd -C -d $trace_opt $args"

	if [[ $debug_opt ]]
	   then echo "$old_cmd_ &> $tmp_o"
		echo "$tst_cmd_ &> $tmp_t"
		return
	fi

	$Trace
					   _show-test-results $tmp_o
	$tst_cmd_ &> $tmp_t || abort tst ; _show-test-results $tmp_t
	[[ $test == u ]] && set-srcs_dst_file && cp $srcs_dst_file $tmp_t.args
	cmp -s $tmp_o $tmp_t && { set +x; echo "-- same results!"; return; }

	echo -e "\nSince different results, we'll regenerate cached data ..."
	PATH=${old_cmd%/*}:$PATH \
	$old_cmd_ &> $tmp_o || abort old ; _show-test-results $tmp_o
					   _show-test-results $tmp_t
	[[ $test == u ]] && set-srcs_dst_file && cp $srcs_dst_file $tmp_o.args
	cmp -s $tmp_o $tmp_t && { set +x; echo "-- same results!"; return; }

	set +x
	echo "-- DIFFERENT results, compare with: diff -u $tmp_o $tmp_t | less"
	[[ $test == u ]] &&
	echo "... also check copy args: diff -u $tmp_o.args $tmp_t.args | less"

	failed_tests+="$test "
}
readonly -f _run-debug-cmds

# ---------------------------------

readonly regression_tests="b c z p u"

function regression-test() {
	local tests=${*:-$regression_tests}
	[[ $tests == [A-Z] ]] && tests=${regression_tests/${tests,}/}

	[[ -x $old_cmd ]] || abort "fix old_cmd= in $config_file"
	[[ -x $tst_cmd ]] || abort "fix tst_cmd= in $config_file"

	echo -e "\nComparing $old_cmd to $tst_cmd"

	local failed_tests=

	# --------------------------------------------

	is-arg_1-in-arg_2 b $tests && {
	_show-test-header backup all
	_run-debug-cmds b run-backups all
	}

	# --------------------------------------------

	is-arg_1-in-arg_2 c $tests && {
	_show-test-header copy to Z
	set -- $drive_dir_prefix*/$snapshot_day_glob,00
	[[ $# != 0 ]] || abort "copy test needs at least one snapshot"
	src_snapshots=$1
	[[ -d $2 ]] && src_snapshots+=" $2"
	_run-debug-cmds c copy-snapshot $src_snapshots Z
	}

	# --------------------------------------------

	is-arg_1-in-arg_2 z $tests && {
	set -- ${drive_dir_prefix}Z/$snapshot_glob
	(( $# > 10 )) || $our_path test-prune || abort "can't setup Z"
	_show-test-header prune Z
	_run-debug-cmds z prune-drive Z
	}

	# --------------------------------------------

	is-arg_1-in-arg_2 p $tests && {
	_show-test-header prune all
	_run-debug-cmds p prune-drives all
	}

	# --------------------------------------------

	is-arg_1-in-arg_2 u $tests && {
	local dst=${update_test_dst_drive-}
	[[ $dst ]] || abort "$config_file needs update_test_dst_drive for 'u'"
	_show-test-header update $dst

	_set-drive_name $dst
	have-job copy &&
	$our_path kill copy $dst &> /dev/null && killed_dst=$dst &&
	    warn "killed update-drive (or copy) on drive $dst"

	_run-debug-cmds u update-drives $dst

	[[ ${killed_dst-} ]] &&
	warn "remember to restart your copy/update job on drive $killed_dst"
	}

	if [[ $failed_tests ]]
	   then warn "ERROR: regressions in these tests: ${failed_tests% }"
	   else	set-warning_string ok \
		   "all the (specified) tests passed: $tests"
		echo -e "\n$warning_string\n"
	fi
}
readonly -f regression-test

#############################################################################
#############################################################################
# Process the requested action with the above functions & global variables. #
#############################################################################
#############################################################################

[[ $# != 0 ]] || abort "specify an action to perform\n$Usage"

action=$1; shift
_our_name="$our_name"
 our_name="$our_name $action"
undo-action-abbrev() { readonly action=$1 our_name="$_our_name $1" _our_name; }

# ---------------------------------

process-action() {

stack_frame_to_show=0		# show line-number inside the 'case' statement

case $action in
  # list-drives [-a]: list mounted backup drives; -a adds drives cron ignores
   ( l*s*dr*v* | ld | ls | df ) undo-action-abbrev list-drives
	list-drive-dirs "$@"
	;;
   # run-backups   names: backup names ('all' for every mounted backup drive)
   ( r*b*k*p* | rb* ) undo-action-abbrev run-backups
	[[ $# != 0 ]] || abort-with-action-Usage
	[[ $1 == all ]] && rm-stale-locks
	create-jobs backup "$@"
	if [[ $is_cron ]]
	   then wait			# want to stay in 'ps'; but ...
#		$IfRun $our_path monitor-drives & # ... not for monitor
	   else true
	fi
	;;
  # prune-drives  names: prune  names ('all' for every "" ""); see configure.sh
   ( pr*n*dr*v* | pd* ) undo-action-abbrev prune-drives
	[[ $# != 0 ]] || abort-with-action-Usage
	create-jobs prune "$@"
	[[ ! $is_cron ]] || wait	# so see master cron job in ps
	;;
   # update-drives [-d] [-s src-names-regex] dst-names: copy missing snapshots
   ( upd*dr*v* | u*d* ) undo-action-abbrev update-drives
	[[ $1 == -d  ]] && {  debug_copy=$1; shift; } ||  debug_copy=
	[[ $1 == -s  ]] && { src_names_regex_opt="$1$2"; shift 2; }
	[[ $1 == -s* ]] && { src_names_regex_opt="$1"  ; shift  ; }
	[[ $1 == -r  ]] && { recurse_opt=$1; shift; } || recurse_opt=
	assert-not-option -o ${1-}
	[[ $# != 0   ]] || abort-with-action-Usage
	create-jobs update ${src_names_regex_opt-} $recurse_opt $*
	# [[ ! $is_cron ]] || wait	# so see master cron job in ps
	;;
   # NOTE: this must appear before copy-snapshots (it has 'cs' as a shortcut)
   # check-snapshot-hard-links names: find snapshots with broken hard links
   ( c*s*h*l* ) undo-action-abbrev check-snapshot-hard-links
	[[ $# != 0   ]] || abort-with-action-Usage
	set-drive_names--from-user-args "$@"

	status=0
	for name in $drive_names
	    do	check-snapshot-hard-links $name || status=$?
	done
	exit $status
	;;
   # copy-snapshots [-d] [-q] snapshots name: copy to 'name' mounted drive
   ( c*p*s*s* | cs* | cp* ) undo-action-abbrev copy-snapshots # cpss
	[[ $1 == -d  ]] && {   debug_copy=$1; shift; } ||   debug_copy=
	[[ $1 == -q  ]] && {    quiet_opt=$1; shift; } ||    quiet_opt=
	[[ $1 == -s* ]] && { src_snap_opt=$1; shift; } || src_snap_opt=
	[[ $1 == -r  ]] && {  recurse_opt=$1; shift; } ||  recurse_opt=
	assert-not-option -o ${1-}
	(( $# >= 2   )) || [[ $src_snap_opt && ${1-} ]] ||
	    abort-with-action-Usage
	drive_name=${!#}
	src_snapshots=${*%$drive_name}

	[[ $recurse_opt ]] && { create-jobs copy $src_snap_opt -r $*; exit; }

	set-drive_name $drive_name
	set-drive_dir  $drive_name

	lock copy || exit 1
	for snapshot in $src_snapshots
	    do	create-jobs copy $quiet_opt -s$snapshot $drive_name
	done
	unlock copy
	;;

  # snapshot-size dir: size of non-hard-linked files (ie in no other snapshots)
   ( snapshot*size | ss ) undo-action-abbrev snapshot-size
	[[ $# == 1 ]] || abort-with-action-Usage
	dir=$1
	[[ -d $dir ]] || abort "dir '$dir' doesn't exist"
	warn "this could take hours"
	$Trace
	KB=$(sudo find $dir -links 1 -printf '%k\n' |
		awk '{ total += $1 } ; END { print total }')
	set-readable_du_size $KB
	du_size=$readable_du_size
	echo "$dir contains >= $du_size of files in no other directories"
	;;

   # w: show full details on all jobs and drives
   # watch [-f][-C][-N names] [watch-opts]: dashboard (-f: wide; -C: cron jobs)
   ( watch | wa* | wt* | w ) [[ $action != w ]] && undo-action-abbrev watch
	watch "$@"
	;;

   # kill [-signal] job-type-glob  name-glob: job-types are backup, copy, prune
   ( kil* | k ) undo-action-abbrev kill
	[[ ${1-} == -* ]] && { signal=$1; shift; }
	[[ $# == 2 ]] || abort-with-action-Usage
	$Trace
	kill-job-on-drives ${signal-} "$@"
	;;
   # continue	   job-type-glob  name-glob: as above, but -CONT signal
   ( con* | c ) undo-action-abbrev continue
	[[ $# == 2 ]] || abort-with-action-Usage
	$Trace
	kill-job-on-drives -c "$@"
	;;
   # suspend	   job-type-glob  name-glob: as above, but -STOP signal
   # stop	   job-type-glob  name-glob: as above, but -STOP signal
   ( sus* | st*p | s ) undo-action-abbrev suspend
	[[ $# == 2 ]] || abort-with-action-Usage
	$Trace
	kill-job-on-drives -s "$@"
	;;
   # ps [ps-opts] [type-glob [name-glob]]: show holders of lock(s)
   ( ps )
	ps-locks "$@"
	;;

   # reset-priority [names]: reset job priorities on drives (defaults to all)
   ( r*p* ) undo-action-abbrev reset-priority
	set-drive_names--from-user-args "$@"

	$Trace
	for drive_name in $drive_names
	    do	_set-drive_dir $drive_name
		suspended-prune-as-drive-usage-response
	done
	;;

   ###########################################################################
   # filesystem maintenance actions
   ###########################################################################

   # monitor-drives: start run-forever monitor of drive response time
   ( mon* | m ) undo-action-abbrev monitor-drives
	[[ $1 == -r ]] || $IfRun exec sudo setsid $our_path $action -r ||
	    abort "you need sudo perms"
	shift

	trap '' HUP
	monitor-drives "$@"
	;;

   ( add*extN*journal | aej ) undo-action-abbrev add-extN-journal
     add-extN-journal "$@"
	;;

   ( dir*sizes | ds ) undo-action-abbrev dir-sizes
     dir-sizes "$@"
	;;

   # filesystem-geometry [-a|-A|drive-dirs]: show sector, inode, block, etc
   ( filesystem*geometry | f*g ) undo-action-abbrev filesystem-geometry
     filesystem-geometry "$@"
	;;

   # mkfs [-f] [mkfs-opts] device name: run mkfs optimized for many snapshots
   ( mkfs | mf* ) undo-action-abbrev mkfs
     mkfs-backup-drive "$@"
	;;
   # copy-drive {src_name | src_dev} dst_name [dst_dev]: duplicate backup drive
   ( c*p**dr*v* | cpd ) undo-action-abbrev copy-drive
     copy-backup-drive "$@"
	;;
   # finish-copy-drive: only used internally
   ( f*c*p*dr*v* | f*c*p*d* | fcd ) undo-action-abbrev finish-copy-drive
     finish-copy-backup-drive "$@"
	;;

   ###########################################################################
   # Actions for regression tests.
   ###########################################################################

   # mk-Z [date [period]]: create mostly-empty snapshot dirs in Z mount-point
   ( mk*[Zz] | mkz ) undo-action-abbrev mk-Z
	[[ $1 == -q ]] && { is_quiet=$true; shift; } || is_quiet=$false
	[[ $1 != -* ]] || abort "unknown option $1"

	# The following designed to work with (custom) configure.sh span of 1,
	#    and are memorialized in action test-prune.
	# Test pruning of hours: snapback mk-Z 12/22/2099 0..23 # 0, 2 seconds
	#    ...  days & months: snapback mk-Z 1/1/2094   0	# 5,14 seconds
	#    ... months & years: snapback mk-Z 1/1/2010   month # 58,8 seconds

	# 1/1/2010 is earliest day, earlier days (e.g. 091231) look like octal
     readonly end_date="1/1/2100"	# keep constant, so can compare
	    start_date=${1:-12/22/2099}	# tests hours with ...
	        period=${2:-0..23}	# sequence of hours, else 'month'

	set-drive_dir Z
	cd_ $drive_dir
	[[ $debug_opt ]] ||
	rm -rf *

	hours=00 is_months=$false
	case $period in
	    ( 0 ) ;;
	    ( month* ) is_months=$true ;;
	    ( * ) eval "set -- {$period}" ; hours=$* ;;
	esac

	local -i start_secs=$(date -d "$start_date" '+%s')
	local -i   end_secs=$(date -d   "$end_date" '+%s')
	local -i secs=start_secs secs_per_day=24*60*60
	let end_secs-=3600		# end at 11 PM on previous day
	while  ((  secs < end_secs ))
	   do	set-day--from-secs $secs
		secs+=secs_per_day
		[[ $day == *01 || ! $is_months ]] || continue
		[[ $day != 0* ]] || abort "start date must be after 1/1/2010"
		for hour in $hours
		    do	[[ $hour == ? ]] && hour=0$hour
			snapshot=$day,$hour
			[[ -d $snapshot ]] || echo $snapshot
		done
	done | xargs -r $IfRun mkdir || abort mkdir

	# setup partial snapshots mid-date, to test pruning
	local -i mid_secs="start_secs+(end_secs-start_secs)/2"
	set-day--from-secs $mid_secs; mid_day=$day
	TraceV 7 start_date mid_day end_date
	for hour in 00 02 04 08 09 12
	    do	for ext in links partial
		    do	snapshot=$mid_day,$hour.$ext
			$IfRun mkdir -p $snapshot
		done
	done

	set-day--from-secs $start_secs
	snapshot=$day,00
	for subdir in /var/repos/snap.test ~/{tmp,git/pylint}
	    do	bad_dir=$snapshot$subdir/deleteme
		$IfRun mkdir -p $bad_dir
		$IfRun touch    $bad_dir/deleteme.txt
	done
	[[ $is_quiet ]] ||
	Trace 0 "created excludable-junk in $snapshot"

	# there was something else that needed to be tested??
	for file in
	    do	true
	done

	$IfRun rm -rf .mk-Z
	$IfRun mkdir  .mk-Z	; [[ $debug_opt ]] ||
	cp -al *    .mk-Z/
	;;

   # test-prune: use mk-Z to run pruning regression test in the Z pseudo-drive
   ( test*prune | tp ) undo-action-abbrev test-prune
	[[ $# == 0 ]] || abort-with-action-Usage

	[[ $UID != 0 ]] || abort "do not run this as root"

	customize-and-validate-configuration-variables Z

	cmd_dirs="/usr/local/bin/ ~/git/$_our_name/bin/"
	echo -e "\nComparing prune results using '$_our_name' in:
	${cmd_dirs/ / vs }"
	set-drive_dir Z

	# see the comment at the top of the mk-Z option, above
	local -A prune_type2mk_Z_args=(
	      [hour]="12/22/2099 0..23"
	 [month-day]="1/1/2094 0"
	[year-month]="1/1/2010 month"
	)

	clone-stashed-mk-Z() {
		local type=$1 stash=.mk-Z.$1
		suspend-tracing
		rm -rf $snapshot_glob* la* && cp -al $stash/* . ||
		   abort "failed to clone $stash"
		restore-tracing
	}

	$Trace
	cd_ $drive_dir
	for type in $(echo ${!prune_type2mk_Z_args[*]} | tr ' ' '\n' | sort)
	    do	mk_Z_args=${prune_type2mk_Z_args[$type]}
		header "prune '$type' snapshots, created by: mk-Z $mk_Z_args"
		stash=.mk-Z.$type
		$IfRun rm -rf $stash.*.ls
		[[ ! -d $stash ]] && {
		$IfRun $our_path mk-Z -q $mk_Z_args &&
		   $IfRun mv .mk-Z $stash && $IfRun rm -f $stash/latest ||
			abort "couldn't populate $stash"; }
		for dir in $cmd_dirs
		    do	eval "dir=$dir"	# expand ~
			$IfRun clone-stashed-mk-Z $type
			$IfRun $dir$_our_name $our_opts prune-drive Z |&
			   fgrep -v ' prune-drive Z: pruned '
			[[ $dir == /usr/* ]] && cmd=old || cmd=new
			ls > $stash.$cmd.ls
		done
		set -- $(echo $stash.*.ls | sort -r)
		diff -q $* && mv $stash.new.ls $stash.pruned.ls &&
			      rm $stash.old.ls &&
		   echo -e "\nSame results, see $stash*" && continue
		warn "regression, see: diff -u $*"
	done

	clone-stashed-mk-Z hour
	echo -e "\nLeft a lot of unpruned snapshots in Z, for other testing."
	;;

   # regression-test [tests]: check functionality, see $tmp_dir/?? for results
   ( r*t* ) undo-action-abbrev regression-test
	# $Trace
	regression-test "$@"
	;;
   # chroot-backup date,time [command]: chroot to snapshot on fastest drive
   ( chr* | cb ) undo-action-abbrev chroot-backup
	chroot-backup "$@"
	;;

   ###########################################################################
   # actions for snapcrypt to call
   ###########################################################################

   # WARNING: this should only be called by "snapcrypt close"
   # unmount names: for each name (can be 'all'), kill backup & unmount drive
   ( u*mount | u ) undo-action-abbrev unmount # umount
	[[ $# != 0 ]] || abort "pass drive names"
     unmount-drives "$@"
	;;
   # for "snapcrypt close": don't eject if didn't get any backups today
   ( has*new*snapshots | hsn ) undo-action-abbrev has-new-snapshots
	drive=$1
	[[ $drive == *Z ]] && exit 0	# for debugging

	$Trace
	is-drive-mounted $drive || exit 0
	suspend-tracing
	set -- $drive/$snapshot_glob	# all the _successful_ snapshots
	restore-tracing
	latest_snapshot=${!#}
	[[ $# != 0 && -d $latest_snapshot ]] ||
	    abort "$drive has no (successful) snapshots"
	latest_date_time=$(basename $latest_snapshot)
	latest_day=${latest_date_time%,??}
	# let latest_day=latest_day-1		# uncomment to debug
	set-date_time
	day=${date_time%,??}
	[[ $latest_day == $day ]] ||
	    abort "$drive has no (successful) backups since $latest_day"
	;;
   # for "snapcrypt close": find drive with max # snapshots since last mounted
   ( max*drive | max*backup* | md | mb ) undo-action-abbrev max-drive
	if [[ $# == 1 ]]
	   then  _set-drive_name $1 &&
		 _set-drive_dir &&
		echo $drive_dir && exit 0
	fi

	set -- ${*:-$(list-drive-dirs)}	# for debugging: | tac
	[[ $# != 0 ]] || abort "no backup drives are mounted"

	local -i secs_per_day=24*60*60
	$Trace
	max_drive=$1; shift
	while [[ $# != 0 ]]
	    do	new_drive=$1
		for (( secs=$(date '+%s'); 1; secs-=secs_per_day ))
		    do	set-day--from-secs $secs

			set -- $new_drive/$day,??*
			[[ $# != 0 ]] || break

			set -- $max_drive/$day,??*
			[[ $# != 0 ]] && continue
			max_drive=$new_drive
			break
		done
		shift
	done
	echo $max_drive
	;;
   # for "snapcrypt": echo drive mountpoint
   ( drive )
	 _set-drive_name $1 || abort "$1 is not a valid backup drive name"
	 _set-drive_dir
	echo $drive_dir
	;;

   # -------------------------------------------------------------
   # this final action has random tests used during development; #
   # you can jump to the end of the file.			 #
   # -------------------------------------------------------------

   # run [-v var-names] func-name: run func-name, echo contents of var-names
   ( run | r ) undo-action-abbrev run
	local cmd=$1
	$Trace
	run-function -p "$@" # can pass: -v "var-name(s)" of vars to be echo'ed
	echo status=$?
	set +x
	[[ $1 == set-* ]] || exit

	header "variables set by $cmd"
	var_names=${1#set-} ; var_names=${var_names%%--from-*}
	var_names=${var_names//-/ }
	declare -i max_name_width=0
	for var_name in $var_names
	    do	(( max_name_width <= ${#var_name} )) || continue
		   max_name_width=${#var_name}
	done
	for var_name in $var_names
	    do	var_value=${!var_name}
		[[ $var_value == *' '* ]] && var_value="'$var_value'"
		printf "%${max_name_width}s=%s\n" $var_name "$var_value"
	done
	;;
   ( test | t ) undo-action-abbrev test; $Trace
	for l in ${!warning_level2tput_args[*]}
	    do set-warning_string $l $l; echo -n "$warning_string  "; done;echo
	print-string-colors; exit

	set-hours() { set-hours--from-minutes "$@"; }
	ml="0 1 2 4 6 10 20 30 50 54 56 58 59 60 90 120 125 150"
	for m in $ml; do set-hours    $m; printf "%3s -> %s\n" $m $hours; done
	for m in $ml; do set-hours -1 $m; printf "%3s -> %s\n" $m $hours; done
	exit

	set-drive_name2do_suspend
	suspend-tracing
	set -- $drive_dir_prefix*/$snapshot_day_glob,00
	restore-tracing
	fastest-snapshots $drive_dir_prefix*/${1##*/} # oldest snapshot
	exit

	set -- $drive_dir_prefix${1^^}/$snapshot_glob*
	new_snapshot=$1
	TraceV 0 new_snapshot
	_have-full-snapshot
	echo "status=$?"
	exit

	lock backup x
	lock backup x || abort badness 1
	unlock backup
	unlock backup && abort badness 2
	exit

	lock backup x
	lock backup x || abort badness 1
	lock backup y && abort badness 2
	exit

	local -a digit2name=(zero one two three)
	echoEV action digit2name[2]; exit

	for dev in $(df | cut -d' ' -f1)
	    do	[[ -b $dev ]] || continue
		set-FS_label--from-FS-device $dev
		echo "$dev -> $FS_label"
	done; exit

	for path in ${drive_dir_prefix}A ${drive_dir_prefix}A/latest /dev/sdb5
	    do	set-FS_type--from-path $path
		echo "$path -> $FS_type"
	done; exit

	set-drive_name ${1:-a}
	TraceV 0 drive_name file_for_logging log_msg_prefix
	echo  test1
	echoE test2
	log 0 test3
	abort test4
	exit

	echoE test
	foo() {
		echoE ftest
		for  i  in ${!FUNCNAME[*]}
		   do	echo "FUNCNAME[i]=${FUNCNAME[$i]}"
		done
		echoEV   i
		TraceV 0 i i
		abort "aborting test"
	}
	foo; exit

	for size in 1023 1024 2123123 3123123123 4123123123123 5123123123123123
	    do	set-readable_du_size $size; echo "$readable_du_size from $size"
	done; exit

	drive_dir=${drive_dir_prefix}F
	cd $drive_dir
	log=/tmp/root/F-190126-15.bz2
	_links-error-msg "nnn 'Too many links'"; exit
	;;

   ( * )
	warn "'$action' is not a recognized action, run: $_our_name -h"; exit 1
	;;
esac

}
readonly -f process-action

# ----------------------

process-action "$@"
