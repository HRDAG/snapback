#! /usr/bin/env bash
# shellcheck disable=SC1007,SC2004,SC2015,SC2034,SC2126,SC2128,SC2196,SC2197

#    snapback (short for "snapshot backups") manages backups on multiple drives
#
#    Copyright (C) 2018-2019, Human Rights Data Analysis Group (HRDAG)
#    https://hrdag.org
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

readonly version=24		# has to match version= in configure.sh.sample

###############################################################################
## Our naming and coding conventions are documented at the top of libsnap.sh ##
###############################################################################

set -u					# abort if access unset variable

readonly dev_null=/dev/null		# for shellcheck

readonly libsnap_project=git@github.com:HRDAG/libsnap
#
# search for ######## in  libsnap.sh to see coding-conventions and environment
[[ :$PATH: == *:/usr/local/bin:* ]] || PATH=/usr/local/bin:$PATH
lib=libsnap.sh
type -t  $lib > $dev_null || PATH=$PATH:${0%/*/*/*}/libsnap/bin
source   $lib ||  # the shellcheck action replaces this command
if which $lib > $dev_null
   then abort "$lib needs to end with 'true'"
   else echo "install $lib from $libsnap_project" >&2; exit 1
fi
(( $libsnap_version >= 1 )) || abort "need latest version of $lib"
#
if   is-arg1-in-arg2 -E ${1-} # regression-test wants alternative config_dir?
   then _args=" $*"
	config_dir=${_args/* -E /}
	config_dir=${config_dir%% *}
elif is-arg1-in-arg2 -e ${1-} # regression-test wants config_file in snapshot?
   then _root=$our_path
	if [[  $_root =~ .*/([0-9]{4}-[^/]+|latest)/ ]]
	   then _root=${BASH_REMATCH[0]}
		_root=${_root%/}
	   else abort "can only use -e with -d (command inside a snapshot)"
	fi
   else _root=
fi
#
[[ ! ${config_dir-} ]] &&
for dir in ~/etc /usr/local/etc /etc
    do	[[ -d $_root$dir/$our_name ]] && break
done
readonly   config_dir=${config_dir:-$_root$dir/$our_name}
readonly exclude_file=$config_dir/exclude.txt
readonly  config_file=$config_dir/configure.sh
unset _args _root

config_file_sample=$config_file.sample
if [[ $our_path == */$our_name/bin/$our_name ]]
   then   git_home=${our_path%/bin/$our_name}
	config_file_sample=$git_home$config_file_sample
fi ;						readonly config_file_sample

[[ -s $config_file_sample ]] ||
   abort "have to install $config_file_sample"

readonly optional_config_vars="
	    mkfs_cmd_opts do_want_external_log FS_log_VG max_swapout_MBps
	    common_mount_options extN_mount_options XFS_mount_options
	    flakey_drive_names_regex drive_specific_config_file"

# For each config var, create associative array for per-drive customization.
# [customize-config-variables currently fails when try to customize an array.]
readonly uncustomizable_config_vars="
	    drive_dir_prefix level2CPU_priority_cmd level2IO_priority_cmd
	    flakey_drive_names_regex old_cmd tst_cmd update_test_dst_drive
	    is_drive_name_capitalized drive_name_regex admin_drive_name_regex
	    is_drive_name_upper_cased drive_class_regex"
#
_set-__config_vars__() {

      set -- $(
      # toss functions before looking for variable assignments
      sed -n -r	-e '/(^[ 	]*function\b.*|\(\)) *\{.*\}/d'		\
		-e '/(^[ 	]*function\b.*|\(\)) *\{/,/^[ 	]*\}/d'	\
		-e 's/^[^#=]*\b([^_]\w+)=.*$/\1/p' $config_file_sample |sort -u
      )
      __config_vars__=" $* " # 'for _var in $optional_config_vars' needs SPACEs
}
_set-__config_vars__
#
_customizable_arrays=
for _var in $__config_vars__
    do	is-arg1-in-arg2 $_var $uncustomizable_config_vars && continue
	_customizable_arrays+="drv_name2$_var "
done
declare -A $_customizable_arrays
#
# this grabs variables that control backup and pruning, and may also hold
# customizing functions (like source-drive-specific-config-file and *hooks)
source $config_file || abort "source'd $config_file ended with non-0 status"

for _var in $optional_config_vars
    do	is-set $_var && continue
	__config_vars__=${__config_vars__/ $_var / }
	_map=drv_name2$_var
	is-set $_map && abort "can't set $_map without setting $_var"
	unset  $_map
done
readonly config_vars=$__config_vars__

[[ $is_drive_name_capitalized || $is_drive_name_upper_cased ]] &&
    shopt -s nocaseglob			# we mostly glob drive names or dirs

readonly PS4		      # remove if some functions want to manipulate it

# all of the following are created in libsnap.sh, but any of them can be
# replaced in $config_file: customization, experimentation, porting, bug-fixing
#
# We use these constants from libsnap.sh (and change $our_name)
readonly tmp_dir our_path true false is_darwin max_call_stack_args
readonly warning_level2tput_args
# We used these functions from libsnap.sh .
# FS-label naming conventions are embodied by set-mount_dir--from-FS-label and
# set-FS_label--from-mount_dir, $config_file can replace them.
readonly -f is-set have-cmd need-cmds set-FS_type--from-path
readonly -f set-inode_size-data_block_size-dir_block_size--from-path
readonly -f set-FS_label--from-FS-device label-drive
readonly -f set-FS_device--from-FS-label set-device_KB--from-block-device
readonly -f set-FS_device--from-path set-mount_dir--from-FS-device
readonly -f is-arg1-in-arg2 print-call-stack warn abort abort-function
readonly -f assert-not-option set-var_value--from-var_name echoE echoEV
readonly -f Trace TraceV remember-tracing suspend-tracing restore-tracing
readonly -f print-or-egrep-Usage-then-exit abort-with-action-Usage log header
readonly -f set-padded_colorized_string--for-printf
readonly -f fix-padded-colorized-string-vars
readonly -f is-an-FS-device-mounted set-absolute_path setup-df-data-from-fields
readonly -f cd_ have-proc is-process-alive set-reversed_words
readonly -f set-popped_word-is_last_word--from-list
readonly -f set-division set-warning_string
readonly -f confirm run-function set-backup_suffix

is-set coder ||				# can set custom value in $config_file
       coder=sweikart@gmail.com

[[ -s $exclude_file ]] ||
   abort "install/edit $exclude_file, see included .sample"

readonly Usage="
Usage: $our_name [options] action [options] [args]

  $our_name (snapshot backups) maintains multiple, uniquely-named,
      online and offsite backup drives (partitions), each with separate
      logging and policy (see files in $config_dir/); for the dashboard,
      run: $our_name watch

  Current actions are (you can specify their acronym, see process-action):
    backup-drives names: backup names ('all' for every mounted backup drive)
     prune-drives names: prune  names ('all' same as above); see configure.sh
    update-drives  [-s src-names-glob] dst-names: copy missing snapshots
    copy-snapshots [-B] [-q] snapshots name: copy to 'name' mounted drive

      rm snapshots: rename snapshots to *.rm, so they'll be pruned (rm -rf)
    unrm snapshots: rename *.rm snapshots to *.partial (update-drive restores)
    redo snapshots: rename      snapshots to *.partial (update-drive restores)

    w: show full details on all jobs and drives
    watch [-s][-C][-N names] [watch-opts]: dashboard (-s: stats; -C: cron jobs)
    big-swapouts: search syslog files for warnings about high swapout rates
    measure-swapout-bandwith swap-dev: to set max_swapout_MBps in configure.sh
    check-logs: update error cache: run this if dashboard fails with I/O error
    list-drives [-a]: list mounted backup drives; -a adds drives cron ignores
    df [-A]: show filesystem details; -A adds non-backup drives

    # -signal defaults to -KILL (-9), i.e. terminates job & deletes lock;
    # a glob can be a comma-separated list, a shell glob pattern, or 'all'.
    kill [-signal] job-type-glob  name-glob: job-types are backup, copy, prune
    continue	   job-type-glob  name-glob: as above, but -CONT signal
    suspend	   job-type-glob  name-glob: as above, but -STOP signal
    stop	   job-type-glob  name-glob: as above, but -STOP signal
    ps [ps-opts]  [job-type-glob [name-glob]]: show holder(s) of lock(s)
    reset-priority [names]: reset job priorities on drives (defaults to all)

    predict-prune [-f span] name: see: grep 'prun\w*=' $config_file
    dump-state [tar-file-name]: store $our_name's full state in tarball
    dir-sizes [-f | name]: generates stats for 'mkfs -b'; -f -> choose old file
    add-extN-journal drive_name [FS_device [VG_name]]: fast external journal
    mkfs [-f] [mkfs-opts] device-or-label [name]: mkfs drive (see comments)
    copy-drive {src_name | src_dev} dst_name [dst_dev]: duplicate backup drive
    filesystem-geometry [-a|-A|drive-dirs]: show sector, inode, block, etc
    snapshot-size dir: size of non-hard-linked files (ie in no other snapshots)

    check-snapshot-hard-links names: find snapshots with broken hard links
    mk-Z [date [period]]: create mostly-empty snapshot dirs in Z mount-point
    test-prune: use mk-Z to run pruning regression test in the Z pseudo-drive
    regression-test [-t] [tests]: check functionality, results in $tmp_dir/??
    chroot-backup date,time [command]: chroot to snapshot on fastest drive
    shellcheck: run shellcheck utility on this script
    run [-v var-names] func-name [args]: run func-name, echo var-names values;
       set globals for func-name with: var_1=foo var_2=bar $our_name run ...

  NOTE: to see what an action would do, use -d option to simulate the action.

  Common options:
	-C: we are being run from cron

	-c: pass -c (--checksum) to rsync
	-n: pass -n (--dry-run ) to rsync
	-v: pass -v (--verbose ) to rsync (and maybe other commands)
	-q: pass -q (--quiet   ) to rsync (and maybe other commands)
	-r rsync-opt: pass rsync-opt to rsync (can appear multiple times)

	-E dir: use dir for config, instead of {~,/usr/local,}/etc/$our_name/
	-e: use *etc/snapback in same snapshot used by: regression-test -d date
	-d: Debug shell script (don't run commands, just show them): simulation
	-t: Trace shell script (show commands as they execute)
	-T level: control whether Trace & TraceV functions run echoE & echoEV
"

is_cron=$false cron_opt=
IfRun= Trace= TraceAll= debug_opt= trace_opt=  our_rsync_opts=
our_opts=
while getopts "C cnvqr: E:edtT: hk"  arg
    do	our_opts+="-$arg ${OPTARG-} "
	case $arg in
	   ( C ) is_cron=$true	cron_opt=-C ;;

	   ( c ) our_rsync_opts+="--checksum "	;;
	   ( n ) our_rsync_opts+="--verbose --dry-run " ;;
	   ( v ) our_rsync_opts+="--verbose "	;;
	   ( q ) our_rsync_opts+="--quiet "	;; # cancels --verbose
	   ( r ) our_rsync_opts+="$OPTARG "	;;

	   ( E ) ;;				 # handled at top of file
	   ( e ) ;;				 # handled at top of file
	   ( d ) IfRun="echo"	debug_opt=-d ;;	 # put $IfRun b4 'active' cmds
	   ( t ) [[ $Trace ]] && TraceAll=$Trace
		 Trace="set -x" trace_opt=-t ;;
	   ( T ) Trace_level=$OPTARG Trace_level_opt="-T $OPTARG" ;;

	   (h|k) print-or-egrep-Usage-then-exit "$@" ;;
	   ( * ) abort "$Usage" ;;
	esac
done
let OPTIND=$OPTIND-1
shift $OPTIND
unset arg

[[ $debug_opt ]] && verbose_opt=-v || verbose_opt=

[[ $Trace && $debug_opt ]] && IfRun=:

trap print-call-stack EXIT
exit-normally() {
	trap 'set +x; rm -f $tmp_1 $tmp_2 $tmp_3 $tmp_4 $tmp_5; trap EXIT' EXIT
	exit ${1-}
}
exit_() { exit-normally "$@"; }		# short form, for test action

# $tmp_1 and $tmp_2 are used then deleted in the same function. so don't
# need to check the whole script to see if someone else is using them.
readonly tmp_1=$tmp_dir/$our_name-1-$BASHPID; tmp=$tmp_1 # only inside function
readonly tmp_2=$tmp_dir/$our_name-2-$BASHPID		 # only inside function
readonly tmp_3=$tmp_dir/$our_name-3-$BASHPID
readonly tmp_4=$tmp_dir/$our_name-4-$BASHPID
readonly tmp_5=$tmp_dir/$our_name-5-$BASHPID

have-cmd lockpid || abort "'make' then install lockpid from $libsnap_project"

shopt -s checkhash			# sometimes move commands for testing
shopt -s extglob			# useful for args to set-glob
shopt -s nullglob			# $# is 0 if pathname expansion "fails"
shopt -s globasciiranges		# range expressions assume C locale
shopt -s shift_verbose			# print error message if bad shift

readonly umask=02			# log dirs are setgid sudo/etc
umask $umask

FUNCNEST=100				# abort on infinite recursion

fgrep -q -x "# version=$version" $config_file_sample ||
  $IfRun abort "$config_file_sample version= does not match $our_path"

append-to-PATH-var PATH /usr/local/bin /usr/sbin /sbin # mkfs, tune2fs, etc

need-cmds fuser setsid

$TraceAll

# exec &> $tmp_dir/$our_name.log	# uncomment for slap-dash debugging

##############################################################################
# Miscellaneous variables used by for making and pruning backup snapshots.
##############################################################################

# touched when prune ends; its time is compared to files in $config_dir/
readonly pruned_timestamp=.pruned.ts

readonly our_opts=${our_opts% }
# need to fork and exec ourselves for session control with 'setsid'
readonly   backup_drive_exe="$our_path $our_opts backup-drive"
readonly    prune_drive_exe="$our_path $our_opts  prune-drive"
readonly   update_drive_exe="$our_path $our_opts update-drive"
readonly copy_snapshots_exe="$our_path $our_opts copy-snapshots"

readonly hostname=${HOSTNAME%%.*}

[[ -d /run ]] && readonly run_dir=/run || readonly run_dir=/var/run

is-set   syslog_path ||			# can set custom value in $config_file
readonly    syslog_path=/var/log/syslog
readonly        log_dir=/var/log/$our_name
readonly drives_log_dir=$log_dir/drives
readonly     status_dir=$run_dir/$our_name

# these are used by log(), besides $log_level
file_for_logging=$log_dir/messages.log	     # set-drive_log_dir-* sets it
log_msg_prefix=' ${action-} ${drive_name-}'  # this gets eval'ed each time

##############################################################################
# Miscellaneous functions used by for making and pruning backup snapshots.
##############################################################################

set-readable_du_size() {
	local -i size=$1

	local suffix=K
	while (( $size >= 1024 ))
	   do	let size/=1024
		case $suffix in		# see: man du
		    ( 'K' ) suffix=M ;;
		    ( 'M' ) suffix=G ;;
		    ( 'G' ) suffix=T ;;
		    ( 'T' ) suffix=P ;;
		    ( 'P' ) suffix=E ;;
		    ( 'E' ) suffix=Z ;;
		    ( 'Z' ) suffix=Y ;;
		esac
	done
	readable_du_size=$size${suffix}B
}
readonly -f set-readable_du_size

# ----------------------------------------------------------------------------

assert-drive_dir-writable() {
	local dir=${1:-$drive_dir}

	[[ -f $dir ]] && dir=${dir%/*}
	[[ -w $dir/. ]] ||
	   abort "$dir mounted read-only??  Maybe corrupted, run fsck."
}
readonly -f assert-drive_dir-writable

# ----------------------------------------------------------------------------
# functions to switch between msecs (milliseconds), secs, minutes, hours
# ----------------------------------------------------------------------------

set-msecs--from-secs() {

	local -i product
	set-product $1 1000
	msecs=$product
}
readonly -f set-msecs--from-secs

# ----------------------------------------------------------------------------

set-secs--from-msecs() {
	if [[ $1 == -* ]]
	   then local decimal_digits_opt=$1  msecs=$2
	   else local decimal_digits_opt=-2  msecs=$1
	fi

	local division
	set-division $decimal_digits_opt $msecs 1000
	secs=$division
}
readonly -f set-secs--from-msecs

# ----------------------------------------------------------------------------

set-minutes--from-secs() {
	local secs=$1

	minutes=$(( ($secs + 30) / 60 ))
}
readonly -f set-minutes--from-secs

# ----------------------------------------------------------------------------

set-hours--from-minutes() {
	if [[ $1 == -* ]]
	   then local decimal_digits_opt=$1  minutes=$2
	   else local decimal_digits_opt=-2  minutes=$1
	fi

	local division
	set-division $decimal_digits_opt $minutes 60
	hours=$division
}
readonly -f set-hours--from-minutes

set-hours--from-minutes 10
[[ $hours == 0.17 ]] || abort "10 minutes != $hours hours"

##############################################################################
# lock management
##############################################################################

readonly lock_dir=/var/lock/$our_name
readonly LOCKPID_DIR=$lock_dir

# use this instead of 'lockpid' when want/need to replace stale lock
function sudo-lockpid() {
	if [[ $1 == -o ]]
	   then local is_optional=$true; shift
	   else local is_optional=$false
	fi

	# we're used when locks maybe stale (sudo-lockpid $lock &> $dev_null);
	# but they usuaully aren't, so "$IfRun lockpid" would only show release
	[[ $debug_opt && $is_optional ]] && return 0

	is-set can_sudo_lockpid ||
	if $IfRun sudo -n lockpid -h &> $dev_null
	   then readonly can_sudo_lockpid=$true
	   else readonly can_sudo_lockpid=$false
	fi

	if [[ $action =~ (kill|continue|suspend) ]]
	   then local is_signaling=$true
	   else local is_signaling=$false
	fi
	if [[ $is_signaling || $can_sudo_lockpid || ! $is_optional ]]
	   then local sudo_lockpid="sudo lockpid --pid=$BASHPID"
	   else local sudo_lockpid=lockpid # only reclaim writable locks
	fi
	[[ ${!#} == */* ]] && local opt= || local opt="--dir=$lock_dir"
	[[ $Trace && ${xtrace-} && ! $IfRun ]] && echo "$PS4 $sudo_lockpid" >&2
	$IfRun $sudo_lockpid $opt ${is_optional:+-q} "$@" |
	    sed "s/--pid=[0-9]*/--pid=PID/" # for regression-test, when $IfRun
	[[ ${PIPESTATUS[0]} == 0 ]]
}
readonly -f sudo-lockpid

# --------------------------------------------

rm-stale-locks() {

	[[ -d $lock_dir ]] || create-lock_dir-log_dirs

	local lock_path
	for lock_path in $lock_dir/*.pid
	    do	[[ -e $lock_path ]] || continue
		sudo-lockpid -o $lock_path &> $dev_null &&
		sudo-lockpid -r $lock_path # we grabbed it, i.e. it was stale
	done
}
readonly -f rm-stale-locks

# ----------------------------------------------------------------------------

set-lock_drive_name() {
	local lock=$1

	lock=${lock##*/}
	lock=${lock#*-}
	lock_drive_name=${lock%.pid}
}
readonly -f set-lock_drive_name

# ----------------------------------------------------------------------------

readonly writer_types="backup prune copy"

set-lock_path() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local type=${1:-$writer_type} name=${2:-$drive_name}

	is-arg1-in-arg2 $type $writer_types ||
	   abort-function "'$type' is unknown lock type"
	[[ $name ]] || abort-function "missing \$2 and \$drive_name null"
	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	lock_path=$lock_dir/$type-$name.pid
	$xtrace
}
readonly -f set-lock_path

# ---------------------------------

# Turn comma-separated lists or sequence-expressions without surrounding (),
# or ranges without surrounding [], into a single syntactically-correct glob.
# Return 0 if the final glob has metadata characters (i.e. not simple string).
function set-glob() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=

	glob=
	local arg
	for arg
	    do	set -f
		[[ $arg == *,*  && $arg != *'{'* ]] && arg="{$arg}"
		[[ $arg == *..* && $arg != *'{'* ]] && arg="{$arg}"
		[[ $arg == *-*  && $arg != *'['* ]] && arg="[$arg]"
		set +f
		glob+="$arg,"		# append ','. we'll wrap in {}
	done
	glob=${glob%,}
	(( $# > 1 )) && glob="{$glob}"
	$xtrace
	[[ $glob == *['[{*?,+@!']* ]]
}
readonly -f set-glob

# ----------------------

set-name_glob() {
	name_glob=$*

	local glob
	  set-glob "$name_glob"
	 name_glob=$glob

	if   [[ $is_drive_name_upper_cased ]]
	   then name_glob=${name_glob^^}
	elif [[ $is_drive_name_capitalized ]]
	   then [[ $name_glob != [[{]* ]] ||
		    abort-function "ask $coder to support this glob: $glob"
		name_glob=${name_glob^}
	fi
}
readonly -f set-name_glob

# ---------------------------------

function set-lock_paths() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $# == [0-2] ]] ||
	    abort-function "$*: must be 0-2 args (can use globs)"
	[[ ${1-} == *.pid ]] && { lock_paths=$1; $xtrace; return 0; }
	local type_glob=${1:-${writer_type:-*}}
	local name_glob=${2:-${drive_name:-*}}
	[[ $name_glob == */* ]] &&
	    { set-_drive_name- $name_glob; name_glob=$_drive_name; }

	set-glob "$type_glob" && type_glob=$glob
	set-glob "$name_glob" && name_glob=$glob

	[[     $type_glob == a*  ]] && type_glob=*
	[[     $type_glob == u*  ]] && type_glob=c
	if [[  $name_glob == all ]]
	   then name_glob=*
	   else set-name_glob "$name_glob"
	fi

	eval "set -- $lock_dir/$type_glob*-$name_glob.pid"
	lock_paths=$*
	[[ -e $drive_monitor_lock_path && $type_glob == [*m]* &&
	   $name_glob == '*' ]] &&
	lock_paths+=" $drive_monitor_lock_path"
	$xtrace
	[[ $lock_paths ]]
}
readonly -f set-lock_paths

# ---------------------------------

function do-log-common-events() {

	[[ ! $is_cron     ||     ${date_time-} == *-00,00   || # log daily
	   ( $log_level -ge 1 && ${date_time-} ==    *,00 ) || # log hourly
	     $log_level -ge 2 ]]			       # log always
}
readonly -f do-log-common-events

# ---------------------------------

function lock-PID() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $1 == -n ]] && { local name=$2; shift 2; } || local name=$drive_name
	local lock_opts=
	while [[ $1 == -* ]] ; do lock_opts+="$1 "; shift; done
	local type=${1:-$writer_type} lock_holder_action=$2

	local lock_path
	set-lock_path $type $name
	lock_file=${lock_path##*/}	# for caller too

	[[ $lock_holder_action == holds* ]] ||
	    lock_holder_action="is $lock_holder_action"

	local output_file=$tmp_1
	set -f; set -- lockpid --dir=$lock_dir $lock_opts $lock_file; set +f
	[[ $UID == 0 || $debug_opt ]] ||
	    { shift; set -- sudo lockpid --pid=$BASHPID "$@"; }
	local lock_cmd=$*
	[[ $Trace && ${xtrace-} && ! $IfRun ]] && echo "$PS4 $lock_cmd" >&2
	$IfRun $lock_cmd &> $output_file ; local status=$?
	lockpid_output=$(<  $output_file)
	rm $output_file

	if [[ $status == 0 ]]
	   then if [[ $lockpid_output ]]
		   then if [[ ! $is_regression_test ]]
			   then echo "$lockpid_output"
			   else echo "$lockpid_output" |
				   sed "s/--pid=[0-9]*/--pid=PID/"
			fi
		fi
		$xtrace
		return 0
	fi

	[[ $lockpid_output =~ [Pp]rocess.([0-9]+).holds ]]
	local lock_holder_PID=${BASH_REMATCH[1]-}
	if [[ $status == $lockpid_busy_exit_status && $lock_holder_PID ]]
	   then do-log-common-events && [[ $writer_type != prune ]] &&
		log  "process $lock_holder_PID $lock_holder_action"
	elif [[ $lock_opts != *-q* ]]
	   then log "$lock_cmd -> $lockpid_output (status=$status)"
		print-call-stack ${drive_name-}
	   else $xtrace; return $status
	fi >&2				# echo problems to stderr
	$xtrace
	return $status
}
readonly -f lock-PID

# ------------------------------------------------------------------

_set-type-name() {
	[[ -o xtrace  ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	type=$1 resource=${2:-$drive_name}

	 set-_drive_name- $resource
	name=$_drive_name

	$xtrace
}
readonly -f _set-type-name

# --------------------------------------------

_set-wait_opt() {
	local do_wait=${1-}

	[[ $do_wait ]] || { wait_opt= ; return; }
	wait_opt=--wait
	[[ ! $is_cron ]] && return	# interactive user waits for lock
	[[ $writer_type == backup ]] || return # only backup-drive is fancy

	[[ $is_cron ]] && continue-jobs $type # user suspended earlier backup?

	declare -i half_backup_period_mins=$backup_period*60/2
	[[ ${date_time-} ]] || set-date_time
	declare    hour=${date_time##*,}
	declare -i hour=${hour#0}    # don't treat zero-padded number as octal

	# if we have to skip backups because they take longer than
	# the $backup_period, try to skip backups that will be pruned
	# soon (instead of long-lasting backups)
	  if [[ $date_time == *-01,00 ]] # kept a very long time?
	   then wait_opt=--wait		 # want it
	elif [[ $date_time == *-16,00 ]] # kept a long time?
	   then wait_opt=--wait		 # want it
	elif [[ $date_time ==    *,00 ]] # kept a fairly long time?
	   then wait_opt=--wait-expiration=23h # want it (if possible)
	elif (( hour % 8 == 0 ))	      # multiple of 8 (i.e. 08 or 16)?
	   then wait_opt=--wait-expiration=7h # want it, pruned slower
	elif (( hour % 4 == 0 ))	      # multiple of 4?
	   then wait_opt=--wait-expiration=3h # want it, pruned slower
	elif (( hour % 2 == 0 ))	      # multiple of 2?
	   then wait_opt=--wait-expiration=1h # want it, pruned slower
	   else wait_opt=--wait-expiration=${half_backup_period_mins}m
	fi
	wait_opt+=" --quiet"
}
readonly -f _set-wait_opt

# --------------------------------------------

# The locking & job-management policy:

# When $is_multi_writer_drive == $true, all writer jobs run in parallel, with
# their (relative) I/O and CPU priorities controlled by
# set-job_type2priority_level() .  [Locking and job creation are described in
# the next section.]

# When $is_multi_writer_drive == $false, only one job can be writing to a
# drive at once (any other jobs will be suspended); this section describes the
# policy (and mechanism) to meet that requirement.  For each drive,
# create-jobs() creates a job for a type of writer, and lock()
# creates a lock for each of those jobs ( see writer_types= ).  The
# backup job gets priority (i.e. non-backup jobs will be suspended when a
# backup job is initiated).  When no backup job is running, and copy and prune
# jobs both exist, reset-priority aka is-copy-higher-priority-than-prune
# decides which one should be suspended (every 5 minutes with default crontab).
#
# An hourly cron job calls action backup-drives (with argument 'all'), which
# calls create-jobs() to create a backup-drive() job for each drive;
# each backup-drive() job starts a prune-drive() job, and prune-drive() may
# start an update-drive() job.  If the cron job is called more frequently
# than hourly, the off-hour jobs just call reset-priority and prune-drive
# (for drives with too-high usage, suspend any copy and start a prune),
# and also run do-chores.
#
# A lock() call for a non-backup lock will get its requested lock immediately
# (so the job will then appear on the dashboard), but will release that lock
# and return 'failed' if a backup is running (it'll wait for the backup to
# finish if called by 'lock -w', e.g. it's a user-initiated action).
# Similarly, a call to continue-jobs() for a non-backup job will be silently
# ignored if a backup is running, and will return 'failed'.

declare -A _lock_type_name2lock_file

# Usage: lock [-w] [-P] type resource
#    Grab a lock of 'type' on resource (drive-dir or snapshot).
#    If -w and lock is held by other job, Wait for lock to be freed;
#    If -P, called by Prevent-Pruning, doesn't matter if backup running.
#    After grab non-backup lock, waits for no-backup if ! is_multi_writer_drive
function lock() {
#	[[ ${action-} != test ]] && # [[ ${action-} != prune* ]] &&
#	[[ -o xtrace  ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ ${1-} == -w ]] && { shift; local  do_wait=$true;} || local  do_wait=
	[[ ${1-} == -P ]] && { shift; local no_prune=$true;} || local no_prune=
	assert-not-option "${1-}"
	[[ $# == [12] ]] || abort-function "[-w] [-P] type resource"
	local type name
	 _set-type-name "$@"
	local drive_name=$name

	local prev_lock_file=${_lock_type_name2lock_file[$type,$name]-}
	[[ ! $prev_lock_file ]] ||
	   abort "hold $prev_lock_file, can't grab $type lock file"

	local	    lock_msg="holds '$type' lock for $drive_name"
	local extra_lock_msg="${lock_msg/$type/backup}, so can't $type"

	local wait_opt
	 _set-wait_opt $do_wait

	local lock_file
	# be sure to grab primary lock first, so job appears on dashboard
	lock-PID $wait_opt $type "$lock_msg" ||
	    { local status=$?; $xtrace; return $status; }
	local primary_lock_file=$lock_file # lock-PID sets lock_file

	! [[ $action == update* && $debug_opt ]] && # not regression-test?
	# this 'if' logic is similar to the logic in _signal-job()
	if is-multi-writer-drive || [[ $type == backup || $no_prune ]]
	   then true
	   else lock-PID $wait_opt backup "$extra_lock_msg" &&
		lock-PID --release backup "$extra_lock_msg" ||
		   { local status=$?; sudo-lockpid -r $primary_lock_file;
		     $xtrace; return $status; }
	fi

	_lock_type_name2lock_file[$type,$name]=$primary_lock_file

	 $xtrace
	return 0
}
readonly -f lock

# ---------------------------------

unlock() {
#	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local type name
	 _set-type-name "$@"

	local lock_file=${_lock_type_name2lock_file[$type,$name]-}
	[[   $lock_file ]] || abort "don't hold lock: type=$type, name=$name"
	if [[ $debug_opt ]]
	   then local lock_prefix="$IfRun "
	elif [[ $UID == 0 ]]
	   then local lock_prefix=
	   else local lock_prefix=sudo-
	fi
	${lock_prefix}lockpid --dir=$lock_dir --release $lock_file
	_lock_type_name2lock_file[$type,$name]=	# in case unset fails ...
	unset "_lock_type_name2lock_file[$type,$name]" # this sometimes fails?

#	$xtrace
}
readonly -f unlock

##############################################################################
# enumerating/showing/signaling/killing process groups
##############################################################################

function set-PID_ps_fields--in-process-groups() {
	local columns_opt=$1; shift

	setup-ps-options
	PID_ps_fields=

	local PGID
	for PGID
	    do	set -- $(COLUMNS=9999 ps -o $columns_opt $ps_opt_g $PGID)
		shift			# toss header
		[[ $# != 0 ]] && PID_ps_fields+="$* "
	done

	[[ $PID_ps_fields ]]
}
readonly -f set-PID_ps_fields--in-process-groups

# ---------------------------------

function set-PIDs--in-process-groups() {

	PIDs=
	set-PID_ps_fields--in-process-groups pid $* || return 1
	PIDs=$PID_ps_fields
}
readonly -f set-PIDs--in-process-groups

# ---------------------------------

set-executables--in-process-groups() {

	executables=
	set-PID_ps_fields--in-process-groups comm $* || return 1
	executables=$PID_ps_fields
}
readonly -f set-executables--in-process-groups

# ---------------------------------

set-state--in-process-groups() {

	executables=
	set-PID_ps_fields--in-process-groups stat $* || return 1
	state=$PID_ps_fields
}
readonly -f set-executables--in-process-groups

# ----------------------------------------------------------------------------

function set-lock_PGID() {
	local lock=$1

	[[ $lock == /* ]] || lock=$lock_dir/${lock##*/}
	lock_PGID=
	[[ -s $lock ]] && set -- $(< $lock) && [[ $# == 1 ]] || return 1
	lock_PGID=$1
	return 0
}
readonly -f set-lock_PGID

# ----------------------

function set-job_PGID() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local job_type=$1 lock_path lock_PGID

	set-lock_path $job_type
	set-lock_PGID $lock_path
	job_PGID=$lock_PGID

	$xtrace
	[[ $job_PGID ]]
}
readonly -f set-job_PGID

# ----------------------------------------------------------------------------

function set-signal_is_kill() {
	local signal=${1#-}

	case ${signal^^} in
	   ( SIGKILL | KILL | 9 )
		signal_is_kill=$true  ; return 0 ;;
	   ( *)	signal_is_kill=$false ; return 1 ;;
	esac
}
readonly -f set-signal_is_kill

# ----------------------

function set-signal_is_stop() {
	local signal=${1#-}

	case ${signal^^} in
	   ( SIGSTOP | STOP | 19 )
		signal_is_stop=$true  ; return 0 ;;
	   ( *)	signal_is_stop=$false ; return 1 ;;
	esac
}
readonly -f set-signal_is_stop

# ----------------------

function is-active-lock() {
	set-lock_paths "$@"

	local lock lock_PGID
	for lock in $lock_paths
	    do	set-lock_PGID $lock && is-process-alive $lock_PGID && return 0
	done
	return 1
}
readonly -f is-active-lock

# ----------------------

function have-job() { is-active-lock "$@"; }
readonly -f have-job

# ----------------------

function is-our-lock() {
	local  lock_file=$1

	[[ -s $lock_file ]] && set -- $(< $lock_file) && [[ ${1-} == $$ ]]
}
readonly -f is-our-lock

# ---------------------------------------

function sudo-kill() {
	local PID=${!#}

	$IfRun kill "$@" 2> $dev_null && return 0 # kill is built-in, so cheap
	is-process-alive ${PID#-} || return 1
	local  kill_msg=$(kill "$@" 2>&1)
	if   [[ $kill_msg == *"Operation not permitted"* ]]
	   then sudo kill "$@"
	elif [[ $kill_msg == *"No such process"* ]]
	   then return 1
	   else echo "$kill_msg" >&2
		return 1
	fi
}
readonly -f sudo-kill

# ----------------------

# return false if job exists but we didn't kill it, otherwise true
function signal-job() {
	local signal=${1#-}; shift
	if [[ $# == 1 && $1 == *.pid ]]
	   then lock_path=$1		# global variable, caller can use it
		[[ $lock_path == /* ]] || lock_path=$lock_dir/${lock_path##*/}
	   else local job_type=$1 drive_name=${2:-$drive_name}
		suspend-tracing
		set-drive_name- $drive_name
		set-lock_path $job_type
		restore-tracing
	fi

	[[ ! $debug_opt ]] &&
	# use -o, because we don't really need to remove a stale lock
	sudo-lockpid -o --not-hold $lock_path &> $dev_null && # if stale ...
	sudo-lockpid    --release  $lock_path && return 0     # nothing to kill

	set-lock_PGID $lock_path || return 0 # is there a valid job to signal?
	sudo-kill -s ${signal^^} -$lock_PGID || return 1 # did our kill work?

	set-signal_is_kill $signal || return 0 # (wanted to) terminate job?

	sudo-lockpid -o $lock_path &> $dev_null && # see if it really died
	sudo-lockpid -r $lock_path
	return $?			# is lock-holder still alive?
}
readonly -f signal-job

# ---------------------------------

# The locking & job-management policy is documented in front of function lock()

function _signal-jobs() {
	local signal=$1; shift

	[[ $IfRun ]] && echo "${FUNCNAME[1]} $*" && return 0

	local type
	for type
	    do	have-job $type || continue
		if [[ $signal == *CONT ]]
		   then # this logic is similar to the logic in lock()
			if is-multi-writer-drive || [[ $type == backup ]]
			   then true
			   else have-job backup && return 1 # bkp has priority
			fi
			set-job_PGID $type &&
			set-priority $type $job_PGID
		fi
		signal-job $signal $type
	done
	return 0
}
readonly -f _signal-jobs

# these take multiple types, and work with the current $drive_name
function  suspend-jobs() {

	[[ $UID == 0 ]] &&
	print-call-stack $drive_name | tee -a $file_for_logging
	_signal-jobs -STOP "$@"
}
function  suspend-jobs() { _signal-jobs -STOP "$@"; }
function continue-jobs() { _signal-jobs -CONT "$@"; }
readonly -f suspend-jobs continue-jobs

# -------------------------------------------------

function kill-job-on-drives() {
	local signal=-KILL
	[[ $1 == -s    ]] && { signal=-STOP ; shift; }
	[[ $1 == -c    ]] && { signal=-CONT ; shift; }
	[[ ${1-} == -* ]] && { signal=${1^^}; shift; }
	assert-not-option "${1-}"
	local type=${1:-$writer_type} drives=${2-}

	set-lock_paths "$@" || return 1

	set-signal_is_kill $signal
	set-signal_is_stop $signal
	local path status=1		# assume nothing we're allowed to kill
	for path in $lock_paths
	    do	if [[ $path == $drive_monitor_lock_path ]]
		   then local is_monitor_lock=$true
		   else local is_monitor_lock=$false
		fi
		if [[ $signal_is_kill ]]
		   then if [[ $is_monitor_lock ]]
			   then [[   $type == m* ||
				   ( $type == a* && $drives == all ) ]] &&
				re-start-monitor-drives-if-needed -f
				continue
			fi

			# sometimes it takes multiple kills for update-drive
			local did_loop=$false
			until signal-job $signal $path
			   do	echo -n .
				env sleep 0.1
				did_loop=$true
			done
			[[ $did_loop ]] && echo

			status=0
		   else [[ $is_monitor_lock ]] && continue
			signal-job $signal $path && status=0
			[[ $signal_is_stop && $type != b* ]] || continue

			local lock=$(basename $path)
			local coder_msg="can ask $coder to fix this."
			local cron_msg="cron (runs every 5 minutes by default)"
			warn "$cron_msg could un-suspend\n   $lock; $coder_msg"

		fi
	done

	return $status
}
readonly -f kill-job-on-drives

# ----------------------------------------------------------------------------

function set-lock_PGIDs() {
	local type=${1:-$writer_type} names_glob=${names_glob:-*}

	lock_PGIDs=

	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	eval "set -- $lock_dir/$type-$names_glob.pid"

	local lock locks=
	for lock; do [[ -s $lock ]] && locks+="$lock "; done

	[[ $type == prune && ! ( $debug_opt || $show_all ) ]] &&
	    locks=${locks/$type-Z.pid/}

	for lock in $locks
	    do	set -- $(< $lock)
		[[ $# == 1 ]] || continue
		lock_PGIDs+=$1,
	done 2> $dev_null	    # a lock might disappear, i.e. $(< ) fails
	lock_PGIDs=${lock_PGIDs%,}
	[[ $lock_PGIDs ]]
}
readonly -f set-lock_PGIDs

# ----------------------------------------------------------------------------

function ps-locks() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ ${1-} == -R ]] && { local do_rm= ; shift; } || local do_rm=$true

	local ps_opts=
	# $1 types are (a)ll, (b)ackup, (c)opy, (p)rune, (m)on: so not 'ps' opt
	while [[ ${1-} == -* || ${1-} == [^abcpm] || $# -ge 3 ]]
	   do ps_opts+="$1 "; shift; done
	set-drive_dirs
	set-rows-columns-COLUMNS
	set-ps_keywords-ps_header
	setup-ps-options
	[[ $ps_opts ]] || ps_opts="-o $ps_keywords $ps_opt_H"

	set-lock_paths "$@"

	[[ $do_rm ]] && rm-stale-locks
	[[ -d $lock_dir ]] || create-lock_dir-log_dirs
	local status=1			# assume all locks are missing/stale
	for lock in $lock_paths
	    do	# race: lockpid has created file but not yet written pid
		[[ -s  $lock ]] || env sleep 0.01
		[[ -e  $lock ]] || continue
		header $lock
		[[ -s  $lock ]] ||
		    { [[ -e $lock ]] && echo "empty lock file"; continue; }
		set -- $(< $lock)
		ps $ps_opts $ps_opt_g $1 || ps $ps_opt_h $ps_opts $1
		status=$?
	done
	$xtrace
	return $status
}
readonly -f ps-locks

##############################################################################
# miscellaneous
##############################################################################

is-set   df_exclude_type_options ||	# can set custom value in $config_file
readonly df_exclude_type_options="-x devtmpfs -x tmpfs -x squashfs"

list-drive-dirs() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ ${1-} == -a ]] &&
	   local list_all_drives=$true && shift ||
	   local list_all_drives=$false

	if [[ -t 0 || -t 1 || -t 2 || $list_all_drives ]]
	   then local regex=$admin_drive_name_regex
	   else local regex=$drive_name_regex # for cron & nohup
	fi
	[[ ${1-} == -A ]] && regex=/ || regex="^$drive_dir_prefix$regex$"
	df --output=target $df_exclude_type_options --no-sync |
	   egrep "$regex" | sort -u
	$xtrace
}
readonly -f list-drive-dirs

# ----------------------

function set-drive_dirs() {

	set -- $(list-drive-dirs "$@")
	drive_dirs=$*
	[[ $drive_dirs ]]
}
readonly -f set-drive_dirs

# ----------------------

readonly escaped_drive_dir_prefix=${drive_dir_prefix//\//\\/}

function set-drive_names() {

	set -- $(list-drive-dirs "$@")
	drive_names=${*//$escaped_drive_dir_prefix/}
	[[ $drive_names ]]
}
readonly -f set-drive_names

# ---------------------------------

function is-drive-mounted() {
	local drive_dir=$1

	[[ $drive_dir ]] || return 1
	[[ $drive_dir == *[-/][zZ] ]] && return 0 # Z is testing pseudo-drive

	suspend-tracing
	set -- $drive_dir/$snapshot_glob*
	restore-tracing
	[[ $# != 0 ]] || is-an-FS-device-mounted $drive_dir
}
readonly -f is-drive-mounted

# ----------------------------------------------------------------------------

set-oldest_snapshot() {

	local oldest= FS
	for FS in $(list-drive-dirs)
	    do	suspend-tracing
		set -- $FS/$snapshot_glob
		[[ $# != 0 ]] || continue
		restore-tracing
		[[ $oldest && ${oldest##*/} < ${1##*/} ]] &&
		   continue
		oldest=$1
	done
	[[ -d $oldest ]] || abort "no old backup drives are mounted"
	oldest_snapshot=$oldest
}
readonly -f set-oldest_snapshot

##############################################################################
# Setup variables for working with a specific backup drive.
##############################################################################

# ----------------------------------------------------------------------------
# manage backup and log directories
# ----------------------------------------------------------------------------

is-set	 possible_admin_groups ||	# can set custom value in $config_file
readonly possible_admin_groups="sudo wheel admin staff adm" # 'admin' is macOS

function set-admin_group {

	is-set admin_group && { [[ $admin_group ]] ; return $?; }

	suspend-tracing
	local env_var env_var_values="${SUDO_USER-} ${USER-} ${LOGNAME-}"
	for env_var in HOME MAIL
	    do	is-set $env_var || continue
		local path=${!env_var}
		env_var_values+=" ${path##*/}"
	done

	local user
	for user in $env_var_values
	    do	[[ $user != root ]] && break
	done

	if [[ ! $user || $user == root ]] # run from cron?
	   then set -- $(ls -ld $log_dir 2>$dev_null)
		readonly admin_group=${4:-}
		[[ $admin_group ]]
		return $?
	fi

	local user_groups=$(env id -G -n $user)

	local group
	for group in $possible_admin_groups NoNe
	    do	is-arg1-in-arg2 $group $user_groups && break
	done
	[[ $group == NoNe ]] && admin_group= || admin_group=$group

	readonly admin_group
	restore-tracing group
	[[ $admin_group ]]
}
readonly -f set-admin_group

# ----------------------

fix-drive_dir-perms() {
	local drive_dir=${1:-$drive_dir}

	is-an-FS-device-mounted $drive_dir || return
	mkdir -p $drive_dir/.junk	# for sysadmin
	set-admin_group &&
	chgrp $admin_group $drive_dir/{.,.??*} &&
	# this will _not_ make non-empty snapshots deletable by group
	chmod g+w	   $drive_dir/{.,.??*} # for 'u' regression test
}
readonly -f fix-drive_dir-perms

# ----------------------

create-lock_dir-log_dirs() {

	local group=

	[[ -d $drives_log_dir && -d $lock_dir ]] || {
	set-admin_group && group=$admin_group
	sudo mkdir -p --mode=1777 $lock_dir
	sudo mkdir -p  $drives_log_dir; [[ $group ]] &&
	sudo chgrp -R $group  $log_dir $lock_dir &&
	sudo chmod -R g+w,g+s $log_dir $lock_dir
	}
	[[ -d $log_dir ]] || abort "need sudo privs for initial setup"

	[[ ${drive_log_dir-} ]] || return

	if [[ ! -d $drive_log_dir ]]
	   then sudo mkdir -p $drive_log_dir
		[[ $is_regression_test ]] &&
		sudo touch $file_for_logging &&
		sudo chown $LOGNAME $drive_log_dir $file_for_logging
	fi
	[[ -d $drive_log_dir ]] || abort "need sudo privs to setup new drive"
}
readonly -f create-lock_dir-log_dirs

# -----------------------------------

if [[ $debug_opt && $is_cron ]]
   then is_regression_test=$true
   else is_regression_test=$false
fi

readonly none=NoNe
_last_fully_initialized_drive_name=

# this is normally called by set-drive_name; but you can pass
# a null drive_name to set default file_for_logging & drive_log_dir
set-drive_log_dir-file_for_logging-is_regression_test() {
	local  drive_name=${1-}	     # called from set-drive_name, so $1 valid

	[[ $drive_name == [zZ] || ( $debug_opt && $is_cron ) ]] &&
	    is_regression_test=$true

	if [[ $drive_name ]]
	   then drive_log_dir=$drives_log_dir/$drive_name
	   else drive_log_dir=$drives_log_dir
	fi
	TraceV 3 drive_log_dir
	file_for_logging=$drive_log_dir/messages.log
	[[ -d $drive_log_dir ]] || create-lock_dir-log_dirs

	if  [[ $_last_fully_initialized_drive_name != ${drive_name:-$none} ]]
	   then _last_fully_initialized_drive_name=${drive_name:-$none}
	   else return			# skip very-long, duplicative setup
	fi

	customize-and-validate-configuration-variables $drive_name
}
readonly -f set-drive_log_dir-file_for_logging-is_regression_test

# ----------------------------------------------------------------------------
# functions for naming and finding backup drives
# ----------------------------------------------------------------------------

# you could ask $coder to allow more characters
readonly allowed_drive_dir_chars='-._a-zA-Z0-9' # '-' must be first

# This is much faster than set-drive_name, but can only be used for
# already-existing-and-initialized backup directories and their names.
# This checks name-validity, and fixex the case of valid names.
set-drive_name-() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ $1 == -q ]] && { local is_quiet=$true; shift; } || local is_quiet=
	[[ $1 == -c ]] && { local clean=$true; shift; } || local clean=$false
	assert-not-option -o "$1"
	local  name=${1#$drive_dir_prefix}
	name=${name%/$snapshot_glob*}
	name=${name%/latest*}

	# might need a quick exit for first phase of set-drive_name .
	[[ $clean ]] && drive_name=$name && { $xtrace; return 0; }

	[[ $name == *[^$allowed_drive_dir_chars]* ]] && {
	   [[ $is_quiet ]] && { $xtrace; return 1; }
	   abort "drive_name='$1' has bad chars (can ask $coder to allow)"
	}

	[[ $name =~ ^$admin_drive_name_regex$ && $name != all ]] || {
	    [[ $is_quiet ]] && { $xtrace; return 1; }
	    abort "'$name' is not a valid drive-name";		    }

	if   [[ $is_drive_name_upper_cased ]]
	   then name=${name^^}
	elif [[ $is_drive_name_capitalized ]]
	   then name=${name^}
	fi
	drive_name=$name

	_last_fully_initialized_drive_name= # prevent weird bugs
	$xtrace
}
readonly -f set-drive_name-

# ---------

# a variant on set-drive_name- that doesn't mess up the global $drive_name
set-_drive_name-() {

	local drive_name	      # don't mess up the usually-global value
	 set-drive_name- "$@"
	_drive_name=$drive_name
}
readonly -f set-_drive_name-

# ----------------------

# pass: directory (that holds snapshots), filesystem label, or valid name
set-drive_name() {
	[[ $# == 1 && $1 ]] || abort "set-drive_name takes a single argument"
	local name=$1

	${set_drive_name_pre_hook-} # can munge 'name' variable

	set-drive_name- -c $name && name=$drive_name

	if [[ ! $name =~ ^$admin_drive_name_regex$ ]]
	   then if [[ $name == /dev/* ]]
		   then set-FS_label--from-FS-device $name
			set-mount_dir--from-FS-label $FS_label
			drive_dir=$mount_dir
		elif [[ $name != /* ]]
		   then set-mount_dir--from-FS-label $name
			drive_dir=$mount_dir
		   else drive_dir=$name
		fi
		[[  $drive_dir =~ \
		   ^$drive_dir_prefix$admin_drive_name_regex$ ]] ||
		   abort "$name is not drive-dir or FS-label or valid-name"
		name=${drive_dir#$drive_dir_prefix}
	fi
	set-drive_name- $name	  # call again, for globbing and case-control
	TraceV 3 drive_name

	${set_drive_name_post_hook-} # can munge 'drive_name' variable

	set-drive_log_dir-file_for_logging-is_regression_test $drive_name
}
readonly -f set-drive_name

# ---------------------------------

# only call this with a known-valid drive_name, for speed
function set-drive_dir-() {
	local name=${1:-$drive_name}

	if [[ $name == $mon_overhead_drive_name ]]
	   then drive_dir=$mon_overhead_drive_dir
	   else drive_dir=$drive_dir_prefix$name
	fi
	[[ -d $drive_dir ]] || warn "no mount directory for '$name'"
}
readonly -f set-drive_dir-

# ----------------------

function set-decryption_dev() {
	local name=${1:-$drive_name} drive_dir FS_label
	name=${1#$drive_dir_prefix}	# might be $drive_dir

	drive_dir=$drive_dir_prefix$name
	set-FS_label--from-mount_dir $drive_dir
	decryption_dev=/dev/mapper/$FS_label
	[[ -b $decryption_dev ]]
}
readonly -f set-decryption_dev

# ----------------------

is-set   darwin_drive_dir ||		# can set custom value in $config_file
readonly darwin_drive_dir=/var/local/snapback

function set-drive_dir() {
	[[ $1 == -q ]] && { local is_quiet=$true; shift; } || local is_quiet=
	assert-not-option "$1"
	local drive_name=$1		# result of set-drive_name, i.e. valid

	[[ $drive_name != */* ]] ||
	  abort "'/' in drive name not (yet)supported, add to drive_dir_prefix"

	set-drive_dir-

	if [[ $is_regression_test && ! -d $drive_dir ]]
	   then	set-admin_group
		[[ $admin_group ]] && local group=:$admin_group || local group=
		[[ $is_darwin ]] &&
		    local _drive_dir=$drive_dir &&
		    drive_dir=$darwin_drive_dir/$(basename $drive_dir)
		sudo mkdir $drive_dir &&
		sudo chmod g+s,g+w $drive_dir &&
		sudo chown $LOGNAME$group $drive_dir ||
		  abort "need sudo privs to setup pseudo-drive 'Z' for testing"
		[[ $is_darwin ]] && sudo ln -s $drive_dir $_drive_dir
	fi

	if is-drive-mounted $drive_dir
	   then have-cmd fix_snapshot_names &&
		   fix_snapshot_names $drive_dir # must call last
		return 0
	fi

	if [[ ! $is_quiet ]]
	   then warn "no filesystem mounted on $drive_dir"
		# print-call-stack $drive_name # uncomment to debug
	fi
	return 1
}
readonly -f set-drive_dir

# ----------------------------------------------------------------------------
# functions for customizing configuration variables
# ----------------------------------------------------------------------------

have-cmd \
source-drive-specific-config-file ||# can define custom version in $config_file
source-drive-specific-config-file() {
	[[ $# == 0 ]] && return
	local _name=$1  _main_config_file=${2:-${config_file-}}
	set-drive_name- $_name
	[[ $_main_config_file ]] || abort "pass config_file as 2nd arg"

	local     _config_file=${_main_config_file/%.sh/-$drive_name.sh}
	if [[ -s $_config_file ]]
	   then drive_specific_config_file=$_config_file; source $_config_file
	   else drive_specific_config_file=		; true
	fi || abort-function "'source $_config_file' returned non-0"
}
readonly -f source-drive-specific-config-file

# ----------------------------------------------------------------------------

function set-customized_drv_names() {
	local var_name=$1

	eval \
	    "customized_drv_names=\${!drv_name2$var_name[*]}"
	[[  $customized_drv_names ]]
}
readonly -f set-customized_drv_names

# ---------------------------------

	   custom_config_vars=
declare -A custom_config_var2default_value

set-custom_config_vars-custom_config_var2default_value() {

	[[ $custom_config_vars ]] && return

	remember-tracing		# since suspend-tracing maybe not run

	local var_name customized_drv_names
	for var_name in $config_vars
	    do	is-set $var_name || abort "set '$var_name=' in $config_file"
		local drv_name2var=drv_name2$var_name
		if ! set-customized_drv_names $var_name # not customized?
		   then unset $drv_name2var
			# rm-pruned-snapshots can clear hard_link_dirs
			[[ $var_name != hard_link_dirs ]] && readonly $var_name
			continue
		fi
		is-readonly-var $var_name &&
		  abort "can't use $drv_name2var, $var_name is marked readonly"

		custom_config_var2default_value[$var_name]=${!var_name}

		suspend-tracing
	done

	custom_config_vars=${!custom_config_var2default_value[*]}
	readonly custom_config_vars custom_config_var2default_value

	restore-tracing custom_config_vars
}
readonly -f set-custom_config_vars-custom_config_var2default_value

# ---------------------------------

function _set-value--for-config-var() {
	local var_name=$1 drive_name=$2 customized_drv_names

	set-customized_drv_names $var_name || return 1 # not customized?

	[[ $drive_name =~ $drive_class_regex ]] || abort-function "no class"
	local drive_class=${BASH_REMATCH[0]}

	local drv_name is_customized=$false
	for drv_name in $drive_name $drive_class # try most-specific name first
	    do	is-arg1-in-arg2 $drv_name $customized_drv_names || continue
		is_customized=$true
		break
	done
	if [[ $is_customized ]]
	   then eval "value=\${drv_name2$var_name[\$drv_name]}"
		Trace 2 "drv_name2$var_name[$drv_name] -> $var_name=$value"
	   else value=${custom_config_var2default_value[$var_name]}
	fi
	return 0
}

readonly -f _set-value--for-config-var

# ---------------------------------

customize-config-variables() {
	local drive_name=${1-}

	set-custom_config_vars-custom_config_var2default_value

	[[ $drive_name ]] || return
	[[ $drive_name == [zZ] ]] && is_regression_test=$true

	remember-tracing
	local var_name value
	for var_name in $custom_config_vars
	    do	_set-value--for-config-var $var_name $drive_name || continue
		eval "$var_name=\$value"
		suspend-tracing
	done
	restore-tracing

	(( $backup_period_for_update > 0 )) && [[ $is_update ]] &&
	    backup_period=$backup_period_for_update
}
readonly -f customize-config-variables

# ---------------------------------

function set-customized_value--for-config-var-name() {
	local var_name=$1 resource=${2:-$drive_name}
	[[ $var_name ]]  || abort-function ": \$1 empty"
	is-set $var_name || abort-function ": $var_name is not set"

	set-custom_config_vars-custom_config_var2default_value

	local drive_name value
	 set-drive_name- $resource
	if _set-value--for-config-var $var_name $drive_name
	   then customized_value=$value       && return 0
	   else customized_value=${!var_name} && return 1
		abort-function ": $var_name is unbound"
	fi
}
readonly -f set-customized_value--for-config-var-name

# ------------------------------------------------------------------

validate-config-variables() {

	declare -p $config_vars | grep -v '^declare -'
	[[ ${PIPESTATUS[0]} == 0 ]] ||
	    abort "must assign above variables, see $config_file_sample"

	local var=snapshot_date_time_separator
	[[ ${!var} == ',' ]] ||
	   abort "$var is not implemented, email $coder"
	#
	[[ ! $extra_excludes ]] ||
	   abort "extra_excludes is not implemented, email $coder"
	#
	local bad_punctuation="[-.:0-9]" # you could ask $coder to change this
	[[ $snapshot_date_time_separator != *$bad_punctuation* ]] ||
	   abort "snapshot_date_time_separator can't contain $bad_punctuation"
	#
	[[ $excluded_backup_hours != *[^-\ \	0-9]* ]] ||
	   abort "excluded_backup_hours must be list of (ranges of) numbers"

	[[ $drive_dir_prefix == *[^$allowed_drive_dir_chars/]* ]] &&
	   abort "drive_dir_prefix has disallowed chars (ask $coder to allow)"

	[[ $drive_response_averaging_window_secs > $mon_check_period_secs ]] ||
	    abort "drive_response_averaging_window_secs too small"

	# these config file(s) will be mentioned in the following error msg
	set -- $config_file ${drive_specific_config_file-}

	echo " $dirs_to_backup " | grep ' [^/]' &&
	   abort "dirs_to_backup contains a non-absolute path in $*"

	is-arg1-in-arg2 $backup_period $valid_backup_periods ||
	   abort "invalid 'backup_period=$backup_period' in $*"
	declare -i backup_period

	(( $max_FS_usage_percent >  0 )) &&
	(( $max_FS_usage_percent < 99 )) || # 99% could be 99.5% (or higher?)
	    abort "invalid: max_FS_usage_percent=$max_FS_usage_percent'"

	[[ -s $exclude_file ]] ||
	   abort "'exclude_file=$exclude_file' is empty file (from $*)"

	local \
	var_msg=successful_rsync_exit_statuses=$successful_rsync_exit_statuses
	is-arg1-in-arg2 0 $successful_rsync_exit_statuses ||
	   abort "'$var_msg' must contain 0 in $*"

	for var_name in drive_name_regex admin_drive_name_regex
	    do	# we'll anchor these variable's values ourselves, when needed
		[[ ${!var_name} != ^* ]] ||
		   abort "remove  leading '^' from $var_name="
		[[ ${!var_name} != *$ ]] ||
		   abort "remove trailing '$' from $var_name="
	done
}
readonly -f validate-config-variables

# ------------------------------------------------------------------

customize-and-validate-configuration-variables() {
	local name=${1-}

	# avoid infinite loop
	set -- ${FUNCNAME[*]} ; shift
	is-arg1-in-arg2 $FUNCNAME $* && return

	suspend-tracing

	source-drive-specific-config-file $name

	customize-config-variables $name

	validate-config-variables	# must do this last

	restore-tracing
}
readonly -f customize-and-validate-configuration-variables

############################################################################
# functions to implement an independent process that monitors disk speed,
# and creates fast replicas of each drive's snapshots (so 'w' doesn't hang).
############################################################################

readonly _monitor_dir=$status_dir/drives

readonly    _mon_lock_dir=$_monitor_dir/lock	       # world-writable,for 'w'
readonly   _mon_globs_dir=$_monitor_dir/globs	       # where list snapshots
readonly  drive_msecs_dir=$_monitor_dir/msecs	       # response time, for 'w'
readonly window_msecs_dir=$_monitor_dir/window-msecs   # msec sample periods
readonly snapshots_replica_dir=$_monitor_dir/snapshots # 'w' uses, avoids hangs
readonly non_empty_partial_dir=$_monitor_dir/partials  # for stats's -e and -E

function create-monitor-dirs() {

	local dirs="$_mon_globs_dir $drive_msecs_dir $window_msecs_dir
		    $snapshots_replica_dir $non_empty_partial_dir"
	mkdir -p $dirs $_mon_lock_dir &&
	chmod ugo+rwx  $_mon_lock_dir	# so don't need sudo-lockpid
}
readonly -f create-monitor-dirs

# ----------------------------------------------------------------------------

lock-replica-of-snapshots() {

	local sleep_msecs=0.5		# less than mon_* resolution
	local lock_file=${FUNCNAME#*lock-}.pid

	local lockpid_opts="--dir=$_mon_lock_dir --sleep-msecs=$sleep_msecs"
	umask 0				# so watch doesn't need sudo-lockpid
	$IfRun lockpid $lockpid_opts "$@" $lock_file || print-call-stack
	umask $umask
}
readonly -f lock-replica-of-snapshots

# ----------------------------------------------------------------------------

declare -i msecs epoch_msecs

readonly mon_overhead_drive_name=_RAM_
readonly mon_overhead_drive_dir=$snapshots_replica_dir

mon-launch-globs() {

	local drive_name drive_dir
	for drive_name
	    do	 set-drive_dir- $drive_name || abort "bad $drive_name"
		[[ ${drive_name2PID[$drive_name]-} ]] && continue # hung drive?

		cd $drive_dir || continue

		local glob_file=$_mon_globs_dir/$drive_name
		local -i epoch_msecs
		set-epoch_msecs # takes ~1 msec to fork+exec (not if bash-5)
		# if $ls_drive_name2PID[$drive_name] still alive, slows this:
		( echo $snapshot_glob* > $glob_file; touch -r . $glob_file ) &
		drive_name2PID[$drive_name]=$!
		drive_name2msecs[$drive_name]=$epoch_msecs

		if [[ $drive_name == $mon_overhead_drive_name ]]
		   then local mon_msec_increment=2  mon_sec_increment=0.002
			mon-look-for-finished-globs $drive_name
			continue	# don't need *.partial code
		fi

		local  PID=${ls_drive_name2PID[$drive_name]-}
		[[ $PID ]] && kill -0 $PID 2> $dev_null && continue # running?
		#
		local partial_file=$non_empty_partial_dir/$drive_name
		(set -- $snapshot_glob.partial
		 [[ $# == 0 ]] && > $partial_file ||
		 # snapshot non-empty if has subdirectories: check link count
		 ls -ld $* | awk '$2 > 2 { print $(NF) }' > $partial_file.$$ &&
					mv $partial_file.$$ $partial_file   ) &
		ls_drive_name2PID[$drive_name]=$!
	done

	cd $tmp_dir		    # in case user tries to unmount $drive_dir
}
readonly -f mon-launch-globs

# ----------------------

mon-process-finished-glob() {
	local drive_name=$1

	set-epoch_msecs
	local -i    start_msecs=${drive_name2msecs[$drive_name]}
	local -i response_msecs=$epoch_msecs-$start_msecs

	local -i window_msecs=$(< $window_msecs_dir/$drive_name)
	local -i sample_count=$window_msecs/$mon_check_period_msecs
	(( $sample_count <= 0 )) && sample_count=1

	if (( $response_msecs <= $mon_check_period_msecs ))
	   then local samples=$response_msecs
	   else # repeat $response_msecs if it spans multiple check-periods
		local samples=
		for ((  span=0, i=0;
		       $span < $response_msecs && $i < $sample_count;
			span+=$mon_check_period_msecs, i++ ))
		    do	samples+="$response_msecs "
		done
	fi

	local msecs_file=$drive_msecs_dir/$drive_name
	if [[ -s $msecs_file ]]
	   then set -- $(< $msecs_file) $samples
	   else set --			$samples
	fi
	while (( $# > $sample_count )) ; do shift; done
	echo-to-file "$*" $msecs_file

	local  snapshots_dir=$snapshots_replica_dir/$drive_name
	[[ -d $snapshots_dir ]] || mkdir $snapshots_dir
	cd_   $snapshots_dir
	local glob_file=$_mon_globs_dir/$drive_name
	lock-replica-of-snapshots --wait # 'w' action uses same locking
	rm -f *
	local subdirs=$(< $glob_file)
	[[ $subdirs ]] && touch $subdirs
	touch -r $glob_file .
	lock-replica-of-snapshots --release
}
readonly -f mon-process-finished-glob

# ----------------------

function do-have-snapshots-of-type() {
	local suffix=$1 drive_name=${2:-$drive_name}

	lock-replica-of-snapshots --wait
	cd $snapshots_replica_dir/$drive_name || return 1
	set -- *$suffix
	lock-replica-of-snapshots --release
	cd $OLDPWD

	[[ $# != 0 ]]
}
readonly -f do-have-snapshots-of-type

# -------------------------------------------------

is-set		mon_check_period_secs || # can set custom value in $config_file
readonly	mon_check_period_secs=0.5 # when look for newly-attached drives
set-msecs--from-secs $mon_check_period_secs # and also used for watch -n period
declare -r -i	mon_check_period_msecs=$msecs
#
is-set        mon_msecs_increment || # can set custom value in $config_file
declare -r -i mon_msecs_increment=1  # lower -> more precision, more CPU usage

readonly mon_initialized_lock_path=$_mon_lock_dir/initialized.pid

# pass a single drive_name for "solitary" processing (to measure overhead)
mon-look-for-finished-globs() {
	[[ $# == [01] ]] || abort-function "[drive_name]"
	local _drive_name=${1-}

	set-epoch_msecs
	local -i start_msecs=$epoch_msecs
	local -i sleep_msecs  slept_msecs
	# Sleep progressively longer as wait for slower drives: this keeps
	# the precision-rate relatively constant, while using less CPU
	# (even though the precision is much higher at the beginning).
	for (( sleep_msecs=0, slept_msecs=0;
	       slept_msecs + sleep_msecs < $mon_check_period_msecs;
	       slept_msecs+=$sleep_msecs, sleep_msecs+=$mon_msecs_increment ))
	   do	set -- ${drive_name2PID[*]} # any backgrounded globbing?
		if [[ $# == 0 ]]	    # if not, stop looking
		   then [[ $_drive_name ]] && abort-function "logic error"
			lockpid --wait $mon_initialized_lock_path > $dev_null
			set-epoch_msecs
			local -i used_msecs=$epoch_msecs-$start_msecs
			local -i left_msecs=$mon_check_period_msecs-$used_msecs
			set-secs--from-msecs -3 $left_msecs
			[[ $secs != *-* ]] && # avoid negative values
			env sleep $secs	# want to appear in ps
			return
		fi

		local drive_name
		for drive_name in ${_drive_name:-${!drive_name2PID[*]}}
		    do	local  PID=${drive_name2PID[$drive_name]}
			[[ $PID ]] && kill -0 $PID 2> $dev_null &&
			    continue			    # hasn't finished
			drive_name2PID[$drive_name]=	    # just finished
			unset "drive_name2PID[$drive_name]" # (might not work)

			mon-process-finished-glob $drive_name &
			[[ $_drive_name ]] && wait $! && return
		done

		msleep $sleep_msecs
	done
}
readonly -f mon-look-for-finished-globs

# ----------------------------------------------------------------------------

update-monitor-drive-config() {
	[[ ${1-} == -c ]] && { shift; local do_check=$true; } ||local do_check=
	[[ $# == 0 ]] &&
	    set-drive_names -a && set -- $drive_names $mon_overhead_drive_name

	cd_ $window_msecs_dir

	local drive_name
	for drive_name
	    do	local window_msecs_file=$drive_name

		if [[ $do_check ]]
		   then is-newer $window_msecs_file $config_file && continue
			$our_path update-monitor-drive-config #so reread config
			break
		fi

		[[ $drive_name == $mon_overhead_drive_name ]] &&
		    drive_name=$1	# need a valid drive_name
		local customized_value
		set-customized_value--for-config-var-name \
		    drive_response_averaging_window_secs
		set-msecs--from-secs $customized_value
		echo-to-file $msecs $window_msecs_file
	done
}
readonly -f update-monitor-drive-config

# ----------------------------------------------------------------------------

readonly drive_monitor_lock_path=$lock_dir/monitor.pid

monitor-drives() {

	lockpid -q $drive_monitor_lock_path || exit-normally 0

	create-status_dir &&
	create-monitor-dirs || abort-function "couldn't create dirs"

	exec &> $_monitor_dir/monitor.log # to catch problems

	local -A -i drive_name2msecs	# drive response time in millliseconds
	local -A    drive_name2PID	# don't use -i: set to '' when PID dies
	local -A ls_drive_name2PID	# ditto
	while true			# monitor forever
	    do	set-drive_names -a	# see if a new drive appeared
		# $mon_overhead_drive_name MUST be first, see $_drive_name code
		drive_names="$mon_overhead_drive_name $drive_names"
		update-monitor-drive-config -c $drive_names # new confgure.sh?
		mon-launch-globs $drive_names
		mon-look-for-finished-globs
	done
}
readonly -f monitor-drives

# ----------------------------------------------------------------------------

re-start-monitor-drives-if-needed() {
	[[ ${1-} == -f ]] && { shift;local do_force=$true; } || local do_force=

	[[ $UID == 0 ]] || { sudo -n kill&&sudo -n $our_path; } &> $dev_null ||
	    return

	if [[ $do_force ]] ||
	   ( [[ $our_path == /usr/* ]] &&   # are we the installed command?
	     is-newer $our_path $drive_monitor_lock_path )
	   then lock-replica-of-snapshots --wait    # don't interrupt monitor
		until signal-job -KILL $drive_monitor_lock_path
		   do	$IfRun env sleep 0.09 # wait for globs/etc; watch hangs
		done
		lock-replica-of-snapshots --release
	fi

	is-active-lock $drive_monitor_lock_path ||
	    sudo $our_path monitor-drives > $dev_null
}
readonly -f re-start-monitor-drives-if-needed


##############################################################################
# Manage priorities for backup and prune and update/copy.
##############################################################################

function is-multi-writer-drive() {
	local drive_name=${1:-$drive_name}

	set-customized_value--for-config-var-name is_multi_writer_drive

	[[ $customized_value ]]
}
readonly -f is-multi-writer-drive

# ----------------------------------------------------------------------------

declare -i highest_drive_usage

function is-drive-usage-too-high() {
	if [[ ${1-} == -e ]]		# want a little extra free space?
	   then local -i extra=$2; shift 2
	   else local -i extra=0
	fi
	local drive_dir=${1:-$drive_dir}

	local drive_name
	 set-drive_name- $drive_dir
	set-customized_value--for-config-var-name max_FS_usage_percent &&
	local max_FS_usage_percent=$customized_value

	suspend-tracing
	local -i pcent ipcent
	setup-df-data-from-fields $drive_dir pcent ipcent
	local -i block_percent=$pcent inode_percent=$ipcent
	if (( $block_percent > $inode_percent ))
	   then max_drive_usage_percent=$block_percent-blk
	   else max_drive_usage_percent=$inode_percent-ind
	fi
	restore-tracing

	if (( $block_percent > $inode_percent ))
	   then highest_drive_usage=$block_percent
	   else highest_drive_usage=$inode_percent
	fi
	(( $block_percent + $extra <= $max_FS_usage_percent )) || return 0
	(( $inode_percent + $extra <= $max_FS_usage_percent )) || return 0
	return 1
}
readonly -f is-drive-usage-too-high

# ----------------------

# For XFS, it's best to set max_drive_usage_percent low, to keep
# the filesystem fast; but, when there's no more pruning to be done,
# you might decide it's OK to do more (slower) copy'ing.

is-set   max_drive_usage_percent_for_copy || # custom value in $config_file?
readonly max_drive_usage_percent_for_copy=95

function is-drive-usage-too-high-for-copy() {
	local drive_dir=${1:-$drive_dir}

	is-drive-usage-too-high $drive_dir || return 1

	do-have-snapshots-of-type .rm && return 0 # pruning takes priority

	prune-drive -m $drive_name     # just rename snapshots needing pruning
	$IfRun msleep $mon_check_period_msecs # await replica update
	do-have-snapshots-of-type .rm && return 0

	(( $highest_drive_usage > $max_drive_usage_percent_for_copy ))
}
readonly -f is-drive-usage-too-high-for-copy

# --------------------------------------

declare -A job_type2priority_level

# this is mostly relevant when $is_multi_writer_drive
set-job_type2priority_level() {

	if is-drive-usage-too-high
	   then job_type2priority_level=(
		    [prune]=higher
		   [backup]=medium
		     [copy]=lower
		)
	   else job_type2priority_level=(
		   [backup]=higher
		     [copy]=medium
		    [prune]=lower
		)
	fi
}
readonly -f set-job_type2priority_level

# -----------------------

# this sets the 'priority' variable _and_ changes the process priority
function set-priority() {
	local job_type=$1 PGID=${2:-$$}

	set-job_type2priority_level
	priority=${job_type2priority_level[$job_type]}

	local CPU_priority_cmd=${level2CPU_priority_cmd[$priority]}
	local  IO_priority_cmd=${level2IO_priority_cmd[$priority]}

	# test-prune is very noisy in here
	[[ $action == prune-drive* && $drive_name == [zZ] ]] && return 0

	{
	$IfRun $CPU_priority_cmd $PGID && { [[ ! $IO_priority_cmd ]] ||
	$IfRun  $IO_priority_cmd $PGID					; }
	} 2> $dev_null |
	if [[ $is_regression_test ]]
	   then sed "s@\b$PGID\b@<a_PGID>@"
	   else egrep -v ' new priority '
	fi
	[[ ${PIPESTATUS[0]} == 0 ]]
}
readonly -f set-priority

# ----------------------------------------------------------------------------

function reset-drive-jobs-priorities {

	local type job_PGID status=1
	for type in $writer_types
	    do	set-job_PGID $type || continue
		set-priority $type $job_PGID  # *-save-writer-stats uses var
		status=0
	done
	return $status
}
readonly -f reset-drive-jobs-priorities

# ------------------------------------------

function is-copy-higher-priority-than-prune() {
	local drive_name=${*:-$drive_name}

	set-drive_name- $drive_name
	reset-drive-jobs-priorities || return 1

	have-job copy || { continue-jobs prune; return 1; }

	local copy_PGID
	if is-drive-usage-too-high-for-copy
	   then suspend-jobs copy
		if set-copy_PGID--if-copy-src #2 drives copying to each other?
		   then local lock_paths
			set-lock_paths prune
			lockpid --release $lock_paths &> $dev_null
		fi
		continue-jobs prune # may do nothing if backup running
	   else set-copy_PGID--if-copy-src && # is this a copy job's source?
		   return 0	    # don't suspend _or_ prune
		continue-jobs copy  # may do nothing if backup running
		is-multi-writer-drive || { suspend-jobs prune; return 0; }
	fi

	return 1
}
readonly -f is-copy-higher-priority-than-prune

# users besides prune just need a simple/clear name
reset-priority() { is-copy-higher-priority-than-prune "$@"; }
readonly -f reset-priority

##############################################################################
##############################################################################
# Functions and variables used to record writer stats
##############################################################################
##############################################################################

readonly stats_dir=$log_dir/stats

readonly stats_data_types="MB minutes"

# first letter of each basename is used in rm-dangling-stats-symlinks
readonly    MB_used_basename=MB-changes
readonly    rm_time_basename=rm-minutes
readonly rsync_time_basename=rsync-minutes

# ---------------------------------

rm-dangling-stats-symlinks() {

	cd $stats_dir &> $dev_null || return

	for drive in [bcp]*/[Mr]*/*	# {backup,copy,prune}/{*-minutes,MB*}/*
	    do	[[ -L $drive && ! -e $drive ]] && rm $drive
	done

	cd $OLDPWD
}
readonly -f rm-dangling-stats-symlinks

# --------------------------------------------

function set-stats_subdir() {
	local  data_type=${1:-$data_type}

	if [[ $data_type == MB ]]
	   then basename=$MB_used_basename
	   else # shellcheck disable=SC1075
		if [[ $writer_type == prune ]]
		   then local basename=$rm_time_basename
		   else local basename=$rsync_time_basename
		fi
	fi

	stats_subdir=stats/$writer_type/$basename
	[[ -d $stats_subdir ]]	     # only relevant if $PWD == $drive_log_dir
}
readonly -f set-stats_subdir

# ----------------------------------------------------------------------------

create-stats_subdir-and-symlink-to-it() {
	local stats_subdir=$1

	local dir=$drive_log_dir/$stats_subdir
	mkdir -p $dir # do for pseudo-drive Z, makes regression tests readable
	local link=$log_dir/$stats_subdir/$drive_name
	$IfRun mkdir -p ${link%/*}
	[[ -e $link ]] ||
	$IfRun ln -s ../../../drives/$drive_name/$stats_subdir $link
}
readonly -f create-stats_subdir-and-symlink-to-it

# ----------------------------------------------------------------------------

handle-stats-when-multiple-writers() {
	local snapshot=$(basename $1)
	snapshot=${snapshot%%.*}

	cd_ $drive_log_dir

	local multi_msg="multiple writers during this job, MB change unknown"

	local lock_file did_find_multiple_writers=$false
	for lock_file in stats/*/$MB_used_basename/*.pid
	    do	# remove stale lock, if any ... and also our own (old??) lock
		lockpid $lock_file &> $dev_null && lockpid -r $lock_file &&
		    continue
		echo-to-file "$multi_msg" ${lock_file%.pid}.txt
		did_find_multiple_writers=$true
	done

	local stats_subdir
	set-stats_subdir MB || mkdir -p $stats_subdir || abort mkdir
	local lock_file=$stats_subdir/$snapshot.pid
	local lock_cmd="lockpid $lock_file"
	$IfRun $lock_cmd || abort-function ": $lock_cmd -> $?"
	if [[ $did_find_multiple_writers &&
	      # with disks: backup is the sole writer, and never suspended
	      ( $writer_type != backup || $is_multi_writer_drive ) ]]
	   then echo-to-file "$multi_msg" ${lock_file%.pid}.txt
	fi

	cd_ $OLDPWD
}
readonly -f handle-stats-when-multiple-writers

# --------------------------------------------

save-stats-file() {
	local stats_subdir=$1 snapshot=$(basename $2) data=$3
	snapshot=${snapshot%%.*}

	cd $drive_log_dir || abort cd
	local data_file=$stats_subdir/$snapshot.txt

	# OK if multiple writers -> larger minutes, that's "current reality"
	if [[ $data_type == MB ]]
	   then local lock_file=${data_file%.txt}.pid
		$IfRun lockpid -r $lock_file
		# a prune or copy could have been suspended by another writer
		if [[ -s $data_file ]]
		   then local  stats_content=$(< $data_file)
			if [[ $stats_content != [-0-9]* ]] # multiple writers?
			   then cd $OLDPWD
				return
			fi
		fi
	fi

	if [[ $data_type == MB ]]	 # MB file needed for jobs_per_day stat
	   then if [[ $data != [-0-9]* ]] # text, i.e. unknown MB?
		   then data="this was a restart, MB change unknown"
		elif [[ ( $data == -1 || $data == 1 ) && $debug_opt ]]
		   then data=0		# for regression test
		fi
	elif [[ $data != [-0-9]* ]]	# unknown minutes? (bug if negative)
	     then cd $OLDPWD		# minutes file not needed for stats
		  return
	fi

	echo-to-file "$data" $data_file

	cd $OLDPWD
}
readonly -f save-stats-file

# ---------------------------------

is-set	      days_to_keep_stats ||	# can set custom value in $config_file
declare -r -i days_to_keep_stats=3	# ensure more than weekend-only data

is-set	      min_stats_files_to_keep || # can set custom value in $config_file
declare -r -i min_stats_files_to_keep=5

prune-stats-files() {
	local stats_subdir=$1

	cd $drive_log_dir || abort cd

	set -- $stats_subdir/$snapshot_glob.txt # duplicated in for loop, below
	[[ $# != 0 ]] && {

	# copy'ed snapshots aren't copied in date,time order, so use file time
	local min_date_TS=$tmp_1
	local old_date=$(date -d "-$days_to_keep_stats days")
	touch --date="$old_date" $min_date_TS
	for file in $*
	    do	[[ $file -ot $min_date_TS  ]] || continue
		set -- $stats_subdir/$snapshot_glob.txt
		(( $# > $min_stats_files_to_keep )) || break
		$IfRun rm $file
	done

	}

	cd $OLDPWD
}
readonly -f prune-stats-files

# -------------------------------------------------------

archive-writer-stats-data() {

	cd $drive_log_dir || abort cd

	local data_type
	for data_type in $stats_data_types
	    do	local writer_type
		for writer_type in $writer_types
		    do	local stats_subdir
			set-stats_subdir $data_type || continue
			set -- $stats_subdir/*.txt
			if [[ $# != 0 ]]
			   then set-date_time -r $stats_subdir
				local dst_subdir=$stats_subdir/.${date_time%,*}
				$IfRun mkdir -p    $dst_subdir
				$IfRun mv -v $stats_subdir/*.txt $dst_subdir/
			fi  |  sed "s@named '$stats_subdir/@@"
		done
	done

	cd $OLDPWD
}
readonly -f archive-writer-stats-data

# ----------------------------------------------------------------------------

save-writer-stats() {
	local snapshot=$1

	cd_ $drive_log_dir

	local data_type
	for data_type in $stats_data_types
	    do	   set-stats_subdir $data_type ||
		create-stats_subdir-and-symlink-to-it $stats_subdir
		eval "local data=\$writer_$data_type"
		 save-stats-file  $stats_subdir $snapshot $data &&
		prune-stats-files $stats_subdir
	done

	cd $OLDPWD
}
readonly -f save-writer-stats

# ----------------------------------------------------------------------------

set-used_MB-size_MB() {
	local drive_dir=${1:-$drive_dir}

	local -i used size
	setup-df-data-from-fields -m $drive_dir used size # -BM appends 'M'
	used_MB=$used
	size_MB=$size
}
readonly -f set-used_MB-size_MB

# --------------------------------------------

set-SECONDS-starting_MB--for-save-writer-stats() {
	if [[ $1 == -r ]]
	   then shift
		local is_a_restart=$true
	   else local is_a_restart=$false
	fi
	local snapshot=$1

	if [[ $is_a_restart ]]		# already half-done?
	   then SECONDS=-1123456789	# our signal to not record stats
	   else SECONDS=0		# else do
		local -i used_MB size_MB
		set-used_MB-size_MB
		starting_MB=$used_MB
	fi

	handle-stats-when-multiple-writers $snapshot
}
readonly -f set-SECONDS-starting_MB--for-save-writer-stats

# -------------------------------------------------------

set-writer_stats_msg--as-save-writer-stats() {
	local snapshot=$1

	writer_stats_msg="(priority=${priority:-default})"

	if (( $SECONDS >= 0 ))		# not a restart, want to record stats?
	   then local -i minutes
		local hours used_MB division
		# we use varnames writer_{data_type}; see stats_data_types=
		set-minutes--from-secs $SECONDS
		local -i writer_minutes=$minutes
		set-hours--from-minutes $writer_minutes
		local writer_hours=$hours

		local used_MB size_MB
		set-used_MB-size_MB
		local -i writer_MB=$used_MB-$starting_MB
		set-division -2 $writer_MB 1024
		local writer_GB=$division
		[[ $writer_GB == -0.00 ]] && writer_GB=${writer_GB#-}

		writer_stats_msg+=" in $writer_hours hours; used $writer_GB GB"
	   else writer_stats_msg+=": earlier attempt aborted"
		writer_MB=unknown  writer_minutes=unknown
	fi

	save-writer-stats $snapshot
}
readonly -f set-writer_stats_msg--as-save-writer-stats

##############################################################################
##############################################################################
# Functions and variables used to prune old backup snapshots.
##############################################################################
##############################################################################

sync-drive-unless-writers() {
	local locks_to_skip=$*

	local lock locks=
	for lock in $writer_types
	    do	is-arg1-in-arg2 $lock $locks_to_skip || locks+=" $lock"
	done
	for lock in $locks
	    do	set-lock_path  $lock
		is-active-lock $lock_path && return
	done &> $dev_null

	$IfRun sync --file-system $drive_dir &> $dev_null # maybe not supported
}
readonly -f sync-drive-unless-writers

# ----------------------------------------------------------------------------

function count-rsyncs-using-resource() {
	local regex=$*

	[[ $drive_name == [zZ] || $IfRun ]] && return 0
	return $(COLUMNS=9999 ps -U root | egrep -c "\brsync .*$regex")
}
readonly -f count-rsyncs-using-resource

# ---------------------------------

function is-sleeping() {
	local job_type=$1 drive_name=${2:-$drive_name} executables

	set-drive_name- $drive_name
	set-job_PGID $job_type || return 1
	set-executables--in-process-groups $job_PGID || { warn "set-exe* -> $?"
		print-call-stack $drive_name; ps-locks $job_type $drive_name;
		return 1; }
	is-arg1-in-arg2 sleep $executables
}
readonly -f is-sleeping

# ---------------------------------

function is-suspended() {
	local job_type=$1 drive_name=${2:-$drive_name} state

	set-drive_name- $drive_name
	set-job_PGID $job_type || return 1
	set-state--in-process-groups $job_PGID || { warn "set-exe* -> $?"
		print-call-stack $drive_name; ps-locks $job_type $drive_name;
		return 1; }
	[[ $state == *T* ]]
}
readonly -f is-suspended

# ----------------------------------------------------------------------------

function update-snapshots-ls {

	[[ ! $debug_opt ]] &&
	echo $snapshot_glob* | tr ' ' '\n' > $drive_log_dir/snapshots.ls
	return 0			# so can precede and follow by '&&'
}
readonly -f update-snapshots-ls

# ----------------------------------------------------------------------------

function _is-time-to-prune-drive() {
	local dir=${1:-$drive_dir}

	[[ ! $is_cron || $is_regression_test ]] && return 0 # run by a person?

	[[ $(date '+%H') == 00 ]] && return 0 # time for our daily prune?

	is-drive-usage-too-high   && return 0 # desparately need a prune?

	set -- $dir/*.rm
	[[ $# != 0 ]] && return 0	# have partially-deleted snapshots?

	local pruned_TS=$dir/$pruned_timestamp

	[[ ! -e $pruned_TS ]] && return 0 # never finished a prune?
	[[ $pruned_TS -ot $config_file   ]] && return 0 # newer config?
	[[ $pruned_TS -ot $exclude_file  ]] && return 0 # newer excludes?
	[[ $(find $pruned_TS ! -mtime 0) ]] && return 0	# not pruned recently?

	return 1			# not time to prune
}
readonly -f _is-time-to-prune-drive

# ----------------------

function _should-run-prune {

	[[ ! $only_do_mv ]] || return 0	# only 'mv' (and rmdir empty dirs)?

	# the following logic is odd, it ensures real-user's request is honored

	if [[ $is_cron ]]
	   then is-copy-higher-priority-than-prune && return 1
	   else # if user changed backup_period or prune-rate, need to rescan
		kill-job-on-drives prune # kill old job, we'll be new job
	fi

	[[ $is_cron ]] && local lock_opt= || local lock_opt=-w
	lock $lock_opt prune &> $tmp_2
	local status=$?
	egrep -v 'process [0-9]+ holds [^ ]* lock for' $tmp_2
	[[ $status != 0 ]] &&		# prune probably already running
	    { is-copy-higher-priority-than-prune; return 1; }

	if [[ $is_cron ]]
	   then _is-time-to-prune-drive || { unlock prune; return 1; }
	   else # this could suspend ourself, which is OK ...
		is-copy-higher-priority-than-prune # real person, can wait
	fi

	return 0
}
readonly -f _should-run-prune

# ----------------------------------------------------------------------------

function sudo-unless-dir-writable() {
	[[ $1 == -n ]] && { local sudo_opt=$1; shift; } || local sudo_opt=
	local path=${!#}

	[[ $path == */* ]] && local dir=${path%/*} || local dir=.
	if [[ -w $dir ]]
	   then "$@"
	   else sudo $sudo_opt "$@"
	fi
}
readonly -f sudo-unless-dir-writable

# ---------------------------------

_prune-exclude-globs-from-all-snapshots() {

	local pruned_TS=$drive_dir/$pruned_timestamp
	[[ $drive_name == [zZ] ||	# regression test?
	   ( ! $debug_opt &&		# ... too slow for real drive
	     # very slow: only run if exclude.txt changed since our last run
	     ( ! -e $pruned_TS ||
		    $pruned_TS -ot $exclude_file ) ) ]] || return

	remember-tracing

	# prune exclude-globs from _all_ snapshots, very slow
	local exclude_glob file
	for snapshot in $drive_dir/$snapshot_glob*
	    do	[[ $snapshot == *.rm ]] && continue
		grep '^ */' $exclude_file | fgrep -v '**' |
		while read exclude_glob
		    do	set -- $snapshot$exclude_glob
			for file	# can have SPACEs, need to quote it
			   do	[[ -e "$file" ]] && echo "$file"
			done
		done
		suspend-tracing
	done | tr '\n' '\0' | xargs -0 -r $IfRun rm -r # -0: files with SPACEs

	$IfRun log "pruned exclude-globs from _all_ snapshots"

	restore-tracing
}
readonly -f _prune-exclude-globs-from-all-snapshots

# ---------------------------------

rm-pruned-snapshots() {
	local snapshots_file=$1

	local snapshot

	assert-drive_dir-writable $PWD

	remember-tracing		# in case comment-out next line ...
	suspend-tracing

	# sort snapshots, for regression-test
	set -- $(tr ' ' '\n' < $snapshots_file | sort -u)
	rm $snapshots_file

	if [[ $is_update && $debug_opt ]]
	   then local sudo=sudo-unless-dir-writable
	   else local sudo=
	fi

	# first, rename snapshots to be pruned, so can see the pruning backlog
	local -i rm_count=0
	local    rm_snapshots=
	for snapshot
	    do	[[ $snapshot != *.rm && ! -e $snapshot/.keep ]] &&
		[[ -e $snapshot ]] || continue
		[[ ! $debug_opt ]] &&		 # speedup for regression test
		# could instead use: count-rsyncs-using-resource $snapshot
		fuser -s $snapshot/. && continue # don't rename if in-use
		if [[ $is_update ]]
		   then  $sudo mv $verbose_opt $snapshot $snapshot.rm
		   else $IfRun mv	       $snapshot $snapshot.rm
		fi
		let rm_count+=1;  rm_snapshots+="$snapshot "
	done

	update-snapshots-ls

	[[ $rm_count != 0 && ! $is_update ]] &&
	if (( $log_level >= 3 ))
	   then [[ $debug_opt ]] ||
		log "will prune these snapshots: " $rm_snapshots
	   else local -i n=$rm_count
		$IfRun \
		log "pruning $n snapshots: will rename to *.rm for deletion"
	fi

	if [[ $only_do_mv ]]
	   then set -- *.partial.rm	# some from update, some from pruning
		[[ $# != 0 ]] && $sudo env rmdir --ignore-fail-on-non-empty $*
		restore-tracing
		return
	fi

	# delete .partial snapshots first, they're less useful
	set -- $snapshot_glob.partial.rm $snapshot_glob.rm
	local snapshot_basenames=$*

	restore-tracing

	if [[ ! -d latest ]]
	   then set -- $snapshot_glob # only the successful snapshots
		[[ -d ${!#} ]] && $IfRun rm -f latest &&
		$IfRun ln -s $(basename ${!#}) latest
	fi

	suspend-tracing
	# put newest ones first, since they have the most hardlinks.
	# use absolute paths, so the 'ps' output is more clear.
	set -- $(echo $drive_dir/*.rm | tr ' ' '\n' | sort -r)
	local number_pruned_snapshots=$#
	restore-tracing number_pruned_snapshots

	$Trace
	# just prune subdirs containing files with massive # of hard-links;
	# except too-high drive usage is more critical than "Too many files".
	if [[ $drive_name == [zZ] ]]
	   then FS_type=
	   else	set-FS_type--from-path $PWD
	fi
	case ${FS_type,,} in
	    ( xfs | btrfs | apfs ) # any FS that supports a zillion links
		hard_link_dirs= ;;
	esac
	[[ ${hard_link_dirs-} ]] && ! is-drive-usage-too-high $drive_dir &&
	for snapshot
	    do	local subdir
		for subdir in $hard_link_dirs
		    do	${rm_snapshot_pre_hook-} # could set snapshot= to block
			$IfRun env rm -rf $snapshot$subdir
			${rm_snapshot_post_hook-} # could update database
		done
		suspend-tracing
	done
	subdir=
	restore-tracing

	# finally, prune the rest of the contents of the *.rm snapshots
	for snapshot
	    do	# is this snapshot already partially deleted?
		if [[ $snapshot == *.partial* ]]
		   then local restart_opt=-r
		   else local restart_opt=
		fi
		local  -i   starting_MB=0
		set-SECONDS-starting_MB--for-save-writer-stats \
		    $restart_opt ${snapshot%.partial*}

		local did_rm=$false
		while true; do		 # so following code can 'break'
		${rm_snapshot_pre_hook-} # could remove .rm suffix, touch .keep
		[[ $snapshot != *$snapshot_glob.rm ]] || # already .partial.rm?
		$IfRun mv $snapshot ${snapshot%.rm}.partial.rm || break
		$IfRun  env   rm -r ${snapshot%.rm}*.rm || break # .rm removed?
		${rm_snapshot_post_hook-} # could update database
		did_rm=$true
		break
		done
		[[ $did_rm ]] || SECONDS=-1123456789 # treat like restart

		set-writer_stats_msg--as-save-writer-stats $snapshot
		(( $log_level >= 2 )) &&
		    log "deleted $(basename $snapshot) $writer_stats_msg"
		suspend-tracing
	done
	restore-tracing

	update-snapshots-ls

	(( $number_pruned_snapshots > 0 )) &&
	if (( $log_level >= 3 ))
	   then [[ $debug_opt ]] ||
	        log "deleted these pruned snapshots: $snapshot_basenames"
	   else $IfRun \
		log "deleted $number_pruned_snapshots *.rm pruned snapshots"
	fi

	_prune-exclude-globs-from-all-snapshots

	sync-drive-unless-writers prune
}
readonly -f rm-pruned-snapshots

# --------------------------------------------------------------------
# vars & funcs that implement snapshot date-time format, and pruning #
# --------------------------------------------------------------------

# snapshot basename format is Year-Mo-Da,Hr, all implemented in this section;
#    to implement snapshot_date_time_separator, search for: ,0 ,? ,$ ,/ ,* etc

readonly      snapshot_glob="[1-9][0-9][0-9]?-??-??,??" # Year-Mo-Da,Hr
# the following 3 are derived from snapshot_glob
readonly  snapshot_day_glob=${snapshot_glob%,??}       # Year-Mo-Da
readonly     snapshot_regex=${snapshot_glob//\?/.}
readonly snapshot_day_regex=${snapshot_regex%,??}

set-date_time() { date_time=$(date '+%Y-%m-%d,%H' "$@"); }
set-day--from-secs() {  day=$(date '+%Y-%m-%d' -d "@$1" ); }
set-seconds--from-snapshot() {
	snapshot_date_time=$1

	[[ $snapshot_date_time =~ ($snapshot_day_regex),([0-9]{2}) ]] ||
	   abort-function "$snapshot_date_time: not a valid snapshot"
	local date=${BASH_REMATCH[1]}  time=${BASH_REMATCH[2]}
	seconds=$(date '+%s' -d "$date $time:00")
}
readonly -f set-date_time set-day--from-secs set-seconds--from-snapshot

# --------------------------------------------

readonly ordered_prune_types="hour day month year"

# ---------------------------------

shorten-date() {
	case $1 in
	    (  hour ) sed 's/,..$//' ;;	# strip time from snapshot's date-time
	    (   day ) sed 's/-..$//' ;; # strip day from snapshot's date
	    ( month ) sed 's/-..$//' ;; # strip month from year-month
	    (  year ) sed   's/.$//' ;; # turn year into decade
	esac | uniq
}
readonly -f shorten-date

# ---------------------------------

declare -r -A type2date_suffix_glob=(
	 [NONE]=""
	 [hour]=",??"
	  [day]="-??,??"
	[month]="-??-??,??"
	 [year]="?-??-??,??"
)
[[ ${snapshot_glob%${type2date_suffix_glob[year]}} != \
   "$snapshot_glob" ]] ||
	abort "snapshot_glob has to end with type2date_suffix_glob[year]"

declare -r -A backup_period2minimal_snapshot_glob=(
    [1]="$snapshot_glob"
    [2]="$snapshot_day_glob,?[02468]"
    [3]="$snapshot_day_glob,{00,03,06,09,12,15,18,21}"
    [4]="$snapshot_day_glob,{[02][048],1[26]}"
    [6]="$snapshot_day_glob,{00,06,12,18}"
    [8]="$snapshot_day_glob,{00,08,16}"
   [12]="$snapshot_day_glob,{00,12}"
   [24]="$snapshot_day_glob,00"
)
readonly valid_backup_periods=${!backup_period2minimal_snapshot_glob[*]}
#
# the [hour] chunks are the complement of the previous map's values
declare -r -A type2prune_type_globs_=(
# period after prune: 2                4                  8          ~12    all
   [hour]=",?[13579]         ,{[02][26],1[048]}      ,{04,12,20}  ,{08,16}"
    [day]="-{?[3579],[1-3]1} -{[02][26],1[048],30} -{04,12,20,28} -{08,24} -16"
  [month]="-{0[3579],11}          -{02,08,12}         -{04,10}       -06"
   [year]="  [13579]                 {2,6}              {4,8}"
)
#
if \
is-set type2prune_type_globs		# can set custom value in $config_file
   then [[ "${type2prune_type_globs[hour]}" == \
	   "${type2prune_type_globs_[hour]}" ]] ||
	   abort "your custom type2prune_type_globs[hour] must match $our_name"
   else _array_declare=$(declare -p type2prune_type_globs_)
	eval "${_array_declare/type2prune_type_globs_=/type2prune_type_globs=}"
fi

# each set of globs skips one value in the range of possibilities, since
# that value is kept for the next higher-order span
declare -r -A type2skipped_value=([hour]=00 [day]=01 [month]=01 [year]=0)

set-prune_glob() {
	local type=$1 prune_type_glob=$2

	local date_suffix_glob=${type2date_suffix_glob[$type]}
	local date_prefix_glob=${snapshot_glob%$date_suffix_glob}
	case $type in
	   (  hour ) local date_suffix_type=NONE  ;;
	   (   day ) local date_suffix_type=hour  ;;
	   ( month ) local date_suffix_type=day   ;;
	   (  year ) local date_suffix_type=month ;;
	esac
	date_suffix_glob=${type2date_suffix_glob[$date_suffix_type]}
	prune_glob=$date_prefix_glob$prune_type_glob$date_suffix_glob{,.*}
}
readonly -f set-prune_glob

# ----------------------

validate-prune_globs() {
	while [[ ${1-} == -* ]]; do shift; done
	local name=${1:-Z}
	[[ $name == all ]] && name=Z
	set-drive_name- $name

	local parent_cmd=$(COLUMNS=9999 ps -o command= $PPID)
	[[  "$parent_cmd " =~ ' '(regression-test|rt)' ' ]] && local debug_opt=
	[[  "$parent_cmd " == *' -C -d prune-drive'*	 ]] && local debug_opt=

	customize-config-variables $drive_name
	set-type2date_span
	[[ $debug_opt ]] && declare -p type2date_span

	local test_dir=$tmp_dir/$our_name_-prune-$drive_name
	mkdir -p $test_dir
	cd $test_dir || abort cd

	set -f		  # make sure code not confused by unexpected globbing
	local type prefix tst_seq suffix
	for type in ${!type2prune_type_globs[*]}
	    do	[[ ${type2date_span[$type]-} =~ ^[1-9][0-9]*$ ]] ||
		    abort "don't have (valid) type2date_span[$type]"

		case $type in
		  ( hour  ) prefix=2000-01-01, tst_seq=0..23 suffix= ;;
		  (  day  ) prefix=2000-01-    tst_seq=1..31 suffix=,00 ;;
		  ( month ) prefix=2000-       tst_seq=1..12 suffix=-01,00 ;;
		  ( year  ) prefix=200	       tst_seq=0..9  suffix=-01-01,00;;
		esac

		set +f; rm -f *; set -f
		eval "set -- {$tst_seq}"
		local tst
		for tst
		    do	[[ $type != year && $tst == ? ]] && tst=0$tst
			> $prefix$tst$suffix
		done
		[[ $debug_opt ]] && header "$type in $PWD" && ls && echo "---"

		local prune_type_globs=${type2prune_type_globs[$type]}
		[[ $debug_opt ]] && echo "$type globs: $prune_type_globs"
		local -i span=0
		local popped_word
		while set-popped_word-is_last_word--from-list prune_type_globs
		   do	let span+=1
			local prune_type_glob=$popped_word
			local prune_glob
			set-prune_glob $type "$prune_type_glob"
			set +f; eval  "set -- $prune_glob"; set -f
			[[ $debug_opt ]] && echo "span=$span will prune: " $*
			local pruned
			for pruned
			    do	[[ ! -s $pruned ]] &&
				    echo $span > $pruned && continue
				local old_span=$(< $pruned)
				local new_span=$span
				abort "$pruned was pruned by spans $old_span and $new_span (first span is 1) in type2prune_type_globs[$type]"
			done
		done

		set +f; set -- *; set -f
		for tst in $*
		    do	[[ -s $tst ]] && continue
			local skipped_value=${type2skipped_value[$type]}
			local skipped_snapshot=$prefix$skipped_value$suffix
			[[ $skipped_snapshot == $tst ]] && { set +x;continue; }
			ls -s
			abort "$tst not pruned by type2prune_type_globs[$type]"
		done
	done
	set +f

	cd $OLDPWD
}
readonly -f validate-prune_globs

# ---------------------------------

declare -r -A type2date_span_var=(
    [hour]=days_per_span_for_hour_prune
     [day]=months_per_span_for_day_prune
   [month]=years_per_span_for_month_prune
    [year]=decades_per_span_for_year_prune
)

# ---------------

declare -A type2date_span

function set-type2date_span {

	local _type
	for _type in ${!type2date_span_var[*]}
	    do	local var=${type2date_span_var[$_type]}
		type2date_span[$_type]=${!var}
	done
}
readonly -f set-type2date_span

# ----------------------------------------------------------------------------
# end of: vars & funcs that implement snapshot date-time format, and pruning #
# ----------------------------------------------------------------------------

# optional $backup_period_for_update could be smaller than $backup_period
_set-backup_period--for-prune() {

	(( $backup_period>$backup_period_for_update &&
			  $backup_period_for_update > 0 )) &&
	    backup_period=$backup_period_for_update # don't prune copy'ed dirs

	# sometimes backup_period or (update version) set higher for speed
	(( $backup_period>$max_backup_period_for_pruning &&
			  $max_backup_period_for_pruning > 0 )) &&
	    backup_period=$max_backup_period_for_pruning
}

# ----------------------------------------------------------------------------

declare -A backup_period2minimal_snapshot_regex
#
for _period in ${!backup_period2minimal_snapshot_glob[*]}
    do	  value=${backup_period2minimal_snapshot_glob[$_period]}
	value=${value//\?/.}
	value=${value//\{/(}
	value=${value//\}/)}
	value=${value//,/|}
	value=${value/|/,} 		# restore $snapshot_date_time_separator
	backup_period2minimal_snapshot_regex[$_period]=$value
done
unset _period
readonly backup_period2minimal_snapshot_regex

set-date_span--scaled() {
	local _date_span=${1:-$date_span}

	set-product $_date_span $pruning_span_scale_factor
	date_span=$product
	(( $date_span <= 0 )) && date_span=1

	[[ ${type-} == hour ]] && local trace_level=2 || local trace_level=3
	TraceV $trace_level type date_span
}
readonly -f set-date_span--scaled

# --------------------------------------------

reverse-sorted-snapshot-basenames() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=

	echo $snapshot_glob*  |		# prune everything
	   tr ' ' '\n' | sort -u -r |
	   grep -v '\.rm$'		# rm-pruned-snapshots handles *.rm
	$xtrace
}
readonly -f reverse-sorted-snapshot-basenames

# --------------------------------------------

set-prune_types() {
	local final_prune_type=${1-X}

	prune_types=

	local _type
	for _type in $ordered_prune_types
	    do	prune_types+="$_type "
		[[ ${final_prune_type:0:1} == ${_type:0:1} ]] && break
	done
}
readonly -f set-prune_types

# --------------------------------------------

declare -i date_span_diff

# if short date span, want to skip over the same dates as would default span
set-date_span_diff() {
	local type=$1

	date_span_diff=0

	local span_var=${type2date_span_var[$type]}
	local default_date_span=${custom_config_var2default_value[$span_var]-}
	[[ $default_date_span && ! $is_regression_test ]] || return

	local -i custom_date_span=$date_span
	local -i date_span
	set-date_span--scaled $default_date_span
	local -i default_date_span=$date_span
	date_span_diff=$(( $default_date_span - $custom_date_span ))
}

# --------------------------------------------

prune-type-to-file() {
	local type=${1%s} file_of_snapshots_to_prune=$2; shift 2
	set -- $(echo $* | tr ' ' '\n' | cut -d. -f1 | shorten-date $type)
	is-arg1-in-arg2 $type $prune_types || { echo $*; return; }
	local remaining_reverse_sorted_snapshot_dates=$*

	set-type2date_span	# run after call to customize-config-variables
	local date_span=${type2date_span[$type]}
	set-date_span--scaled
	set-date_span_diff $type
	local date_suffix_glob=${type2date_suffix_glob[$type]}
	local prune_type_globs=${type2prune_type_globs[$type]}
	set -f; set -- $prune_type_globs; set +f
	declare -i number_prune_globs=$#

	Trace 5 "\n==> $type prune <=="
	local -i period=$backup_period
	local prune_glob
	while set-popped_word-is_last_word--from-list prune_type_globs
	    do	local prune_type_glob=$popped_word
		set -- $remaining_reverse_sorted_snapshot_dates

		# might want to delete *all* the snapshots left to be pruned
		if [[ $date_span == 0 ]]
		   then shift	      # don't delete span we previously pruned
			for date
			    do	echo $date*
			done
			break
		fi
		(( $# < 10 )) && local ss=$* || ss="$1 ${2-} ${3-} ... ${!#}"
		Trace 4 "\n  LOOP $type: $# dates left: $ss"

		shift $date_span 2> $dev_null || # skip span of newer dates
		    shift $# # shift does nothing if try to shift more than $#
		[[ ! $is_last_word ]] || shift $date_span_diff || shift $#
		remaining_reverse_sorted_snapshot_dates=$*
		local newest_prune_date_in_this_pass=${1-}
		[[ $newest_prune_date_in_this_pass ]] || break

		set-prune_glob $type "$prune_type_glob"
		TraceV 5 prune_type_glob prune_glob is_last_word
		eval "set -- $prune_glob"
		(( $# < 10 )) && local ss=$* || ss="$1 ${2-} ${3-} ... ${!#}"
		Trace 5 "\n Matched  $# snapshots: $ss"

		# skip over the snapshot prune-matches that aren't old enough,
		# i.e. the ones that were handled in earlier passes (spans)
		TraceV 5 date_suffix_glob newest_prune_date_in_this_pass
		set -- $(echo $* | tr ' ' '\n' | sort -r)
		while [[ $# != 0 ]]
		   do	[[ $1 == [^1-9]* ]] && shift && continue # skip junk
			local date=${1%$date_suffix_glob*}
			[[   $date > $newest_prune_date_in_this_pass ]] ||
			    break
			shift
		done
		[[ -d ${1-} ]] || continue
		# delete all the old-enough prune matches
		(( $# < 10 )) && local ss=$* || ss="$1 ${2-} ${3-} ... ${!#}"
		Trace 5 "\nDeleting ~$# snapshots: $ss"
		echo ${*##$oldest_snapshot*} # don't delete oldest snapshot
	done >> $file_of_snapshots_to_prune

	echo $remaining_reverse_sorted_snapshot_dates
}
readonly -f prune-type-to-file

# ---------------------------------------------------------

function prune-snapshots-not-matching-backup_period() {
	local file_of_snapshots_to_prune=$1

	local bp=$backup_period
	Trace 5 "prune snapshots whose hour doesn't fit backup_period=$bp"

	local regex=${backup_period2minimal_snapshot_regex[$backup_period]}
	local valid_snapshot_regex="$regex(|\..*)"
	local snapshot
	for snapshot in $snapshot_glob*
	    do	[[ $snapshot =~ $valid_snapshot_regex ]] ||
		   echo $snapshot
	done > $file_of_snapshots_to_prune
	[[  -s $file_of_snapshots_to_prune ]]
}
readonly -f prune-snapshots-not-matching-backup_period

# ---------------------------------------------------------

# The locking & job-management policy is documented in front of function lock()

# for the goals of this function, see prune-variable comments in configure.sh
function prune-drive() {
	if [[ ${1-} == -m ]]
	   then shift
		local only_do_mv=$true
	   else local only_do_mv=$is_update
	fi
	assert-not-option "${1-}"
	local drive_name=$1 drive_dir

	suspend-tracing
	set-drive_name $drive_name
	set-drive_dir  $drive_name || return 1
	restore-tracing

	_should-run-prune || return 1 # calls 'lock prune' (unless $only_do_mv)

	local -i backup_period=$backup_period
	    _set-backup_period--for-prune
	local  snapshots_to_prune_file=$tmp_4
	rm -f $snapshots_to_prune_file

	set-prune_types ${final_prune_type-}

	cd_ $drive_dir	# so can safely kill job with: fuser -k -M $drive_dir

	$Trace
	set -- $(reverse-sorted-snapshot-basenames)
	local oldest_snapshot=${!#}
	# prune-type-to-file returns dates remaining, to check for more pruning
	set -- $(prune-type-to-file hour  $snapshots_to_prune_file $*)
	set -- $(prune-type-to-file day   $snapshots_to_prune_file $*);#$Trace
	set -- $(prune-type-to-file month $snapshots_to_prune_file $*);#set +x
	set -- $(prune-type-to-file year  $snapshots_to_prune_file $*)

	rm-pruned-snapshots $snapshots_to_prune_file # it deletes the file
	rm -f $snapshots_to_prune_file

	[[ $only_do_mv ]] && return 0

	[[ ! $debug_opt ]] &&	     # did rm-pruned-snapshots actually prune?
	if is-drive-usage-too-high
	   then local file=$snapshots_to_prune_file
		prune-snapshots-not-matching-backup_period $file &&
		    rm-pruned-snapshots $file
		rm -f $snapshots_to_prune_file
	fi

	$IfRun touch $drive_dir/$pruned_timestamp # touch even if did nothing

	unlock prune
}
readonly -f prune-drive

##############################################################################
##############################################################################
# Functions and variables used to create new backup snapshots
##############################################################################
##############################################################################

# ----------------------------------------------------------------------------
# functions to setup --link-dest args to rsync
# ----------------------------------------------------------------------------

latest_snapshot=

function set-latest_snapshot() {
	local drive_dir=${1:-$drive_dir}

	[[ $latest_snapshot ]] && return 0

	latest_snapshot=$drive_dir/latest
	[[ -d $latest_snapshot ]] || { latest_snapshot= ; return 1; }

	local absolute_dir
	set-absolute_dir $latest_snapshot
	latest_snapshot=$absolute_dir
	return 0
}
readonly -f set-latest_snapshot

# ----------------------------------------------------------------------------

function _have-full-snapshot {

	set -- $snapshot_glob
	[[ $# != 0 ]]
}
readonly -f _have-full-snapshot

# ---------------------------------

declare -i num_full_link_dests

set-num_full_link_dests() {

	# need at least 2 --link-dest args in case the sysadmnin borked one,
	# and a few hours worth in case a file was deleted then recovered;
	# don't make this too large, it slows recovery from "Too many links"
	if (( $backup_period == 1 ))
	   then num_full_link_dests=4
	   else num_full_link_dests=2
	fi

	# if a file is new or modified,  we'll  check $num_full_link_dests
	# drives to (hopelessly) look for a match; if $num_full_link_dests
	# is 4 instead of 2, that's 4 extra dir-cache accesses (which
	# require disk accesses on a cache miss) for no good reason,
	# which can flush more useful entries from the cache: not worth it
	num_full_link_dests=2
}
readonly -f set-num_full_link_dests

# ----------------------

set-link_dest_dirs() {
	local new_snapshot=$1; shift
	# $* is now snapshots for --link-dest, ones closet to $new_snapshot 1st

	link_dest_dirs=

	while [[ ! -d ${1-} || ${1-} == $new_snapshot* ]]
	   do	[[ $# != 0 ]] || return	# we might not have any snapshots
		shift
	done
	[[ -d ${1-} ]] || return

	remember-tracing
	local -i goody_snapshots=0 links_snapshots=0 junky_snapshots=0
	_have-full-snapshot || junky_snapshots=-10 # big src, slow/flakey dst?
	local snapshot
	for snapshot in $*
	    do	[[ -d  $snapshot ]] || continue
		set -- $snapshot/*
		[[ $# != 0 ]] || continue # update's empty snapshot?
		# don't consider *.partial or *.links to be adequate;
		# rsync allows 20 --link-dest options max (10 per direction)
		case $snapshot in
		   (*.links) (( ++links_snapshots > 3 )) && continue ;;
		   (*.*    ) (( ++junky_snapshots > 2 )) && continue ;;
		   ( *     ) (( ++goody_snapshots >= $num_full_link_dests )) &&
				 link_dest_dirs+=" $PWD/$snapshot" && break ;;
		esac
		link_dest_dirs+=" $PWD/$snapshot"
		suspend-tracing
	done
	restore-tracing link_dest_dirs
}
readonly -f set-link_dest_dirs

# ----------------------

set-link_dest_opts() {
	local link_dest_dirs=$*

	[[ $link_dest_dirs ]] || { link_dest_opts= ; return; }

	(( $# <= 20 )) ||
	    abort-function "$*: $# snapshots, exceeds rsync's max (20)"

	link_dest_dirs=" $*"		# so handle first dir also
	link_dest_opts=${link_dest_dirs// / --link-dest=}
}
readonly -f set-link_dest_opts

# ------------------------------------------------------------------

set-sorted_snapshots() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local sort_opt=${1-}

	# want the .links snapshots too, so quickly recover from
	#    'Too many links' by just copying the file
	# want a .partial to get the latest stuff, but won't "count" it
	set -- $(echo $snapshot_glob{,.links,.partial} |
		   tr ' ' '\n' | sort $sort_opt)
	useful_snapshots=$*
	$xtrace
}
readonly -f set-sorted_snapshots

# --------------------------------------------

set-link_dest_opts--for-backup-drive() {
	local new_snapshot=${1##*/}   useful_snapshots

	set-num_full_link_dests
	set-sorted_snapshots -r		# reverse-sorted, i.e. newest first
	set-link_dest_dirs $new_snapshot $useful_snapshots
	set-link_dest_opts $link_dest_dirs
}
readonly -f set-link_dest_opts--for-backup-drive

# --------------------------------------------------------

# need to link to snapshots that are earlier and later than $new_snapshot
set-older_link_dest_dirs-newer_link_dest_dirs() {
	local new_snapshot=$1; shift; local excluded_dirs=$*   useful_snapshots
	TraceV 5 new_snapshot excluded_dirs

	set-sorted_snapshots -r		# reverse-sorted, i.e. newest first
	suspend-tracing
	local older_snapshots=
	for snapshot in $useful_snapshots
	   do	[[ $snapshot < $new_snapshot ]] || continue
		is-arg1-in-arg2 $PWD/$snapshot $excluded_dirs && continue
		older_snapshots+=" $snapshot"
	done
	restore-tracing
	set-link_dest_dirs $new_snapshot $older_snapshots # newest to older
	older_link_dest_dirs=$link_dest_dirs
	TraceV 5 older_link_dest_dirs

	set-sorted_snapshots
	suspend-tracing
	local newer_snapshots=
	for snapshot in $useful_snapshots
	   do	[[ $snapshot > $new_snapshot ]] || continue
		is-arg1-in-arg2 $PWD/$snapshot $excluded_dirs && continue
		newer_snapshots+=" $snapshot"
	done
	restore-tracing
	set-link_dest_dirs $new_snapshot $newer_snapshots # oldest to newer
	newer_link_dest_dirs=$link_dest_dirs
	TraceV 5 newer_link_dest_dirs
}
readonly -f set-older_link_dest_dirs-newer_link_dest_dirs

# ---------------------------------

# Need to link to snapshots that are earlier and later than $new_snapshot.  See
# J. in doc/Install.txt for tuning the VFS cache (directory and inode caches).
set-link_dest_opts--for-copy-snapshot() {
	local new_snapshot=${1##*/}

	# Optimize the order in which snapshots are chosen for the
	# --link-dest= options: The first snapshot should be the one that was
	# most-recently scanned, so it's in the VFS cache (directory and inode
	# caches), even if it's not the "nearest neighbor" (and thus less
	# likely to have what's needed): the most-recently-scanned snapshot is
	# $previously_copied_snapshot, the one we just created.  Since this
	# first snapshot is older than $new_snapshot, the next snapshot should
	# be newer: the 'latest' snapshot should be in the VFS cache, because
	# it's the most recent backup (if it's not in the cache, it needs to
	# be in the cache, for the next backup). For subsequent snapshots, do:
	# older, then newer, then even-older, then even-newer, ...

	local link_dest_fast_dirs=${previously_copied_snapshot-}
	set-latest_snapshot && link_dest_fast_dirs+=" $latest_snapshot"

	# $link_dest_fast_dirs usually has 2 dirs && num_full_link_dests == 2,
	# so we only need 1 (full) snapshot from $older_link_dest_dirs and from
	# $newer_link_dest_dirs, so we won't bother to alternate between them.

	set-num_full_link_dests
	[[ ${previously_copied_snapshot-} && $latest_snapshot ]] &&
	    let num_full_link_dests-=1
	TraceV 5  link_dest_fast_dirs num_full_link_dests
	set-older_link_dest_dirs-newer_link_dest_dirs $new_snapshot \
						      $link_dest_fast_dirs

	# For a server that has continually-added and never-deleted files
	# (like a git or snapshot server), $latest_snapshot is almost as
	# effective as $newer_link_dest_dirs; otherwise, you might want
	# $newer_link_dest_dirs to precede $older_link_dest_dirs
	set-link_dest_opts \
	    $link_dest_fast_dirs $older_link_dest_dirs $newer_link_dest_dirs
	TraceV 5 link_dest_opts
}
readonly -f set-link_dest_opts--for-copy-snapshot

# ----------------------------------------------------------------------------
# misc functions to support run-rsync
# ----------------------------------------------------------------------------

set-excluded_hours() {

	set -- $(
	for hour
	    do	[[ $hour == 0?   ]] && hour=${hour#0} # zero-padded, not octal
		[[ $hour =~ ^0+$ ]] && continue # pruning needs midnight backup
		[[ $hour == *-*  ]] || { echo $hour; continue; }
		[[ $hour != *-*-* ]] || abort "bad $var_name range"
		[[ $hour != 0-* ]] ||abort "$var_name range can't start with 0"
		[[ $hour != *-0 ]] ||abort "$var_name range can't end with 0"
		first=${hour%-*} last=${hour#*-}
		if (( $first <= $last ))
		   then eval "echo {$first..$last}"
		   else eval "echo {$first..23} {1..$last}" # exclude midnight
		fi
	done
	)
	excluded_hours=$*
}
readonly -f set-excluded_hours

# ---------------------------------

function _is-time-to-backup-drive {

	[[ ! $is_cron || $is_regression_test ]] && return 0 # run by a person?

	set -- $(date '+%k %M')
	local -i current_hour=$1 current_minute=${2#0}

	(( $current_hour == 0 && $current_minute == 5 )) &&
	   update-snapshots-ls &&
	   ( cd $log_dir && $our_path w | echo-to-file - cron-w.txt ) &

	# we're called more than hourly (to reset priorities, and to prune)
	(( $current_minute == 0 )) || [[ $debug_opt ]] || return 1

	set-excluded_hours $excluded_backup_hours
	is-arg1-in-arg2 $current_hour $excluded_hours && return 1

	(( $current_hour % $backup_period == 0 )) || return 1

	# FIXME: need to send email if this happens
	is-drive-usage-too-high && (( $highest_drive_usage >= 99 )) && return 1

	return 0
}
readonly -f _is-time-to-backup-drive

# -----------------------------------------------------
# the following functions support _handle-rsync-results
# -----------------------------------------------------

_links-error-msg() {
	local msg=$*

	# since contents of $() are run in subshell, have to echo results
	local -i max_src_links=$(
	local -i max_src_links=0
	bzcat $log | tr -d '"' | cut -d' ' -f3 |
	while read dst_file
	    do	src_file=${dst_file#$drive_dir/$snapshot_glob.partial}
		[[ -f $src_file ]] || continue
		set -- $(ls -l $src_file)
		((   $max_src_links >= $2 )) && continue
		      max_src_links=$2
		echo $max_src_links
	done | tail -n1
	)

	local -i link_dest_wait=$(( num_full_link_dests * backup_period ))
	set -- *.rm
	msg="$msg; Worst case, tried to add $max_src_links links to a snapshot file; these files will eventually appear in a new snapshot after $link_dest_wait hours; $# snapshots waiting to be pruned, newer prunes subtract ~$max_src_links links"

	[[ $hostname != eleanor ]] &&
	msg="$msg; Edit prune variables in $config_file to reduce # snapshots"

	echo "$msg"
}
readonly -f _links-error-msg

# ---------------------------------

_handle-rsync-results() {
	local new_snapshot=$1 status=$2 log=$3

	if [[ -s $log ]]
	   then [[ $IfRun ]] && { bzcat $log; rm $log; }
	   else rm -f $log
	fi

	# uncomment next line to debug link_fail_count code with -d option
	# echo 'link failed: Too many links (31)' | bzip2 >> $log; status=31

	local error_msg=

	if is-arg1-in-arg2 $status "$successful_rsync_exit_statuses"
	   then $IfRun mv $new_snapshot.partial $new_snapshot &&
		[[ $new_snapshot != *.links ]] &&
		set -- $snapshot_glob && [[ $# != 0 ]] &&
		$IfRun rm -f latest && $IfRun ln -s ${!#} latest &&
		update-snapshots-ls
		set-writer_stats_msg--as-save-writer-stats $new_snapshot
		[[ $new_snapshot == *,00 || $log_level -gt 0 ||
		   ! $is_cron || $debug_opt ]] && $IfRun \
		    log "created $(basename $new_snapshot) $writer_stats_msg"
	   else set -- $(bzcat $log 2>$dev_null | # might be empty file
			 grep -c ': Too many links (31) *$')
		local  link_fail_count=$1 # see test, above
		if (( $link_fail_count == 0 ))
		   then local err=$(bzcat $log | tail -n2)
			((  $(echo "$err" | wc -l) > 1 )) &&
			err=$(echo "$err" | sed '1s/.*: //' |
						tr '\n' '|' | sed 's/|/; /')
			error_msg="...; ${err}rsync exit status=$status"
		   else error_msg="$link_fail_count 'Too many links'"
			error_msg=$(_links-error-msg "$error_msg")
			$IfRun mv $new_snapshot.partial $new_snapshot.links
			set-writer_stats_msg--as-save-writer-stats \
			    $new_snapshot
		fi
		if is-arg1-in-arg2 $status "$no_log_rsync_exit_statuses" ||
		   (( $(bzcat $log | wc -l) == 0 ))
		   then rm -f $log
			error_msg="$error_msg; Partial snapshot still useful"
		   else error_msg="$error_msg; See $log"
		fi
	fi

	if [[  $error_msg ]]
	   then	[[ $Trace || $drive_name == [zZ] ]] && # Z = debug "drive"
		log "$error_msg" ||
		log "$error_msg" |& tee -a /dev/stderr | sed 's/; /\n/g' |
		   $IfRun mail -s "$our_name: errors" $sysadmin_email_addresses
	   else rm -f $log
	fi
}
readonly -f _handle-rsync-results

# -------------------------------------------------------

set-partial_dst() {
	local  dst_snapshot=$1

	if [[ $dst_snapshot == *.partial ]]
	   then partial_dst=$dst_snapshot
	   else partial_dst=$dst_snapshot.partial
		# if we (partially) created this snapshot earlier, reuse it
		local suffix
		for   suffix in '' '.links'
		    do	local  useful_dst=$dst_snapshot$suffix
			[[ -d $useful_dst ]] &&
			   $IfRun mv $useful_dst $partial_dst && break
		done
	fi
}
readonly -f set-partial_dst

# -------------------------------------------------------

function _run-rsync-cmd() {

	# drive_dir_prefix and rsync_backup_opts come from $config_file
	local relative_opt= excludes=
	[[ $writer_type != copy ]] &&
	relative_opt=--relative  excludes="--exclude=$drive_dir_prefix*
					   --exclude-from=$exclude_file"
	set -- $partial_dst/*
	if [[ $# != 0 ]]		# snapshot not empty?
	   then local restart_opt=-r
	   else local restart_opt=
	fi
	set-SECONDS-starting_MB--for-save-writer-stats \
	    $restart_opt $partial_dst

	shopt -u nullglob   # nullglob disappears --exclude=$drive_dir_prefix*

	$Trace
	$IfRun rsync $rsync_backup_opts	\
		     $our_rsync_opts	\
		     $relative_opt	\
		     $link_dest_opts	\
		     $excludes		\
			$src_dirs $partial_dst/ |& bzip2 -9 > $log
	local status=${PIPESTATUS[0]}	# https://stackoverflow.com/a/20738063

	shopt -s nullglob

	return $status
}
readonly -f _run-rsync-cmd

# -------------------------------------------------------

function run-rsync() {
	assert-not-option "${1-}"
	local dst_snapshot=${!#}
	local src_dirs=${*#$dst_snapshot}

	local date_time=${dst_snapshot##*/}
	local log=$tmp_dir/$drive_name-${date_time%%.*}.bz2

	assert-drive_dir-writable ${dst_snapshot%/*}

	set-partial_dst $dst_snapshot

	[[ $writer_type != copy ]] &&  # copy keeps original mtime
	{		     # ensure $dst_snapshot has current time
	[[ $debug_opt ]] ||  # use 'sleep 9' to wait for rsync to modify mtime
	for (( n = 0; n < 20; n++ ))
	    do [[ -e $partial_dst || -e $dst_snapshot ]] && break
	       env sleep 9
	done
	[[ -d $partial_dst ]] && $IfRun \
	touch $partial_dst		# in case we crash before next 'touch'
	} &

	suspend-tracing
	if [[ $writer_type != copy ]]
	   then set-link_dest_opts--for-backup-drive  $dst_snapshot
	   else set-link_dest_opts--for-copy-snapshot $dst_snapshot
	fi
	restore-tracing link_dest_opts

	local -i starting_MB=0		# for *-save-writer-stats
	_run-rsync-cmd
	local status=$?

	[[ $writer_type != copy ]] &&
	$IfRun touch $partial_dst	# 'when we finished', not mdate of src

	_handle-rsync-results $dst_snapshot $status $log

	sync-drive-unless-writers $writer_type

	return $status
}
readonly -f run-rsync

# -------------------------------------------------------

function backup-drive-rsync() {
	local date_time=$1

	set-priority backup

	local new_snapshot=$drive_dir/$date_time

	cd_ $drive_dir	# so can safely kill job with: fuser -k -M $drive_dir

	suspend-tracing
	run-rsync $dirs_to_backup $new_snapshot
	restore-tracing			# this preserves $?
}
readonly -f backup-drive-rsync

# ----------------------------

function set-copy_PGID--if-copy-src() {
	local resource=${1:-$drive_name}

	copy_PGID=

	if ! [[ $resource == $lock_dir/* || $resource == *.pid ]]
	   then local lock_path
		set-lock_path prune || return 1
		local prune_lock_path=$lock_path
	   else local prune_lock_path=$lock_dir/${resource#$lock_dir/}
	fi

	local lock_PGID
	  set-lock_PGID $prune_lock_path || return 1
	local prune_lock_PGID=$lock_PGID

	  set-lock_paths copy all
	local lock_path
	for lock_path in $lock_paths
	    do	set-lock_PGID $lock_path
		(( $lock_PGID == $prune_lock_PGID )) || continue
		copy_PGID=$lock_PGID
		return 0
	done

	return 1
}
readonly -f set-copy_PGID--if-copy-src

# ----------------------

function set-prune_lock_path-copy_PGID--for-prune-lock-owned-by-copy() {
	local drive_name=${1:-$drive_name}

	prune_lock_path= copy_PGID=

	local lock_paths
	set-lock_paths copy && set-lock_PGID $lock_paths || return 1
	copy_PGID=$lock_PGID

	  set-lock_paths prune all
	local lock_path
	for lock_path in $lock_paths
	    do	set-lock_PGID $lock_path
		(( $lock_PGID == $copy_PGID )) || continue

		prune_lock_path=$lock_path
		return 0
	done

	copy_PGID=
	return 1
}
readonly -f set-prune_lock_path-copy_PGID--for-prune-lock-owned-by-copy

# ----------------------

function _set-prune_lock_path-copy_PGID--if-release-copy-src-prune-lock() {

	set-prune_lock_path-copy_PGID--for-prune-lock-owned-by-copy ${1-} &&
	    $IfRun sudo rm $prune_lock_path || unset prune_lock_path copy_PGID
}
readonly -f _set-prune_lock_path-copy_PGID--if-release-copy-src-prune-lock

# ----------------------

restore-lock() {
	local lock_path=${1-} lock_PGID=${2-}

	[[ $lock_path ]] || return
	sudo-lockpid --pid=$lock_PGID $lock_path
}
readonly -f restore-lock

# ----------------------

did_prevent_pruning_print_stack=$false

prevent-pruning() {
	local resource=$1

	until lock -P prune $resource > $dev_null
	    do	local status=$?
		kill-job-on-drives prune $resource
		if [[ ! $did_prevent_pruning_print_stack ]]
		   then  did_prevent_pruning_print_stack=$true
			local lock_msg="lock returned $status"
			print-call-stack \
			    "$lock_msg: awaiting $drive_name lock" |
			    tee -a $file_for_logging
		fi
		$IfRun env sleep 1.0
	done
	did_prevent_pruning_print_stack=$false # for future call
}
readonly -f prevent-pruning

# ----------------------

# The locking & job-management policy is documented in front of function lock()

function backup-drive() {
	local drive_name=$1 drive_dir

	set-drive_name $drive_name
	set-drive_dir  $drive_name || return 1

	local date_time
	set-date_time

	if ! _is-time-to-backup-drive	# must call within 1 minute of startup
	   then $IfRun create-jobs prune
		return
	fi
	if [[ $is_multi_writer_drive && $is_cron ]]
	   then $IfRun create-jobs prune
	fi

	# grab backup lock before prune, so don't suspend prune if the sysadmin
	# suspended the backup and continued the prune (is it still relevant?)
	lock -w backup || return 1	# wait for lock, so don't skip backup

	if [[ ! $is_multi_writer_drive ]]
	   then suspend-jobs copy prune
		# if suspended a copy, it's now OK to prune its source drive
		_set-prune_lock_path-copy_PGID--if-release-copy-src-prune-lock
	fi

	# could create LVM snapshot that's specified in $dirs_to_backup, and/or
	# do a database-dump
	${backup_drive_pre_hook-}

	backup-drive-rsync $date_time
	local status=$?

	# could delete source-snapshot that's specified in $dirs_to_backup, or
	# delete a database-dump, or write $date_time & $status to a database
	${backup_drive_post_hook-}

	unlock backup

	if [[ ! $is_multi_writer_drive ]]
	   then # before continue a copy, disable the pruning of its source
		restore-lock ${prune_lock_path-} ${copy_PGID-}
		$IfRun create-jobs prune # also manages (continues) a copy job
	fi

	return $status
}
readonly -f backup-drive

##############################################################################
##############################################################################
# Functions and variables used to copy snapshots between backup drives.
##############################################################################
##############################################################################

is-in-cron-job() {
	local name=$1  drive_name

	set-drive_name $name
	[[ $drive_name =~ ^$drive_name_regex$ ]]
}
readonly -f is-in-cron-job

# ---------------------------------

assert-not-in-cron-jobs() {

	local name
	for name
	    do	is-in-cron-job $name || continue
		local regex=drive_name_regex
		$IfRun abort "remove $drive_name from $regex= in $config_file"
	done
}
readonly -f assert-not-in-cron-jobs

# ----------------------------------------------------------------------------

function bad-copy() {
	local msg=$*

	[[ $is_quiet || $is_update || $debug_opt ]] ||
	   abort "$msg; use -q to not abort"

	[[ ! $debug_opt || $is_update ]] || echo "copy-snapshot: $msg"

	return 1
}
readonly -f bad-copy

# ---------------------------------

declare -A drive_name2backup_type

set-backup_type() {
	local drive_name=$1	  # fastest if it's a drive_name not drive_dir

	backup_type=${drive_name2backup_type[$drive_name]-}
	[[ $backup_type ]] && return	# was it in the cache?

	backup_type=
	local variable_name
	for variable_name in dirs_to_backup exclude_file extra_excludes
	    do	set-customized_value--for-config-var-name $variable_name
		backup_type+="$customized_value|"
	done
	backup_type=${backup_type%|}
	drive_name2backup_type[$drive_name]=$backup_type # cache it
}
readonly -f set-backup_type

# ---------------------------------

function matches-dst_backup_type() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local drive_dir=$1 drive_name

	set-drive_name- $drive_dir
	set-backup_type $drive_name
	$xtrace
	[[ $backup_type == $dst_backup_type || $debug_opt ]]
}
readonly -f matches-dst_backup_type

# ----------------------

function is-src_snapshot-useful() {
	local src_snapshot=$1

	[[ -d $src_snapshot ]] || bad-copy "no snapshot '$1'" || return 1
	local  src_basename=${src_snapshot##*/}
	[[ $src_basename == $snapshot_glob ||
	   $src_basename == $snapshot_glob.links ]] ||
	   bad-copy "$src_snapshot is not a reliable snapshot" || return 1
	[[ $src_basename =~ $dst_minimal_snapshot_regex(|\..*) ]] ||
	   bad-copy "$src_snapshot doesn't fit $dst_drive_name backup_period"||
	   return 1

	matches-dst_backup_type ${src_snapshot%/*} && return 0

       bad-copy "$src_snapshot & $dst_drive_name backup characteristics differ"
}
readonly -f is-src_snapshot-useful

# ---------------------------------

function is-dst_snapshot-needed() {
	local dst_snapshot=$1

	set -- ${dst_snapshot%.*}*	# a version might exist
	[[ $# == 0    ]] && return 0
	[[ $# == 1    ]] ||
	   bad-copy "'$*' exist, (mv then) delete worst one" || return 1
	[[ $1 != *.rm ]] ||
	   bad-copy "destination is waiting to be pruned" || return 1

	local ext=${1##*.} junk_dir=${dst_snapshot%/*}/.junk
	[[ ! -d $1 ]] &&
	   $IfRun mv $1 $junk_dir/ && { warn "junk in $junk_dir"; return 0; }
	! [[ ${1##*/} != *.* || $ext == links || $ext == partial ]] &&
	   $IfRun mv $1 $junk_dir/ && { warn "junk in $junk_dir"; return 0; }

	[[ ${1##*/} != *.* && ${dst_snapshot##*/} == *.* ]] && {
	[[ ! $is_quiet ]] && log "${dst_snapshot##*/} not needed"; return 1; }
	[[ $1 != $dst_snapshot ]] && return 0
	[[ $is_quiet || $action == update* ]] ||
	    log "$dst_snapshot already exists"; return 1
}
readonly -f is-dst_snapshot-needed

# ---------------------------------

function copy-snapshot() {
	[[ $1 == -s* ]] && { local src=${1#-s}   ; shift; } || local src=
	[[ $1 == -q ]] && { local is_quiet=$true ; shift; } || local is_quiet=
	[[ $1 == -u ]] && { local is_update=$true; shift; } || local is_update=
	assert-not-option -o "${1-}"
	[[ $src     ]] && set -- $src $1
	(( $# >= 2  )) || abort-function "src(s) dst_drive_name"
	local src_snapshot=${1%/} dst_drive_name=${!#}
	local src_snapshots=${*#$dst_drive_name}
	src_snapshot=${src_snapshot%/.keep}
	local drive_name=$drive_name drive_dir=${drive_dir-} # protect caller
	copy_snapshot_args=		# holds result when $is_update

	$Trace
	[[ ${dst_minimal_snapshot_regex-} ]] || { # don't repeat dst setup
	set-drive_dir $dst_drive_name || abort "$dst_drive_name not mounted"
	dst_dir=$drive_dir
	local regex=${backup_period2minimal_snapshot_regex[$backup_period]}
	dst_minimal_snapshot_regex=$regex
	set-backup_type $dst_drive_name
	dst_backup_type=$backup_type	   ; }

	[[ $src_snapshot == /* && ! -L $src_snapshot ]] || {
	# the above criteria is alway satisfied by update, so we're 'copy' ...
	local absolute_path
	set-absolute_path $src_snapshot
	src_snapshot=$absolute_path
	src_snapshots=$absolute_path ; } # ... so only a single src

	local dst_snapshot=$dst_dir/${src_snapshot##*/}

	is-dst_snapshot-needed $dst_snapshot || return 1
	is-src_snapshot-useful $src_snapshot || return 1

	TraceV 2 src_snapshot dst_snapshot

	[[ ${debug_copy-} ]] &&
	    echo "copy $src_snapshot/\$dirs to $dst_dir/" && return 0

	[[ $is_update ]] &&
	    copy_snapshot_args="$src_snapshots $dst_snapshot" && return 0

	copy-snapshot-rsync $src_snapshot $dst_snapshot
}
readonly -f copy-snapshot

# -----------------------------------------

function copy-snapshots() {
	local src_snapshots=  src_snapshot
	while [[ $1 == -s* ]]
	   do	src_snapshot=${1#-s}
		src_snapshots+="${src_snapshot%/.keep} "
		shift
	done
	[[ $1 == -B ]] && { local  lock_bkp=$true ; shift; } || local lock_bkp=
	[[ $1 == -q ]] && { local quiet_opt=$1 ; shift; } || local quiet_opt=
	assert-not-option -o "${1-}"
	[[ $src_snapshots && $# == 1 ]] ||
	    abort-function "src_option(s) [-q] dst_drive_name"
	set-drive_name $1

	lock -w copy || exit-normally 1

	[[ $lock_bkp ]] && lock -w backup
	local status=0
	for src_snapshot in $src_snapshots
	    do	copy-snapshot $quiet_opt $src_snapshot $drive_name ||
		    status=$?
	done
	[[ $lock_bkp ]] && unlock backup

	unlock copy
	return $status
}
readonly -f copy-snapshots

# -------------------------------------------------------

# The locking & job-management policy is documented in front of function lock()

# The following is similar to the second half of backup-drive-rsync;
# it's called by copy-snapshot and update-drive, to do the real work.
function copy-snapshot-rsync() {
	local src_snapshot=$1 dst_snapshot=$2

	if [[ ! $is_multi_writer_drive ]]
	   then if [[ ! ${lock_bkp-} ]]
		   then lock -w backup || return 1 # wait for backup ...
			unlock  backup		   # ... but don't hold lock
		fi

		set-copy_PGID--if-copy-src || # 2 drives copying to each other?
		suspend-jobs prune    # cron will swap jobs if drive space low
	fi

	if is-multi-writer-drive   $src_snapshot ||
	   is-drive-usage-too-high $src_snapshot
	   then local did_lock_src_prune=$false
	   else local did_lock_src_prune=$true
		prevent-pruning $src_snapshot
	fi

	set-priority copy

	cd_ ${dst_snapshot%/*}	     # can kill job with: fuser -k -M $dst_dir
	run-rsync $src_snapshot/. $dst_snapshot; local status=$?
	cd_ $OLDPWD
	previously_copied_snapshot=$dst_snapshot

	[[ ! $is_multi_writer_drive ]] &&
	continue-jobs prune

	[[ $did_lock_src_prune ]] && unlock prune $src_snapshot

	return $status
}
readonly -f copy-snapshot-rsync

# ----------------------------------------------------------------------------
# ----------------------------------------------------------------------------
# functions needed for update-drive (wrapper around copy-snapshot)
# ----------------------------------------------------------------------------
# ----------------------------------------------------------------------------

wait-for-full-snapshots() {
	local min_full_snapshots=$1

	while true
	   do	suspend-tracing
		set -- $drive_dir/$snapshot_glob
		restore-tracing
		(( $# > $min_full_snapshots )) && return # an extra one: safety
		env sleep 1h
	done
}
readonly -f wait-for-full-snapshots

# ----------------------------------------------------------------------------

function set-srcs_dst_file() {

	# this is not deleted, so can be inspected
	srcs_dst_file=$tmp_dir/$our_name_-update-$drive_name$debug_opt.args
	[[ -s $srcs_dst_file ]]
}
readonly -f set-srcs_dst_file

# ----------------------------------------------------------------------------

set-excluded_drive_dirs_regex() {

	if [[ $debug_opt && ${flakey_drive_names_regex-} ]]
	   then excluded_drive_dirs_regex=$flakey_drive_names_regex
	   else excluded_drive_dirs_regex=NoThInG
	fi
}
readonly -f set-excluded_drive_dirs_regex

# ----------------------------------------------------------------------------

# ---------------------------------
# functions for src_dirs-for-update
# ---------------------------------

set-regex--from-glob() {
	local glob=$1

	set-glob "$glob"
	[[ $glob != *..* ]] || abort-function "can't handle '..'"

	glob=${glob//\*/.*}
	glob=${glob//\?/.}
	glob=${glob//\{/(}
	glob=${glob//\}/)}
	glob=${glob//\,/|}

	regex=$glob
}
readonly -f set-regex--from-glob

# ----------------------

_set-src_names_regex() {

	[[ ${src_names_glob-} ]] || { src_names_regex=. ; return ; }

	local name_glob regex
	set-name_glob "$src_names_glob"
	set-regex--from-glob "$name_glob"
	src_names_regex=$regex
}
readonly -f _set-src_names_regex

# --------------------------------

_set-drive_dirs--for-update-srcs() {
	local drive_name=${1:-$drive_name}
	set-drive_dir-

	set-excluded_drive_dirs_regex
	_set-src_names_regex

	set-backup_type $drive_name
	dst_backup_type=$backup_type

	drive_dirs=
	local src_drive_dir
	for src_drive_dir in $(list-drive-dirs -a)
	    do	[[ $src_drive_dir != $drive_dir ]] || continue

		local exclude_regex=$drive_dir_prefix$excluded_drive_dirs_regex
		[[ $src_drive_dir =~ $exclude_regex ]] && continue

		local include_regex=$drive_dir_prefix$src_names_regex$
		[[ $src_drive_dir =~ $include_regex ]] || continue

		matches-dst_backup_type $src_drive_dir &&
		   drive_dirs+="$src_drive_dir "
	done
	drive_dirs=${drive_dirs% }
	[[ $drive_dirs ]]
}
readonly -f _set-drive_dirs--for-update-srcs

# --------------------------------

src_dirs-for-update() {

	_set-drive_dirs--for-update-srcs ||
	   abort "couldn't find any drives to copy to $drive_name"

	local period=$backup_period
	local min_snapshot_glob=${backup_period2minimal_snapshot_glob[$period]}
	[[ $min_snapshot_glob ]] ||
	    abort "backup_period2minimal_snapshot_glob is broken"

	TraceV 1 drive_dirs min_snapshot_glob sort_key_args

	local dir
	for dir in $drive_dirs
	    do	suspend-tracing
		eval "echo $dir/$min_snapshot_glob{,.links}"   # useful ones
		eval "echo $dir/$snapshot_glob{,.links}/.keep" # never pruned
		restore-tracing
	done | tr ' ' '\n'
}
readonly -f src_dirs-for-update

# ----------------------------------------------------------------------------

declare -A basename2dirs basename2is_keep

# this is a group-by: group snapshots on different drives by snapshot basename
set-basename2dirs-basename2is_keep() {
	local dirs_generator=${1:-src_dirs-for-update}

	local name_glob
	set-name_glob "${excluded_src_names_glob-}"
	local excluded_names_glob=$name_glob

	local dir basename
	while read dir
	   do	basename=${dir%/.keep}
		basename=${basename##*/}

		[[ $excluded_names_glob ]] &&
		   set -- $drive_dir_prefix$excluded_names_glob/$basename &&
		   [[ $# != 0 && -d $1 ]] && continue

		if [[ $dir == */.keep ]]
		   then basename2is_keep[$basename]=$true
			is-arg1-in-arg2  $dir \
			 ${basename2dirs[$basename]-} && continue # duplicate?
		fi
		[[ -d $dir ]] || continue
		basename2dirs[$basename]+="$dir "
	done <<<$($dirs_generator)
}
readonly -f set-basename2dirs-basename2is_keep

# ----------------------------------------------------------------------------

mkdir-missing-snapshots-then-print-copy-args() {

	if [[ $UID == 0 ]]
	   then local sudo=
	   else local sudo=sudo-unless-dir-writable
	fi

	set-basename2dirs-basename2is_keep
	# sort basenames for regression-test
	set -- $(echo ${!basename2dirs[*]} | tr ' ' '\n' | sort)

	local snapshot basename
	for snapshot
	    do	local src_snapshots=${basename2dirs[$snapshot]}
		copy-snapshot -u $src_snapshots $drive_name # loads a var
		set -- $copy_snapshot_args   # variable set by copy-snapshot
		[[ $# != 0 ]] || continue    # src might not have been needed
		local	   dst_snapshot=${!#} # last arg is destination
		basename=${dst_snapshot##*/}
		[[ -d $dst_snapshot.links ]] && continue # have upgradable dst?

		# create a .partial dir for pruning (unless it has a /.keep).
		# use env to avoid 'mkdir' builtin (which doesn't handle -v)
		$sudo env mkdir $verbose_opt -p $dst_snapshot.partial >&2
		[[ ${basename2is_keep[$basename]-} ]] &&
		    echo > $dst_snapshot.partial/.keep && [[ $verbose_opt ]] &&
		echo touch $dst_snapshot.partial/.keep >&2
		echo "$@"		# the args for future copy-snapshot
	done
}
readonly -f mkdir-missing-snapshots-then-print-copy-args

# ----------------------------------------------------------------------------

function _set-speed_record() {
	local snapshot=$1   drive_name drive_dir

	set-drive_name- $snapshot

	speed_record=${drive_name2speed_record[$drive_name]-}
	[[ $speed_record ]] && return 0

	set-drive_dir- || { print-call-stack; return 1; }

	if is-multi-writer-drive $snapshot
	   then local not_multi_writer=0
	   else local not_multi_writer=1
	fi

	local -i writer_count=0
	have-job backup &&			      writer_count+=1
	have-job copy	&& ! is-sleeping copy && ! is-suspended copy &&
						      writer_count+=1
	have-job prune	&& is-drive-usage-too-high && writer_count+=1

	count-rsyncs-using-resource " $drive_dir/"
	local rsync_count=$?

	# this must match _set-not_multi_writer-writer_count-rsync_count()
	speed_record="$not_multi_writer|$writer_count|$rsync_count|$snapshot"
}
readonly -f _set-speed_record

# ----------------------

_set-not_multi_writer-writer_count-rsync_count() {
	local speed_record=$1

	set -- ${speed_record//|/ }
	not_multi_writer=$1 writer_count=$2 rsync_count=$3
}
readonly -f _set-not_multi_writer-writer_count-rsync_count

# ---------------------------------

# the "fastest" snapshot is on drive that's: 1. multi-writer; else 2. not
# running a backup or copy; else 3. not being pruned (or can kill prune);
# else 4. hosting the smallest number of rsync commands.
# but, we'll skip a drive that's not mulit-writer && hosts write jobs, which
# means we might not return anything (so caller has to do multiple passes, to
# wait for a source drive to become "available")
fastest-snapshots() {
	if [[ $1 == -f ]]
	   then local do_force=$true; shift
	elif [[ $is_regression_test ]]
	   then local do_force=$true
	   else local do_force=$false
	fi

	local snapshot not_multi_writer writer_count rsync_count
	for snapshot
	    do	_set-speed_record $snapshot || continue
		_set-not_multi_writer-writer_count-rsync_count $speed_record

		[[ ! $do_force ]] &&
		[[ $writer_count -gt 0 && $not_multi_writer == 1 ]] &&
		    continue			# prefer a better snapshot?

		[[ ( $writer_count -gt 0 || $rsync_count -gt 0 ) &&
		   $ignore_slow_sources && ! $do_force ]] && continue

		echo "$speed_record"
	done | sort -t\| -n |		# numeric sort
	# cat; return			# uncomment to debug with action 'test'
	cut -d\| -f4
}
readonly -f fastest-snapshots

# -------------------------------------------------------

function fill-in-unpruned-empty-snapshots() {
	local copy_args_file=$1

	local status=1			# assume we did no work

	local skipped_copy_args_file=$tmp_5
	local force_opt= # to force one copy per pass (if all sources are busy)
	while true
	    do	local args dst_snapshot=
		local did_skip_a_snapshot=$false
		while read args
		    do	[[ $args ]] || abort "blank line in $srcs_dst_file"
			set -- $args
			local   src_snapshot_1=$1
			local   dst_snapshot=${!#}
			[[ -d  $dst_snapshot ]] && continue #undeleted or done?
			set -- $dst_snapshot*
			[[ $# != 0 ]] || continue # was it pruned away?
			# desired snapshot could be newly created, or pruned...
			set -- $drive_dir_prefix*/${src_snapshot_1##*/}
			[[ $# != 0 ]] || continue # sources pruned away?

			is-set     drive_name2speed_record ||
			declare -A drive_name2speed_record
			set -- $(fastest-snapshots $force_opt $*)
			if [[ $# != 0 ]]
			   then copy-snapshot-rsync $1 $dst_snapshot >&2
				status=0 # we did some work
				[[ ! $debug_opt ]] &&
				# copy-* took a long time, recheck drive speeds
				unset drive_name2speed_record # force a rebuild
				force_opt= # do 1 force per pass
			   else did_skip_a_snapshot=$true
				echo $args # save for next pass
			fi
		done < $copy_args_file > $skipped_copy_args_file
		[[ ! $did_skip_a_snapshot ]] && break # did we do all the work?
		$IfRun cp $skipped_copy_args_file $copy_args_file # less work
		[[   $force_opt || $ignore_slow_sources ]] ||
		    { force_opt=-f; continue; }
		[[ ! $debug_opt ]] || warn "no work to do" || break
		env sleep 5m		# wait for source(s) to become unbusy
	done
	$IfRun rm $copy_args_file $skipped_copy_args_file |
	    sed 's/-[0-9]*$/-PID/'
	return $status
}
readonly -f fill-in-unpruned-empty-snapshots

# ----------------------------------------------------------------------------

declare is_update=$false

function update-drive() {
	local update_drive_args=$*	# for recursion
	local ignore_slow_sources=$false are_recursing=$false
	[[ $1 == -r  ]] && { 	    are_recursing=$true; shift; }
	[[ $1 == -S  ]] && {  ignore_slow_sources=$true; shift; }
	[[ $1 == -s* ]] && { local          src_names_glob=${1#-?}; shift; }
	[[ $1 == -e* ]] && { local excluded_src_names_glob=${1#-?}; shift; }
	[[ $1 == -f  ]] && { local do_force=$true; shift; } || local do_force=
	assert-not-option $1

	is_update=$true
	set-drive_name $1
	set-drive_dir $drive_name
	cd $drive_dir || abort-function cd

	# need to grab the copy lock in debug mode, pruning runs mv & rmdir
	[[ $is_cron ]] && local lock_opt= || local lock_opt=-w
	[[ $are_recursing ]] ||
	IfRun= lock $lock_opt copy > $dev_null || exit-normally 1
	[[ $is_cron ]] || reset-priority # this might suspend us

	rmdir *.partial &> $dev_null	# in case crashed

	# make sure that we're not using partially-created snapshots
	# in rsync's --link-dest options
	set-num_full_link_dests
	[[ $do_force ]] || ! is-in-cron-job $drive_name ||
	    $IfRun wait-for-full-snapshots $num_full_link_dests

	set-srcs_dst_file
	mkdir-missing-snapshots-then-print-copy-args > $srcs_dst_file

	prune-drive $drive_name

	fill-in-unpruned-empty-snapshots $srcs_dst_file
	local status=$?
	[[ $status == 0 ]] &&	  # did we do actually do some copying (slow)?
	$IfRun update-drive -r ${update_drive_args#-r} # see if new snapshots

	rmdir *.partial &> $dev_null

	IfRun= unlock copy
	return $status
}
readonly -f update-drive

##############################################################################
##############################################################################
# Run multiple jobs, each in a separate session (unique PGID, stored in lock).
##############################################################################
##############################################################################

do-chores() {

	check-logs			# create data for 'watch'
	rm-dangling-stats-symlinks
	rm-stale-locks			# do before ...
	re-start-monitor-drives-if-needed
	# log "$FUNCNAME finished"	# for debugging
}
readonly -f do-chores

# ----------------------------------------------------------------------------

function set-drive_dirs--from-user-args() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	[[ ${1-} == -[aA] ]] && { local all_opt=$1; shift; } || local all_opt=

	if [[ $# == 0 || ${1,,} == all || $1 == '*' ]]
	   then set-drive_dirs $all_opt
		$xtrace
		return $?
	fi

	[[ $1 != /* ]] && set-glob "$@" && eval "set -- $drive_dir_prefix$glob"

	drive_dirs=
	for drive_dir
	    do	set-drive_name- -q $drive_dir  &&
		set-drive_dir-     $drive_name || continue
		[[ $drive_name != [zZ] || $is_regression_test ]] || continue
		is-drive-mounted   $drive_dir  &&
		      drive_dirs+="$drive_dir "
	done
	drive_dirs=${drive_dirs% }
	$xtrace
	[[ $drive_dirs ]]
}
readonly -f set-drive_dirs--from-user-args

# ---------------------------------

function set-drive_names--from-user-args() {
	 set-drive_dirs--from-user-args "$@" || return $?

	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	drive_names=
	local drive_dir drive_name
	for drive_dir in $drive_dirs
	    do	set-drive_name- $drive_dir
		  drive_names+="$drive_name "
	done
	drive_names=${drive_names% }
	$xtrace
	[[ $drive_names ]]
}
readonly -f set-drive_names--from-user-args

# ---------------------------------

_set-function-our_exe-writer_type() {
	local type=$1

	# *_exe variables include options to snapback (e.g. -d and -t)
	case $type in
	   ( backup ) function=backup-drive	writer_type=backup  ;;
	   ( prune  ) function=prune-drive	writer_type=prune   ;;
	   ( update ) function=update-drive	writer_type=copy    ;;
	   ( copy   ) function=copy-snapshots	writer_type=copy    ;;
	   (   *    ) abort-function "action '$type' is not supported" ;;
	esac
	local our_exe_varname=${function/-/_}_exe
	our_exe=${!our_exe_varname}
}
readonly -f _set-function-our_exe-writer_type

# ---------------------------------

# The locking & job-management policy is documented in front of function lock()

# Create a unique job on each specified drive (default $drive_name).
# Each job has its own session: lock files will hold PGID (process-group ID),
# making 'kill'/'suspend' and 'ps' and 'watch' (dashboard) easy to manage.
# We run backups simultaneously, so they all share the cached source files;
# we run prunes  simultaneously, since a prune's I/O stays on its own drive;
# we run copy's  simultaneously, cuz uses fastest-snapshots to find idle src.
# See action update-drives for the weird dance we perform when passed options;
# see action copy-snapshots for handling an arbitrary number of source args.
create-jobs() {
	local type=$1; shift
	local opts= are_recursing=$false
	while [[ ${1-} == -[^r]* ]] ; do opts+="$1 "; shift; done
	[[ ${1-} == -r ]] && { are_recursing=$true; shift; }

	[[ $action == $type* ]] && local do_warn=$true || local do_warn=$false

	if [[ $# == 0 ]]
	   then set -- ${drive_name-}
	elif [[ $1 == all || $1 == '*' ]]
	   then set-excluded_drive_dirs_regex
		set -- $(list-drive-dirs |
			     egrep -v "\b$excluded_drive_dirs_regex$")
		if [[ $is_cron && $type == backup ]]
		   then $IfRun do-chores & # echo appears whenever, unless ...
			[[ $is_regression_test ]] && env sleep 0.05 # ... wait
		fi
	   else # shellcheck disable=SC1075
		if set-drive_names--from-user-args "$@"
		   then set -- $drive_names
		elif [[ $* != [zZ] ]]
		   then abort "no valid drive names specified: $*"
		fi
	fi
	if [[ $# == 0 ]]
	   then if [[ $is_cron ]]
		   then [[ $type == backup ]] && do-chores
			exit-normally 0
		fi
		abort-function "$type: pass a (non-excluded) drive name"
	fi

	[[ ! $debug_opt ]] && set-reversed_words $* &&
	   set -- $reversed_words	# 'ps' shows newest process first

	local function our_exe writer_type # backup creates prune job
	 _set-function-our_exe-writer_type $type

	if [[ $are_recursing ]]
	   then $Trace
		$function $opts $1
		exit-normally $?
	fi

	[[ $UID == 0 || $* == [zZ] ]] || $IfRun abort "run with sudo"

	[[ ! $debug_opt && $* != [Zz] && -t 1 && $do_warn ]] && echo -e "
	NOTE: your $action command will run as a separate, disconnected job;
	      and it might wait for a lock before it can start.  See it with:

		$our_name_ watch
"
	$Trace
	for name
	    do	# [[ $name == *[aA] ]] && set -x	   # uncomment to debug
		set-drive_name- $name &&  name=$drive_name # cleanup for 'ps'
		if [[  ! $debug_opt   && $name != [zZ] ]]
		   then trap '' HUP
			# Want new process-group so can ps/kill independently.
			setsid \
			$our_exe $opts -r $name &
		   else $our_exe $opts -r $name # run in foreground for testing
			echo
		fi
		set +x			# uncomment to just debug one drive
	done
}
readonly -f create-jobs

##############################################################################
##############################################################################
# Functions used by 'watch' action.
##############################################################################
##############################################################################

# If change this value, adjust the width of the -* suffix on
# max_drive_usage_percent's value in is-drive-usage-too-high() .
readonly watch_field_width=5+1		# +1 for 'unit' suffix

# this is used by set-padded_colorized_string--for-printf in libsnap.sh
readonly default_padded_colorized_string_field_width=$watch_field_width

set-stats_format() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local drive_names=$*

	[[ ${stats_format-} ]] && { $xtrace; return; }

	local -i format_width
	local -i field_width=$watch_field_width
	local format=
	local drive_name
	for drive_name in $drive_names
	    do	format_width=${#drive_name}+1+$field_width # +1 for '='
		format+="%-${format_width}s  "
	done
	stats_format=${format%  }
	TraceV 1 stats_format
	$xtrace
}
readonly -f set-stats_format

# ----------------------------------------------------------------------------

have-cmd \
set-units ||			   # can define custom version in $config_file
set-units() {			   # a stylistic function
	local letter=$1

	set-warning_string stale $letter
	units=$warning_string		# doesn't work, confuses printf
	units=${letter,}		# lower-cased looks the best
	case $units in
	   ( g ) : units=${units^} ;;	# didn't like it
	esac
}

# ----------------------------------------------------------------------------

# dashboard's decimal numbers should have a 2-digit integeral, otherwise 0-pad
set-padded_number() {
	local number=${1-}

	if [[ $number == ?.* ]]
	   then padded_number=0$number
	   else padded_number=$number
	fi
	[[ $padded_number ]]
}
readonly -f set-padded_number

# ----------------------------------------------------------------------------

function set-count-average-maximum-sum-files--from-stats-files() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local data_type=$1

	local caller_PWD=$PWD
	cd_ $drives_log_dir/$drive_name
	local stats_subdir
	set-stats_subdir $data_type && cd_ $stats_subdir &&
	    set -- $snapshot_glob.txt || set --
	files=$*

	local  cache_type=${stats_subdir#stats/}
	local  cache_dir=$watch_cache_dir/stats-dir/$drive_name
	[[ -d $cache_dir ]] || mkdir -p $cache_dir || abort mkdir $cache_dir
	local  cache_file=$cache_dir/${cache_type//\//_}.sh
	[[ -s $cache_file && $cache_file -nt . ]] && source $cache_file &&
	    local do_compute=$false || local do_compute=$true
	#[[ $do_compute ]] || echo -n "C: " # uncomment to ensure caching works

	while [[ $do_compute ]]; do	# we can use 'break' to do cleanup

	[[ $# != 0 ]] || { count=0 average=0 maximum=0 sum=0; break; }

	if [[ ${writer_type-} == prune && ${data_type-} == MB ]]
	   then local is_negative=$true
	   else local is_negative=$false
	fi
	count=0  maximum=-1123456789  sum=0
	local file
	for file
	    do	local file_contents=$(< $file)
		[[ $file_contents == [-0-9]* ]] || continue
		local -i number=$file_contents

		if [[ $is_negative && $number != 0 ]]
		   then (( $number < 0 )) ||
			    abort "$PWD/$file: pruned MB=$number"
			number=-$number	# make it positive, so fits in field
		fi
		sum+=$number
		count+=1
		(( maximum<number )) &&
		   maximum=number
	done

	(( $count > 0 )) || { average=0  maximum=0; break; }
	average=$(( ( $sum + ($count/2) ) / $count ))

	break
	done

	[[ $do_compute ]] &&
	local data="count=$count average=$average maximum=$maximum sum=$sum" &&
	echo-to-file "$data" $cache_file

	cd $caller_PWD
	TraceV 2 count average maximum sum
	$xtrace
	[[ $files ]]
}
readonly -f set-count-average-maximum-sum-files--from-stats-files

# ---------------------------------

set-hour_avg-hour_max--from-files-of-minutes() {
	local writer_type=${1:-$writer_type}

	local -i \
	    count average maximum sum
	set-count-average-maximum-sum-files--from-stats-files minutes ||
	    { hour_avg= hour_max= ; return; }
	set-units h

	set-hours--from-minutes -2 $average # 2 decimal points
	set-padded_number $hours
	hour_avg=$padded_number$units

	set-hours--from-minutes -2 $maximum
	set-padded_number $hours
	hour_max=$padded_number$units

	[[ $writer_type == backup ]] || return

	# drv_name2backup_period_for_update -> localize period
	set-customized_value--for-config-var-name backup_period &&
	local -i backup_period=$customized_value
	local -i backup_period_mins=$backup_period*60
	if (( average >= backup_period_mins ))
	   then if (( average == backup_period_mins ))
		   then local type=warning
		   else local type=error
		fi
		set-warning_string $type $hour_avg
		set-padded_colorized_string--for-printf \
		    $hour_avg $warning_string
		hour_avg=$padded_colorized_string
	fi
}
readonly -f set-hour_avg-hour_max--from-files-of-minutes

# --------------------------------------------

set-writer_hour_avgs-writer_hour_maxs() {
	local writer_type=$1

	local drive_name hour_avgs= hour_maxs=
	for drive_name in $all_drive_names
	    do	local \
		    hour_avg hour_max
		set-hour_avg-hour_max--from-files-of-minutes
		hour_avgs+="$drive_name=$hour_avg "
		hour_maxs+="$drive_name=$hour_max "
	done

	printf -v writer_hour_avgs "$stats_format" $hour_avgs
	printf -v writer_hour_maxs "$stats_format" $hour_maxs
	fix-padded-colorized-string-vars writer_hour_avgs
	strip-trailing-whitespace writer_hour_avgs writer_hour_maxs
}
readonly -f set-writer_hour_avgs-writer_hour_maxs

# ----------------------------------------------------------------------------

set-percent_usage() {
	local -i MB=$1

	local drive_dir division
	set-drive_dir-
	local -i used_MB size_MB
	set-used_MB-size_MB
	local -i  MB_100=MB*100
	set-division -2 $MB_100 $size_MB
	[[ $division == -0.00 ]] && division=${division#-}
	percent_usage=$division%
}
readonly -f set-percent_usage

# ---------------------------------

set-GB_avg-predicted_TB_sum-predicted_percent_usage() {

	local -i \
	    count average maximum sum
	set-count-average-maximum-sum-files--from-stats-files MB
	(( $count > 0 )) ||
	    { GB_avg= predicted_TB_sum= predicted_percent_usage= ; return; }

	set-units g
	set-division -2 $average 1024 # 2 decimal points
	set-padded_number $division
	GB_avg=$padded_number$units

	if [[ $writer_type != backup ]]
	   then local -i stats_number=${drive_name2stats_number[$drive_name]}
		if (( $stats_number > 0 && $average != 0 ))
		   then set-units t
			local -i predicted_sum=$average*$stats_number
			set-division -2 $predicted_sum $((1024*1024))
			set-padded_number $division
			predicted_TB_sum=$padded_number$units

			set-percent_usage $predicted_sum
			predicted_percent_usage=$percent_usage
		   else predicted_percent_usage= predicted_TB_sum=
		fi
	fi
	TraceV 1 count average sum \
	        GB_avg predicted_TB_sum predicted_percent_usage
}
readonly -f set-GB_avg-predicted_TB_sum-predicted_percent_usage

# --------------------------------------------

function set-jobs_per_day-writer_GBs_per_day-percent_usages_per_day() {
	local writer_type=$1

	jobs_per_day= GBs_per_day= percents_per_day=
	local drive_name padded_number division percent_usage
	for drive_name in $all_drive_names
	    do	local -i MB_per_day=0  unique_hours=0 \
		       count average maximum sum
		if set-count-average-maximum-sum-files--from-stats-files MB
		   then local snapshots=${files//.txt/}

			local hours=${snapshots//$snapshot_day_glob,/}
			set-uniques $hours
			set -- $uniques
			local unique_hours=$#

			local days=${snapshots//,??/}
			set-uniques $days
			set -- $uniques
			local -i day_count=$#

		        local snap_1=${snapshots%% *}
			(( $unique_hours > 1 )) &&
			# we usually get a few jobs before and after whole days
			[[ $snap_1 != *,00 || $# -gt $days_to_keep_stats ]] &&
			day_count=$day_count-1
			set -- $snapshots
			local  file_count=$#
			if [[ $file_count == $count ]]
			   then MB_per_day=$sum/$day_count
			   else # some MB values unknown, have to estimate
			        MB_per_day=$average*$unique_hours
			fi
		fi

		jobs_per_day+="$drive_name=$unique_hours "

		set-units g
		if (( $MB_per_day > 0 ))
		   then set-division -2 $MB_per_day 1024
			set-padded_number $division$units
		   else padded_number=
		fi
		GBs_per_day+="$drive_name=$padded_number "

		if (( $MB_per_day > 0 ))
		   then set-percent_usage $MB_per_day
			set-padded_number $percent_usage
		   else padded_number=
		fi
		percents_per_day+="$drive_name=$padded_number "
		TraceV 1 unique_hours sum day_count MB_per_day percent_usage
	done

	printf -v           jobs_per_day "$stats_format"     $jobs_per_day
	printf -v     writer_GBs_per_day "$stats_format"      $GBs_per_day
	printf -v percent_usages_per_day "$stats_format" $percents_per_day
	strip-trailing-whitespace \
	    jobs_per_day     writer_GBs_per_day percent_usages_per_day
	[[ $jobs_per_day == *=[1-9]* ]]
}
readonly -f set-jobs_per_day-writer_GBs_per_day-percent_usages_per_day

# ------------------------------------------------------------------

set-writer_GB_avgs-predicted_TB_sums-predicted_percent_usages() {
	local writer_type=$1

	local GB_avgs= predicted_TBs= predicted_percents=
	local drive_name padded_number
	for drive_name in $all_drive_names
	    do	local \
		    GB_avg predicted_TB_sum predicted_percent_usage
		set-GB_avg-predicted_TB_sum-predicted_percent_usage

		set-padded_number $GB_avg
		GB_avgs+="$drive_name=$padded_number "

		[[ $writer_type != backup ]] || continue

		set-padded_number $predicted_TB_sum
		predicted_TBs+="$drive_name=$padded_number "

		set-padded_number $predicted_percent_usage
		predicted_percents+="$drive_name=$padded_number "
	done

	printf -v writer_GB_avgs           "$stats_format" $GB_avgs
	printf -v predicted_TB_sums        "$stats_format" $predicted_TBs
	printf -v predicted_percent_usages "$stats_format" $predicted_percents
	strip-trailing-whitespace \
	    writer_GB_avgs     predicted_TB_sums predicted_percent_usages
	[[ $writer_GB_avgs == *=[-0-9]* ]]
}
readonly -f set-writer_GB_avgs-predicted_TB_sums-predicted_percent_usages

# ----------------------------------------------------------------------------

set-drive_usages() {

	local max_drive_usage_percent warning_string
	for drive_dir in $all_drive_dirs
	    do	# is-drive-usage-too-high sets max_drive_usage_percent
		is-drive-usage-too-high && local warn=$true || local warn=
		local     type=${max_drive_usage_percent#*-}    _type
		local  percent=${max_drive_usage_percent%-*}
		((  ${#percent} ==   1 )) && percent=0$percent
		if [[ $percent  == 100 && $watch_opt ]]
		   then set-warning_string error FULL!
			percent=$warning_string
		elif [[ $warn && $watch_opt ]]
		   then [[ $percent == 99 ]] && _type=error || _type=warning
			set-warning_string $_type $percent%$type
			percent=$warning_string
		   else percent=$percent%$type
		fi
		set-drive_name- $drive_dir
		percents+="$drive_name=$percent "
	done
	printf -v drive_usages "$stats_format" $percents
	fix-padded-colorized-string-vars drive_usages # we're done with printf
	strip-trailing-whitespace drive_usages
}
readonly -f set-drive_usages

# ----------------------------------------------------------------------------

is-set   drive_response_warning_secs || # custom value in $config_file?
readonly drive_response_warning_secs=1.0

set-drive_responses() {

	set-units s
	local overhead_msecs_file=$drive_msecs_dir/$mon_overhead_drive_name
	if [[ -s $overhead_msecs_file ]]
	   then local -i average
		set-average $overhead_msecs_file
		local -i overhead_msecs=$average
	   else local -i overhead_msecs=0  average
	fi

	set-msecs--from-secs $drive_response_warning_secs
	local drive_response_warning_msecs=$msecs

	local drive_name secs padded_number responses=
	for drive_name in $all_drive_names
	    do	set-average $drive_msecs_dir/$drive_name
		local -i msecs=$average-$overhead_msecs
		(( $msecs < 0 )) && msecs=0

		if (( $msecs <= 99999 )) # fits in alloted format?
		   then set-secs--from-msecs $msecs
			set-padded_number $secs
			local secs=$padded_number$units
			if (( $msecs >= $drive_response_warning_msecs ))
			   then set-warning_string warning $secs
				secs=$warning_string
			fi
		   else set-warning_string error HUNG!
			local secs=$warning_string
		fi
		responses+="$drive_name=$secs "
	done
	printf -v drive_responses "$stats_format" $responses
	strip-trailing-whitespace drive_responses
}
readonly -f set-drive_responses

# ----------------------------------------------------------------------------

function count-snapshots-being-created-on-drive() {
	local drive_name=${1:-$drive_name}

	local -i count=0

	local lock_paths
	set-lock_paths backup,copy
	set -- $lock_paths
	[[ $# == 2 ]] && (( $(< $1) == $(< $2) )) && shift # duplicate PID?

	# count snapshots we're creating
	local path
	for path
	    do	is-active-lock $path && count+=1
	done

	return $count
}
readonly -f count-snapshots-being-created-on-drive

# --------------------------------------------

_set-age() {
	local snapshot=$1

	if [[ ${hour_ages-} ]]
	   then local -i denominator=60*60    # seconds/hour
	   else local -i denominator=60*60*24 # seconds/day
	fi
	set-seconds--from-snapshot $snapshot
	age=$(( ( $SECONDS - $seconds + ($denominator/2) ) / $denominator ))
}
readonly -f _set-age

# ------------------

set-oldest_age-newest_age() {

	_set-age $1    ; oldest_age=$age
	_set-age ${!#} ; newest_age=$age
}
readonly -f set-oldest_age-newest_age

# ---------------------------------

_set-colorized_new() {
	local new=${1-}

	set-customized_value--for-config-var-name backup_period
	local -i max_age=2*$customized_value
	local warning_string=
	if [[ ! $new ]]
	   then set-warning_string error NONE!
	elif (( ${new%[a-zA-Z]} < $max_age ))
	   then true
	   else set-warning_string warning $new
	fi

	if [[ $warning_string ]]
	   then set-padded_colorized_string--for-printf $new $warning_string
		warning_string=$padded_colorized_string
	fi
	colorized_new=${warning_string:-$new}
}
readonly -f _set-colorized_new

# ----------------------

_recalculate-snapshot-stats-vars() {

	[[ ${hour_ages-} ]] && local units=H || local units=D
	set-units $units
	lock-replica-of-snapshots --wait # wait for $snapshots_replica_dir
	local drive_name nums= oldies= newies=
	for drive_name in $all_drive_names
	    do	local dir=$snapshots_replica_dir/$drive_name
		cd_  $dir
		ending=${type2date_suffix_glob[$ignored_date_ending_type]}
		suspend-tracing
		set -- $snapshot_glob$suffix
		restore-tracing

		[[ $# != 0 ]] && {
		local  partials_file=$non_empty_partial_dir/$drive_name
		[[ -s $partials_file ]] &&
		    local partials=$(< $partials_file) || local partials=
		local snapshot snap prev_snap= snaps=
		for snapshot in $*
		    do	if [[ $skip_empty || $only_empty ]]
			   then is-arg1-in-arg2 $snapshot $partials &&
				   local is_empty=$false ||local is_empty=$true
				[[ $skip_empty &&   $is_empty ]] && continue
				[[ $only_empty && ! $is_empty ]] && continue
			fi
			local snap=${snapshot%$ending$suffix}
			[[ $prev_snap != $snap ]] && snaps+="$snap "
			    prev_snap=$snap
			[[ $skip_empty || $only_empty ]] || suspend-tracing
		done
		set -- $snaps
		}
		restore-tracing

		if [[ $skip_empty ]]	# counting old & unfinished snapshots?
		   then count-snapshots-being-created-on-drive
			shift $? &> $dev_null # forget ones we're creating
		fi

		nums+="$drive_name=$# "

		[[ $dates ]] || continue
		if [[ $# != 0 ]]
		   then set-oldest_age-newest_age $*
			local old=$oldest_age	new=$newest_age$units
			(( ${#old} < $watch_field_width )) &&
			      old+=$units
		   else local old=		new=
		fi
		if [[ ! $suffix && $watch_opt ]] # checking complete snapshots?
		   then _set-colorized_new $new	 # warn if newest not today
			new=$colorized_new
		fi
		oldies+="$drive_name=$old "
		newies+="$drive_name=$new "
	done
	cd $OLDPWD || abort "cd $OLDPWD"
	lock-replica-of-snapshots --release

	printf -v stats_numbers     "$stats_format" $nums   ; [[ $dates ]] && {
	printf -v stats_oldest_ages "$stats_format" $oldies
	printf -v stats_newest_ages "$stats_format" $newies		    ; }
	local vars="stats_numbers stats_oldest_ages stats_newest_ages"
	fix-padded-colorized-string-vars $vars # we're done with printf
	strip-trailing-whitespace $vars
}
readonly -f _recalculate-snapshot-stats-vars

# ----------------------

readonly watch_cache_dir=$stats_dir/watch
readonly cached_drive_names_file=$watch_cache_dir/drive-names.txt

function _is-stats-cache-fresh {
	local cache_file=$1

	[[ -s $cache_file ]] || return 1

	if [[ $drive_names != "$(< $cached_drive_names_file)" ]]
	   then rm -f $cached_drive_names_file $watch_cache_dir/*/*,*.txt
		return 1
	fi

	local drive_name
	for drive_name in $all_drive_names
	    do	local replica_dir=$snapshots_replica_dir/$drive_name
		[[ $cache_file -nt $replica_dir/. ]] || return 1
	done

	return 0
}
readonly -f _is-stats-cache-fresh

# ----------------------

function setup-snapshot-stats() {
	[[ $1 == -? ]] && local option=$1 || local option=
	[[ $1 == -h ]] && { shift;local  hour_ages=$true; } ||local  hour_ages=
	[[ $1 == -e ]] && { shift;local only_empty=$true; } ||local only_empty=
	[[ $1 == -E ]] && { shift;local skip_empty=$true; } ||local skip_empty=
	local suffix=$1 _suffix=$1
	local ignored_date_ending_type=${2:-NONE} # NONE used in prune arrays

	[[ $suffix ]] &&
	   local suffix_name=${suffix/\*/STAR} || local suffix_name=NONE
	suffix_name=${suffix_name#/}
	suffix_name=${suffix_name#.} ; local \
	 cache_name="suffix=$suffix_name,ignored=$ignored_date_ending_type"
	 cache_name+=",option=$option.txt"

	[[ $suffix == .rm ]] && suffix=*$suffix # also handle .partial.rm
	[[ $ignored_date_ending_type == NONE && $suffix_name != keep ]] &&
	   local dates=$true || local dates=$false

	local     numbers_cache_file=$watch_cache_dir/numbers/$cache_name
	local oldest_ages_cache_file=$watch_cache_dir/oldest-ages/$cache_name
	local newest_ages_cache_file=$watch_cache_dir/newest-ages/$cache_name
	local drive_names=$all_drive_names
	# the cache files in number/ are a pure superset of the files in *-age/
	if _is-stats-cache-fresh  $numbers_cache_file && [[ $watch_opt ]]
	   then stats_numbers=$(< $numbers_cache_file)
		[[ $dates ]] && {
		stats_oldest_ages=$(< $oldest_ages_cache_file)
		stats_newest_ages=$(< $newest_ages_cache_file)
		}
		# echo -n C:		# uncomment to ensure cache is working
		[[ $stats_numbers == *=[1-9]* ]] # have some snapshots?
		return $?
	fi

	_recalculate-snapshot-stats-vars
	[[ $stats_numbers == *=[1-9]* ]] # have some snapshots?
	local status=$?

	[[ $watch_opt ]] || return 0	# don't cache non-colorized 'w' data

	# it takes ~0.05 secs/drive to calculate stats, called 9 times: cache
	[[ -w $log_dir  ]] || return $status # need write access to the cache

	   [[ -d ${numbers_cache_file%/*} ]] ||
	mkdir -p ${numbers_cache_file%/*} ${oldest_ages_cache_file%/*} \
					  ${newest_ages_cache_file%/*}
	echo-to-file "$drive_names" $cached_drive_names_file
	echo-to-file "$stats_numbers"     $numbers_cache_file;[[ $dates ]] && {
	echo-to-file "$stats_oldest_ages" $oldest_ages_cache_file
	echo-to-file "$stats_newest_ages" $newest_ages_cache_file	    ; }

	return $status
}
readonly -f setup-snapshot-stats

# ----------------------------------------------------------------------------

declare -i max_drive_name_len

set-max_drive_name_len() {
	local drive_names=${*:-$drive_names}

	max_drive_name_len=0

	local drive_name
	for drive_name in $drive_names
	    do	(( max_drive_name_len<${#drive_name} )) &&
		   max_drive_name_len=${#drive_name}
	done
}
readonly -f set-max_drive_name_len

# -------------------------------------------------------

declare -i min_full_columns=94		# watch will re-write this

function run-df() {
	local drive_dirs=${*:-$(list-drive-dirs -a)}

	set-rows-columns-COLUMNS

	echo
	local df_fields=source,fstype,size,avail,used,pcent,iused,ipcent,target
	if (( ${columns:-99} >= $min_full_columns ))
	   then filter-df() { cat; }
	   else filter-df() { sed -e 's/Mounted on/Drive/' \
				  -e "s@$drive_dir_prefix@ @" ; }
		df_fields=${df_fields/,size/}
	fi
	local df_opts="--block-size=G --output=$df_fields
		       $df_exclude_type_options --no-sync"
	df $df_opts $drive_dirs | filter-df

	[[ ${show_all-} ]] || return

	echo
	df_fields=${df_fields/,iused,ipcent,/,}
	df_opts="-m --output=$df_fields
		       $df_exclude_type_options --no-sync"
	df $df_opts $drive_dirs | filter-df
}
readonly -f run-df

# --------------------------------------------

function run-lsblk() {
	local drive_dirs=${*:-$(list-drive-dirs -a)}

	have-cmd lsblk && [[ $drive_dirs ]] || return 1

	local dir devices=
	for dir in $drive_dirs
	    do	set-FS_device--from-path $dir &&
		devices+="$FS_device "
	done

	echo
	# fields that don't work: rm,model; unreliable fields: rota
	lsblk_fields=name,fstype,type,size,state,sched,opt-io,mountpoint
	lsblk --output=$lsblk_fields --sort mountpoint  $devices 2>$dev_null ||
	lsblk --output=$lsblk_fields			$devices
}
readonly -f run-lsblk

# ----------------------------------------------------------------------------

function trim-ps {

	# when prune excludes, prune & cron-job can both have a multi-arg 'rm'
	sed -e 's@\( rm [^0-9]*[0-9][^ ]* \).*@\1...@'	\
	    -e '/ lockpid .* replica/d' \
	    -e "s@ --dir=$lock_dir @ @"	\
	    -e "s@ --quiet @ @"		\
	    -e 's@/bin/bash /@/@'	\
	    -e 's@ bash /@ /@'		\
	    -e 's@ /usr/local/bin/@ @'	\
	    -e 's@ -r @ @'		\
	    -e "s@ $HOME/@ ~/@g"	\
	    -e 's@\([0-9]\)     rsync@\1   rsync@' # so can fit in 80 columns
	return 0
}
readonly -f trim-ps

# --------------------------------------------

function trim-backup-ps {

	trim-ps |
	sed -e 's@ --.* @ $opts -R $dirs @' \
	    -e "s@$drive_dir_prefix@@g"	# remove prefix last
	return 0
}
readonly -f trim-backup-ps

# --------------------------------------------

function trim-prune-ps {

	trim-ps
}
readonly -f trim-prune-ps

# --------------------------------------------

function trim-copy-update-ps {

	set -f; set -- $rsync_backup_opts; set +f # standardize whitespace

	local cpss="$our_name_ c"
	local   ud="$our_name_ u"
	trim-ps |
	# makes *.links copy wrap: -e "s@ $* /@ \$opts /@" \
	# makes *.links copy wrap: -e 's@ --.* --link-dest=[^ ]* /@ $opts /@' \
	sed -r \
	    -e '/update-drive/s@ -s@ -s @' \
	    -e "/   [^ ]*$ud/d"   \
	    -e   "/$cpss/s@ -s@ @g" \
	    -e   "/$cpss/s@ -B @ @g" \
	    -e "s@($cpss[^ ]+ +[^ ]+) +[^ ]+.* ([^ ]+) *\$@\1 ... \2@" \
	    -e 's@ --.* --link-dest=[^ ]* /@ /@' \
	    -e "/[0-9]   $our_name_/d" \
	    -e "s@ $* /@ /@" \
	    -e 's@/[^/]*/\. /@/$snap/. /@' \
	    -e "s@$drive_dir_prefix@@g"	# remove prefix last
	return 0
}
readonly -f trim-copy-update-ps

# -----------------------------------------------------------
# the following functions are called consecutively by watch()
# -----------------------------------------------------------

is-set   watch_exe_options ||		# can set custom value in $config_file
readonly watch_exe_options="-c -d -p -x"

exec-watch-snapback-w() {
	local opts=
	while [[ ${1-} == -* || ${1-} == [0-9]* ]]; do opts+="$1 "; shift; done

	local w_opts="$ps_opt $no_errors $stats_opt $cron_opt $bg_opt"
	if [[ $names ]]
	   then set-drive_names--from-user-args $names ||
		   warn "'$names' not mounted" || exit-normally $?
		w_opts+=" -N ${drive_names// /,}"
	fi
	# n >= 0.5 is best for watching wchan (when -C , plus 'sudo ps' access)
	local watch_opt_n=$mon_check_period_secs
	exec watch $watch_exe_options -n $watch_opt_n $opts \
	     $our_path $our_opts w -w $w_opts "$@"
	abort-function "exec failed"
}
readonly -f exec-watch-snapback-w

# --------------------------------------------

set-drive_names-names_msg-names_glob-drive_dirs() {
	local names=$*

	drive_names= drive_dirs=
	if [[ $names ]]
	   then local name drive_name drive_dir
		for name in ${names//,/ }
		    do	set-drive_name- $name
			set-drive_dir-  $drive_name
			drive_names+="$drive_name "
			 drive_dirs+="$drive_dir "
		done
	   else drive_names=$all_drive_names drive_dirs=$all_drive_dirs
	fi
	drive_names=${drive_names% }
	if [[ $names ]]
	   then local name_list=${drive_names// /,}
		names_glob="{$name_list}"  names_msg=" for $name_list "
	   else names_glob=		   names_msg=
	fi
}
readonly -f set-drive_names-names_msg-names_glob-drive_dirs

# --------------------------------------------

declare -i rows columns rows_left

set-rows-columns-COLUMNS() {

	[[ ${rows-} ]] && return

	if [[ ${watch_opt-} || -t 1 || -t 2 ]]
	   then set -f; set -- $(stty -a); set +f
		rows=${5%;} columns=${7%;}
	   else rows=999999 columns=9999
	fi
	rows_left=$rows
	export COLUMNS=9999	     # for 'ps' (we shorten the COMMAND value)
}
readonly -f set-rows-columns-COLUMNS

# --------------------------------------------

declare -i max_ps_width

set-max_ps_width() {
	local ps_header=$1 rsync_ps_out=$2

	ps_header=${ps_header%COMMAND}
	set-max_drive_name_len ${drive_names-$drive_name}
	max_ps_width=${#ps_header}+${#rsync_ps_out}+max_drive_name_len
	let max_ps_width+=1    # 'watch' executable requires blank last column
}
readonly -f set-max_ps_width

# ----------------------

declare cputime

have-cmd \
set-ps_keywords-ps_header ||	   # can define custom version in $config_file
set-ps_keywords-ps_header() {

	[[ ${cputime-} ]] && return

	set-rows-columns-COLUMNS

	cputime=cputime				 # global
	[[ ! $is_darwin ]] && cputime=$cputime:9 # Darwin's is wider

	# min fits in 80-column screen; grep's expect ends with cputime,command
	ps_min_keywords=pid,pgid,%mem,stat,$cputime,command # cron_opt uses
	ps_min_header="  PID  PGID %MEM STAT      TIME COMMAND"
	#
	ps_max_keywords=pid,pgid,start,%mem,%cpu,stat,$cputime,command
	ps_max_header="  PID  PGID  STARTED %MEM %CPU STAT      TIME COMMAND"

	if (( ${columns-0} >= $min_full_columns )) || [[ ${ps_opt-} == -f ]]
	   then readonly is_wide=$true
	   else readonly is_wide=$false
	fi

	if [[ $is_wide ]]
	   then ps_keywords=$ps_max_keywords  ps_header=$ps_max_header
	   else ps_keywords=$ps_min_keywords  ps_header=$ps_min_header
	fi
}
readonly -f set-ps_keywords-ps_header

# ----------------------

# dynamically determine 'ps' fields based on screen column width
setup-ps-variables-and-ps_-function() {

	set-ps_keywords-ps_header
	setup-ps-options

	# trim-ps trims 2 SPACEs from front of rsync command, so fit in 80 cols
	max_rsync_ps_out="  rsync X/.snap/. /2019-03-30,00.links.partial/"
	[[ $ps_opt_H ]] || {
	    [[ max_rsync_ps_out =~ rsync.* ]] &&
	       max_rsync_ps_out=${BASE_REMATCH[0]} ; } # strip leading SPACEs
	set-max_ps_width "$ps_max_header" "$max_rsync_ps_out"
	local min_full_columns=$max_ps_width

	# all field-names followed by '=' means "don't print header"
	ps_() { ps $ps_opt_H -o ${ps_keywords//,/=,}= "$@"; }
	readonly -f ps_
}
readonly -f setup-ps-variables-and-ps_-function

# --------------------------------------------

declare -i num_drives=

set-prune_cmds-copy_rsync_cmds-bkp_rsync_cmds() {

	num_drives=$#

	! set-lock_PGIDs prune && prune_cmds= ||
	prune_cmds=$(ps_ $ps_opt_g $lock_PGIDs 2>$dev_null  |
     egrep ' (prune-drive|update-drive|copy-snapshots|lockpid|sleep|rm|sync) ')

	# if -H, use spacing to find middle rsync (the one with the most CPU)
	[[ $ps_opt_H ]] && local rsync_ps="    rsync" || local rsync_ps=rsync
	cmds-with-one-rsync() { echo "$@" |
		awk '  /rsync/ { if (second) {print; second=0} else second=1 }
		     ! /rsync/ { print }' ; } # use when don't have -H

	# both update-drive and copy-snapshot use the copy lock
	! set-lock_PGIDs copy && copy_rsync_cmds= ||
	copy_rsync_cmds=$(ps_ $ps_opt_g $lock_PGIDs |
			   # first -e ensures we don't see forked snapback also
			   grep -e "[0-9] .*$our_name_.* [cu]"      \
				-e " [l]ockpid "     -e " [s]leep " \
				-e "[0-9] $rsync_ps" -e " [s]ync "     )
	[[ $ps_opt_H ]] ||
	    copy_rsync_cmds=$(cmds-with-one-rsync "$copy_rsync_cmds")
	! set-lock_PGIDs backup && bkp_rsync_cmds=  ||
	bkp_rsync_cmds=$(ps_ $ps_opt_g $lock_PGIDs |
			     grep -e "[0-9] $rsync_ps" -e " [s]ync ")
	[[ $ps_opt_H ]] ||
	    bkp_rsync_cmds=$(cmds-with-one-rsync "$bkp_rsync_cmds")
}
readonly -f set-prune_cmds-copy_rsync_cmds-bkp_rsync_cmds

# --------------------------------------------

function _set-cron_PGIDs() {

	local rsync_or_rm_cmd_PGIDs_file=$tmp_1
	ps -U root -o pgid,command |
	   awk '/[ \/]rm / || /[ \/]rsync / {print $1}' > \
	       $rsync_or_rm_cmd_PGIDs_file
	cron_job_regex=' -C backup-drives? ' # put into configure.sh ??
	set -- $(ps -U root -o pgid,command |
			egrep "$cron_job_regex" |
			fgrep -w -f $rsync_or_rm_cmd_PGIDs_file |
			awk '$0 !~ /setsid / {print $1}' |
			sort -u -n -r)	# the newest PIDs are shown first
	rm -f $rsync_or_rm_cmd_PGIDs_file
	cron_PGIDs=$*
	[[ $cron_PGIDs ]]
}
readonly -f _set-cron_PGIDs

# ---------------------------------

widest_wchan_value=call_rwsem_down_read_failed # linux-3.2
widest_wchan_value=balance_dirty_pages.isra.17 # linux-3.2
widest_wchan_value=balance_dirty_pages.isra.24 # linux-4.x
readonly widest_wchan_value

is-set	   max_ps_wchan_width ||	# can set custom value in $config_file
declare -i max_ps_wchan_width=${#widest_wchan_value}+1
is-set	   min_ps_wchan_width ||	# can set custom value in $config_file
declare -i min_ps_wchan_width=10	# minimum useful value

_set-sudo-wchan-max_ps_wchan_width-ps_keywords() {
	local ps_min_keywords=$*

	ps_keywords=${ps_min_keywords/,%mem,stat,*time*,/,%mem,%cpu,state,}
	local ps_header="  PID  PGID %MEM %CPU S COMMAND"
	[[ $ps_opt_f ]] && ps_header=${ps_header/  PGID/} # have forest?
	[[ $ps_opt_f ]] && ps_keywords=${ps_keywords/,pgid,/,}	; local \
	rsync_ps_out=" |       \_ rsync .opts -R .dirs /2019-07-07,00.partial/"
	[[ $ps_opt_f ]] || {
	    [[ max_rsync_ps_out =~ rsync.* ]] &&		  local \
	       max_rsync_ps_out=${BASE_REMATCH[0]} ; } # strip forest stuff
	set-max_ps_width "$ps_header" "$rsync_ps_out"

	if (( columns > min_ps_wchan_width + max_ps_width ))
	   then local ps_wchan_width=$(( columns - max_ps_width ))
		   (( ps_wchan_width > max_ps_wchan_width )) &&
		      ps_wchan_width=$max_ps_wchan_width
	   else local ps_wchan_width=
	fi

	[[ $ps_wchan_width ]] && wchan=wchan:$ps_wchan_width || wchan=
	[[ $wchan ]] && sudo -n ps &> $dev_null && sudo=sudo || sudo= wchan=
	[[ $wchan ]] && ps_keywords=${ps_keywords/,stat/,$wchan,stat}
}
readonly -f _set-sudo-wchan-max_ps_wchan_width-ps_keywords

# ---------------------------------

_set-ps_keywords--from-columns() {
	local columns=$1

	# deduct the width of the ps record with max wchan
	let columns-=max_ps_wchan_width+max_ps_width # treating as columns_left
	# if we still have columns left, can add more fields
	(( columns >  3 )) && ps_keywords=${ps_keywords/,state,/,stat,}
	(( columns > 13 )) && ps_keywords=${ps_keywords/,comm/,$cputime,comm}
	(( columns > 22 )) && ps_keywords=${ps_keywords/pid,/pid,start,}
	(( columns > 28 )) && ps_keywords=${ps_keywords/pid,/pid,pgid,}
			      ps_keywords=${ps_keywords/,pgid,pgid,/,pgid,/}
}
readonly -f _set-ps_keywords--from-columns

# ---------------------------------

_set-cron_cmds--from-PGIDs() {
	local PGIDs=$*

	local PIDs
	set-PIDs--in-process-groups $PGIDs
	#  option f for "forest"; run trim-backup-ps now, for next adjustment
	cron_cmds=$($sudo ps $ps_opt_f -o $ps_keywords $PIDs | trim-backup-ps)
	[[ $ps_opt_f ]] ||
	# since no forest ascii-art to visually separate jobs, use blank lines
	cron_cmds=$(echo "$cron_cmds" |
		    awk '$1 == $2 {if (old) print ""; else old=1} {print}')
}
readonly -f _set-cron_cmds--from-PGIDs

# ---------------------------------

function set-cron_cmds() {

	_set-cron_PGIDs || return 1

	_set-sudo-wchan-max_ps_wchan_width-ps_keywords $ps_min_keywords

	_set-ps_keywords--from-columns $columns

	_set-cron_cmds--from-PGIDs $cron_PGIDs

	return 0
}
readonly -f set-cron_cmds

# --------------------------------------------

declare -i rows_for_one_detailed_rsync min_rows min_rows_with_df

set-min_rows-min_rows_with_df-rows_left() {

	rows_for_one_detailed_rsync=5	# full details section + 1 rsync
	rows_for_one_detailed_rsync+=2	# full rsync wraps across lines
	#  prune-drive (PD) includes parent of  'rm'   process (also in -C)
	#   copy-snap  (CS) includes parent of 'rsync' process (also in -C)
	# backup-drive (BD) includes 'rsync' only
	local -i PD=$(echo    "$prune_cmds"   | fgrep -c 'prune-drive')
	(( PD > 0 )) && PD=$((PD*2 + 4)) # add in 'rm' plus section-overhead
	local -i CS=$(echo "$copy_rsync_cmds" | egrep -c '(update|copy)-')
	(( CS > 0 )) && CS=$((CS*2 + 4)) # add in 'rsync' plus section-overhead
	local -i BD=$(echo  "$bkp_rsync_cmds" | fgrep -c r); num_bkp_rsyncs=$BD
	(( BD > 0 )) && let BD+=7	# header plus default variable values
	(( BD > 0 )) && let BD+=$rows_for_one_detailed_rsync ||
				 rows_for_one_detailed_rsync=0
	[[ $stats_opt ]] && PD=0 CS=0 BD=0
	TraceV 1 PD CS BD && let rows_left-=3

	# min rows: 1 watch line, 1 blank line, 8+1 lines of section-1 stats,
	#   4 lines of empty backup section.
	# the copy (CS) section is only printed if there's some activity.
	min_rows=$(( 1 + 1 + 8+1 + 4 + PD + CS + BD )); [[ $cron_cmds ]] &&
	min_rows+=$((4 + 5*$num_bkp_rsyncs)) # 5: $our_name + 3 rsyncs + bzip
	min_rows_with_df=$((min_rows + 2 + num_drives))
	[[ -s $big_swapouts_file ]] && min_rows_with_df+=2
	[[ $show_all || $functions ]] && rows_left=1222333000
	TraceV 1 min_rows min_rows_with_df && let rows_left-=3 # one more ...
	TraceV 1 rows_left
}
readonly -f set-min_rows-min_rows_with_df-rows_left

# -------------------------------------------------------

readonly syslog_errors_dir=$status_dir/syslog-errors
readonly syslog_errors_count_msg_file=$syslog_errors_dir/count-msg.txt

readonly status_dir_lock_path=$lock_dir/status-dir.pid

create-status_dir() {

	[[ $UID == 0 ]] && lockpid --wait $status_dir_lock_path || return

	[[ -d $status_dir ]] || {

	sudo mkdir $status_dir &&
	set-admin_group &&
	sudo chgrp $admin_group $status_dir &&
	sudo chmod g+w,g+s $status_dir ||
	    { local s=$?; rmdir $status_dir; abort-function " -> $s"; }

	sudo mkdir     $syslog_errors_dir
	sudo chmod g+w $syslog_errors_dir

	}

	lockpid --release $status_dir_lock_path
}
readonly -f create-status_dir

# --------------------------------------------

show-errors-in-syslog() {
	local errors_count_msg_file=${1:-$syslog_errors_count_msg_file}

	[[ ! ${no_errors-} && -s $errors_count_msg_file ]] && {

	local header="count subset-of-$(basename $syslog_path)-record"
	set-warning_string warning "${header^^}"
	echo "$warning_string"
	while read count msg
	   do	local -i msg_len=${#msg}
		(( $msg_len > $columns - 8 )) && msg="${msg:0:$columns-12} ..."
		case $msg in
		    ( *"uas_eh_abort_handler"*		      |	\
		      *"uas_eh_device_reset_handler start"*   |	\
		      *"uas_eh_device_reset_handler success"* | \
		      *"reset "*" USB device"*		  )
			  local type=warning ;;
		    ( * ) local type=error   ;;
		esac
		set-warning_string $type "$msg"
		printf "%5d: %s\n" $count "$warning_string"
		let rows_left-=1
	done < $errors_count_msg_file

	echo
	let rows_left-=2

	}

	[[ $all_drive_names ]] && return

	create-status_dir		# in case we just did an install
	# run the functions at start of show-filesystem-info-that-fits
	print-big-swapouts-file
	 set-FS_repair_cmds_file
	show-FS-repair-cmds
	echo "No mounted backup drives found."
	quit-if-requested
	exit-normally
}
readonly -f show-errors-in-syslog

# --------------------------------------------

show-sudo-config-warning() {

	local -i min_for_rare=$(( min_rows_with_df + 6 + 7 + 6 ))
	[[ ! -s /etc/sudoers.d/$our_name_ &&
	   $rows_left -gt $min_for_rare       ]] || return

	header -E "to not fill the log with frequent 'sudo ps'"
	echo
	option_1="install etc/sudoers.d/$our_name"
	option_2="put its contents into /etc/sudoers"
	echo -e "$option_1, or $option_2"

	header "statistics"
	echo

	let rows_left-=6		# only adjust for optional sections
}
readonly -f show-sudo-config-warning

# --------------------------------------------

# this section is mandatory
show-stats-section-1() {

	report-rows_left-if-parallelized

	# NOTE: see min_rows= in set-min_rows-min_rows_with_df-rows_left

	set-writer_hour_avgs-writer_hour_maxs backup
	echo "Average hours to create backup snapshot:  $writer_hour_avgs"
	echo "Maximum hours to create backup snapshot:  $writer_hour_maxs"
	setup-snapshot-stats -h ''
	echo "  Age of newest good snapshot, in hours:  $stats_newest_ages"
	set-drive_usages
	echo " Maximum drive (b)lock or (i)node usage:  $drive_usages"
	set-drive_responses
	echo "      Seconds to list drive's snapshots:  $drive_responses"
	setup-snapshot-stats ''	      # was in show-stats-section-3
	echo " Number complete & successful snapshots:  $stats_numbers"
	setup-snapshot-stats .rm
	echo " Number pruned .rm snaps awaiting rm -r:  $stats_numbers"
	setup-snapshot-stats -e .partial
	echo " Number empty .partial dirs, for update:  $stats_numbers"
}
readonly -f show-stats-section-1

# ----------------------------------------------------------------------------

set-drive_name2stats_number() {
	local  stats_number=" $*"
	local  init=${stats_number// / [}
	init=${init//=/]=}
	eval "drive_name2stats_number=( $init )"
}
readonly -f set-drive_name2stats_number

# ---------------------------------

ech_() {

	if [[ ${watch_opt-} ]]
	   then set-warning_string stale "$*"; echo "$warning_string"
	   else echo "$*"
	fi
}
readonly -f ech_

# ----------------------

_do-have-stats() {
	[[ ${1-} == -R ]] && { shift; local skip_last_report=$true; }
	local data_type=${1:-always}

	case $data_type in
	    ( always ) set -- 1						;;
	    ( backup ) set -- $stats_dir/$data_type/MB-changes/*/*.txt	;;
	    ( prune  ) set -- $snapshots_replica_dir/*/*.rm		;;
	    (  copy  ) set -- $snapshots_replica_dir/*/*.partial	;;
	    (   *    ) abort-function "$1: unknown data_type"		;;
	esac
	[[ $# == 0 ]] && { report-rows_left-if-parallelized; return 1; }

	(( $rows_left >= ($min_rows_with_df + $rows_used) )) ||
	[[ $stats_opt ]] || { report-rows_left-if-parallelized; return 1; }

	let pipe_rows_left=$rows_left-$rows_used
	[[ ! ${skip_last_report-} ]] && report-rows_left-if-parallelized
	return 0
}
readonly -f _do-have-stats

# ----------------------

show-stats-section-2-backup() {

	local -i rows_used=4+1		# stats plus 1 blank line
	_do-have-stats backup || return

	set-jobs_per_day-writer_GBs_per_day-percent_usages_per_day backup ||
	    return
	echo				# first row used
	ech_ "Number of backups/day (usually by cron):  $jobs_per_day"
	let rows_left-=1+1		# include blank line

	set-writer_GB_avgs-predicted_TB_sums-predicted_percent_usages backup ||
	    return
	echo " Average GB used when create new backup:  $writer_GB_avgs"
	echo "    Average GB used per day for backups:  $writer_GBs_per_day"
	echo " Daily percentage-point change in usage:  $percent_usages_per_day"
	let rows_left-=3
}
readonly -f show-stats-section-2-backup

# ---------------------------------

show-stats-section-2-prune() {

	local -i rows_used=5
	_do-have-stats prune || return

	setup-snapshot-stats .rm || return

	ech_ " Number pruned .rm snaps awaiting rm -r:  $stats_numbers"

	set-writer_hour_avgs-writer_hour_maxs prune
	echo "  Average hours to delete *.rm snapshot:  $writer_hour_avgs"

	declare -A drive_name2stats_number
	set-drive_name2stats_number $stats_numbers
	set-writer_GB_avgs-predicted_TB_sums-predicted_percent_usages prune
	echo "Average GB freed when prune rm snapshot:  $writer_GB_avgs"
	echo "     ... predicted total TB to be freed:  $predicted_TB_sums"
	echo "           ... predicted %-point change:  $predicted_percent_usages"
	let rows_left-=$rows_used
}
readonly -f show-stats-section-2-prune

# ---------------------------------

show-stats-section-2-copy() {

	local -i rows_used=5
	_do-have-stats -R || return	# don't pass 'copy', need next one ...

	setup-snapshot-stats -e .partial ||
	    { report-rows_left-if-parallelized; return; }
	let rows_left-=$rows_used
	report-rows_left-if-parallelized

	ech_ " Number empty .partial dirs, for update:  $stats_numbers"

	set-writer_hour_avgs-writer_hour_maxs copy
	echo "  Average hours to copy/update snapshot:  $writer_hour_avgs"

	declare -A drive_name2stats_number
	set-drive_name2stats_number $stats_numbers
	set-writer_GB_avgs-predicted_TB_sums-predicted_percent_usages copy
	echo "   Average GB used when copy a snapshot:  $writer_GB_avgs"
	echo "     ... predicted total TB to be added:  $predicted_TB_sums"
	echo "           ... predicted %-point change:  $predicted_percent_usages"
}
readonly -f show-stats-section-2-copy

# --------------------------------------------

show-stats-section-3() {

	local -i rows_used=7		# stats plus 1 blank line
	_do-have-stats || return

	echo				# first row used
	setup-snapshot-stats .rm
				[[ $stats_newest_ages == *=[0-9]* ]] &&
	echo "   Age of newest pending prune, in days:  $stats_newest_ages"
	setup-snapshot-stats .links
	echo "  Number .links (failed 'ln') snapshots:  $stats_numbers"
				[[ $stats_newest_ages == *=[0-9]* ]] &&
	echo " Days since newest 'Too many links' err:  $stats_newest_ages"
	setup-snapshot-stats -E .partial
	echo " Number of aborted snapshots (.partial):  $stats_numbers"
	echo "    Days since newest .partial snapshot:  $stats_newest_ages"
	setup-snapshot-stats /.keep	# doesn't set oldest/newest_ages
	echo "Number snaps never pruned (have /.keep):  $stats_numbers"
#	setup-snapshot-stats ''		# moved to show-stats-section-1
#	echo "  Number complete/successful snapshots:  $stats_numbers"

	let rows_left-=$rows_used
}
readonly -f show-stats-section-3

# --------------------------------------------

show-stats-section-4() {

	local -i rows_used=6		# stats plus 1 blank line
	_do-have-stats || return

	echo				# first row used
	setup-snapshot-stats ''
	echo "   Age of oldest good snapshot, in days:  $stats_oldest_ages"
	setup-snapshot-stats '' hour
	echo "   Total number  days  w/good snapshots:  $stats_numbers"
	setup-snapshot-stats '' day
	echo "   Total number months w/good snapshots:  $stats_numbers"
	setup-snapshot-stats '' month
	echo "   Total number years  w/good snapshots:  $stats_numbers"
	setup-snapshot-stats '*'
	echo "TOTAL snapshots (good+links+partial+rm):  $stats_numbers"

	let rows_left-=$rows_used
}
readonly -f show-stats-section-4

# --------------------------------------------

is-set   FS_repair_cmd_regex ||		# can set custom value in $config_file
readonly FS_repair_cmd_regex='[x]fs_repair|[f]sck(\.[^ ]+)?'

declare -i FS_repair_cmds_lines

set-FS_repair_cmds_file() {

	FS_repair_cmds_lines=0
	FS_repair_cmds_file=$tmp_3
	ps -o $ps_keywords -U root |
	   egrep -e '%[M]EM' \
		 -e "\b($FS_repair_cmd_regex)\b" > $FS_repair_cmds_file
	# unless there's a time in the file, no processes were found
	[[ "$(< $FS_repair_cmds_file)" == *[0-9]:[0-9]* ]] ||
	    { > $FS_repair_cmds_file; return 1; }

	local ps_line_count=$(wc -l < $FS_repair_cmds_file)
	let rows_left-=$(( 3 + $ps_line_count )) # 3 for header
}
readonly -f set-FS_repair_cmds_file

# ----------------------

show-FS-repair-cmds() {

	[[ -s $FS_repair_cmds_file ]] && {

	fgrep -q ' fsck ' $FS_repair_cmds_file &&
	fgrep -q ' fsck.' $FS_repair_cmds_file &&
	   local sed_opt='/ fsck /d' || local sed_opt='#'

	set-warning_string warning "FS repair command(s), e.g. fsck"
	header "$warning_string"
	echo
	if [[ $watch_opt ]]
	   then sed -r -e "$sed_opt" -e 's@ -.* (/dev/)@ ... \1@'
	   else sed "$sed_opt"
	fi < $FS_repair_cmds_file

	}

	rm $FS_repair_cmds_file
}
readonly -f show-FS-repair-cmds

# --------------------------------------------

show-filesystem-info-that-fits() {
	local drive_dirs=$*

	# df is more important than rsync details
	local -i extra=$rows_for_one_detailed_rsync
	(( $rows_left + $extra >= $min_rows_with_df )) && # see BD+=
	local do_run_df=$true &&
	let rows_left-=$num_drives+2

	(( $rows_left >= $min_rows_with_df )) && [[ ! $copy_rsync_cmds ]] &&
	local do_run_lsblk=$true &&
	let rows_left-=$num_drives+2

	report-rows_left-if-parallelized

	if [[ $show_all && ! $stats_opt ]]
	   then have-cmd snapcrypt && snapcrypt status all
		filesystem-geometry $drive_dirs
	   else	[[ ${do_run_df-} ]] &&
		run-df $drive_dirs

		# --------------------------------------------

		[[ ${do_run_lsblk-} ]] &&
		run-lsblk $drive_dirs
	fi

	print-big-swapouts-file		# these are also run at end of ...

	show-FS-repair-cmds		# ... show-errors-in-syslog
}
readonly -f show-filesystem-info-that-fits

# --------------------------------------------

show-prune-cmds() {

	report-rows_left-if-parallelized

	[[ $prune_cmds || $show_all ]] && header "prune-drive" && echo
	if [[ $prune_cmds ]]
	   then echo "$ps_header"
		echo "$prune_cmds" | trim-prune-ps
	elif [[ $show_all ]]
	   then echo -e "No pruning is being done$names_msg."
	fi
}
readonly -f show-prune-cmds

# --------------------------------------------

show-copy-cmds() {

	report-rows_left-if-parallelized

	[[ $copy_rsync_cmds && ( $show_all || ! $cron_opt ) ]] || return

	header "copy (update-drive or copy-snapshots)"
	echo
	echo "$ps_header"
	echo "$copy_rsync_cmds" | trim-copy-update-ps
}
readonly -f show-copy-cmds

# --------------------------------------------

set-rsync_abbrev_msg() {

	# for some reason, appending newlines does nothing?!
	if [[ $is_wide ]]
	   then local var_name=" (\$rsync_backup_opts)"
	   else local var_name=
	fi

	rsync_abbrev_msg="
	  default opts=\"$rsync_backup_opts\"$var_name
	  default dirs=\"$dirs_to_backup\" (\$dirs_to_backup)" ; readonly \
	rsync_abbrev_msg=${rsync_abbrev_msg//	/} # strip leading TAB
}
readonly -f set-rsync_abbrev_msg


# --------------------------------------------

show-backup-cmds() {

	report-rows_left-if-parallelized

       header "backup-drive's most-CPU-intensive rsync processes (abbreviated)"
	[[ $bkp_rsync_cmds ]] && {
	echo "$rsync_abbrev_msg"; echo
	echo "$ps_header"
	echo "$bkp_rsync_cmds" | trim-backup-ps | sort -ty -k2 # rs(y)nc
	} || echo -e "\nNo backups are running$names_msg."

}
readonly -f show-backup-cmds

# --------------------------------------------

# show process tree of master cron job(s)
show-cron-jobs() {

	report-rows_left-if-parallelized

	[[ $cron_cmds ]] || return

	set -- $(ps -o stime= $cron_PGIDs | sort -u)
	local stime=$*
	local regex=${cron_job_regex%%s*}
	header "$stime: '$regex' cron job(s), PGID='$cron_PGIDs'"; echo
	(( $rows_left < $min_rows )) && echo "${rsync_abbrev_msg#?}" && echo
	echo "$cron_cmds"	   # we used trim-backup-ps when we created it
}
readonly -f show-cron-jobs

# --------------------------------------------

show-backup-cmds-with-full-details() {

	report-rows_left-if-parallelized

	[[ $bkp_rsync_cmds ]] || return

      header "backup-drive's most-CPU-intensive rsync processes (full details)"
	echo
	echo "$ps_header"
	echo "$bkp_rsync_cmds" | sed "s@ $HOME/@ ~/@g" | sort -ty -k2 # rs(y)nc
}
readonly -f show-backup-cmds-with-full-details

# --------------------------------------------

show-copy-cmds-with-full-details() {

	report-rows_left-if-parallelized

	[[ $copy_rsync_cmds == *rsync* ]] || return

       header "copy/update's most-CPU-intensive rsync processes (full details)"
	echo
	echo "$ps_header"
	echo "$copy_rsync_cmds" | sed -n "s@ $HOME/@ ~/@g; /\brsync /p" |
	   sort -ty -k2		      # sort on 'y' in rs(y)nc (never in STAT)
}
readonly -f show-copy-cmds-with-full-details

# ----------------------------------------------------------------------------

_start-monitor-drives-if-needed() {

	is-active-lock $drive_monitor_lock_path && return
	sudo -n $our_path -h &> $dev_null || { # need sudo password?
	sleep 0.21			# wait for another process to start mon
	is-active-lock $drive_monitor_lock_path && return
	}

	sudo $our_path monitor-drives || abort-function monitor-drives
	until [[ -d $(dirname $mon_initialized_lock_path) ]]
	   do	env sleep 0.12
	done
	while   lockpid    $mon_initialized_lock_path
	   do	lockpid -r $mon_initialized_lock_path
		env sleep 0.13
	done > $dev_null
}
readonly -f _start-monitor-drives-if-needed

# ------------------------------------------------------------------

_set-functions() {

	functions=
	local function
	for function
	    do	function=show-${function#show-}
		[[ $(type -t $function) == function ]] ||
		    abort "'$function' is an unknown function"
		functions+="$function "
	done
}
readonly -f _set-functions

# --------------------------------------------

readonly generate_output_files_dir=$tmp_dir/generate.$BASHPID
[[ ! -d $generate_output_files_dir ]] || rm -r $generate_output_files_dir
readonly rows_left_file=$generate_output_files_dir/rows_left

function generate() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local function=$*

	[[ ! $functions ]] ||
	is-arg1-in-arg2 $function $functions || { $xtrace; return 1; }

	[[ $do_parallel ]] || { $function; $xtrace; return $?; }

	[[ -d $generate_output_files_dir ]] ||
	mkdir $generate_output_files_dir || abort-function mkdir

	> $rows_left_file
	local output_file=$generate_output_files_dir/out-$job_num
	$function &> $output_file &
	job_num2PID[job_num++]=$!
	Trace 1 "$output_file from $function"

	# wouldn't need polling if used a fifo, but they're buggy in bash-4.4
	until [[ -s $rows_left_file ]] ; do msleep 1; done
	read rows_left < $rows_left_file # let child modify our global

	$xtrace
}

readonly -f generate

# ----------------------

report-rows_left-if-parallelized() {

	[[ $do_parallel ]] && echo $rows_left > $rows_left_file
}
readonly -f report-rows_left-if-parallelized

# ----------------------

quit-if-requested() {

	read -n 1 -t 0.2 user_input
	[[ ${user_input-} == [qQ]* ]] && kill -1 $PPID # kill 'watch' binary
}
readonly -f quit-if-requested

# ----------------------

show-generated-output() {

	quit-if-requested

	[[ $do_parallel ]] || return

	local -i max_job_num=$job_num-1
	for (( job_num=0; $job_num <= $max_job_num; job_num++ ))
	    do	local  PID=${job_num2PID[$job_num]}
		wait  $PID
		local output_file=$generate_output_files_dir/out-$job_num
		cat  $output_file &&
		: rm $output_file	# uncomment to debug
	done
	rm -r $generate_output_files_dir
}
readonly -f show-generated-output

# ---------------------------------

is-set   show_drive_functions ||	# can set custom value in $config_file
readonly show_drive_functions="stats-section-1
stats-section-2-backup stats-section-2-prune stats-section-2-copy
filesystem-info-that-fits"

watch() {
	# most of these variables are accessed in exec-watch-snapback-w
	local watch_opt= ps_opt= no_errors= stats_opt= cron_opt= bg_opt= names=
	[[ ${1-} == -w ]] && { watch_opt=$1; shift; } # internal option
	[[ ${1-} == -f ]] && {    ps_opt=$1; shift; }
	[[ ${1-} == -E ]] && { no_errors=$1; shift; }
	[[ ${1-} == -s ]] && { stats_opt=$1; shift; }
	[[ ${1-} == -C ]] && {  cron_opt=$1; shift; }
	[[ ${1-} == -f ]] && {    ps_opt=$1; shift; }
	[[ ${1-} == -P ]] && {    bg_opt=$1; shift; }
	[[ ${1-} == -d ]] && { do_drives=$1; shift; }
	[[ ${1-} == -u ]] && { user_show=$1; shift; }
	[[ ${1-} == -N ]] && {     names=$2; shift 2; }

	[[ ${do_drives-} ]] && set -- $show_drive_functions
	[[ ${user_show-} ]] && set -- $show_user_functions
	[[ $action == watch ]] && exec-watch-snapback-w "$@" # 'watch' options

	_set-functions $* ; shift $#

	set-drive_names -a
	local all_drive_names=$drive_names
	set-stats_format $all_drive_names
	local all_drive_dirs=" $all_drive_names"
	set -- ${all_drive_dirs// / $drive_dir_prefix}
	all_drive_dirs=$*

	[[ $bg_opt == -P ]] && local do_parallel= || local do_parallel=$true
	local do_tput=$true show_all=$false
	[[ $watch_opt ]] || ps_opt=-f cron_opt=-C show_all=$true do_tput=$false
	[[ $watch_opt ]] || trap '' HUP
	[[ $watch_opt && $Trace ]] && exec 2>$tmp_dir/$our_name_-w.$BASHPID
	[[ $watch_opt || $UID != 0 ]] || check-logs
	(( $Trace_level > 0 )) && do_parallel=$false

	SECONDS=$(date '+%s')		# for _set-age()

	set-drive_names-names_msg-names_glob-drive_dirs $names # set-lock_PGIDs
	TraceV 1 drive_names names_glob ps_opt cron_opt show_all

	set-rows-columns-COLUMNS

	setup-ps-variables-and-ps_-function

	set-prune_cmds-copy_rsync_cmds-bkp_rsync_cmds $drive_names

	[[ $cron_opt && $prune_cmds$bkp_rsync_cmds$copy_rsync_cmds ]] &&
	    set-cron_cmds || cron_cmds=

	local -i rows_left=$rows      # the following functions decrement this

	set-FS_repair_cmds_file
	[[ -s $big_swapouts_file ]] && let rows_left-=2

	set-min_rows-min_rows_with_df-rows_left

	# these are for generate and show-generated-output
	local -i job_num=0
	local -a job_num2PID

	# --------------------------------------------------
	# now we're ready to start showing stuff to the user
	# --------------------------------------------------

	[[ $watch_opt ]] || $Trace

	show-errors-in-syslog	  # before access disk (can trigger I/O error)

	_start-monitor-drives-if-needed

	show-sudo-config-warning

	generate show-stats-section-1
	generate show-stats-section-2-backup
	generate show-stats-section-2-prune
	generate show-stats-section-2-copy
	generate show-stats-section-3
	generate show-stats-section-4

	generate show-filesystem-info-that-fits $drive_dirs

	[[ $stats_opt ]] && { show-generated-output; return; }

	[[ ! $cron_cmds || $show_all ]] &&
	generate show-prune-cmds
	[[ ! $cron_cmds || $show_all ]] &&
	generate show-copy-cmds

	set-rsync_abbrev_msg

	[[ ! $cron_cmds || $show_all ]] &&
	generate show-backup-cmds

	generate show-cron-jobs

	generate show-backup-cmds-with-full-details
	generate show-copy-cmds-with-full-details

	show-generated-output
}
readonly -f watch

##############################################################################
##############################################################################
# Functions for monitoring/creating/altering filesystems and VFS.
##############################################################################
##############################################################################

# ----------------------------------------------------------------------------
# function to predict impact of changing pruning variables in configure.sh
# ----------------------------------------------------------------------------

# predict-prune [-f span] name: see: grep 'prun\w*=' $config_file
predict-prune() {
	local args=$*

	[[ ( ${1-} == -f && $# -ge 3 ) || ( ${1-} != -f && $# -ge 1 ) ]] ||
	    abort-with-action-Usage

	$our_path -d prune-drives "$@" > $tmp_1 || exit $?
	sed -n -r '/^(mv|rm) /s@.*[/ ]@@p' $tmp_1 > $tmp_2 ||abort-function sed
	sort $tmp_2
	set -- $(wc -l < $tmp_2); rm $tmp_1 $tmp_2

	echo -e "
	With current *prun* variable values in $config_file,
	running '$our_name_ prune $args' would prune $1 snapshots.
" >& 2
}
readonly -f predict-prune

# ----------------------------------------------------------------------------
# Function to dump snapack state, for a coder to investigate problems/issues.
# Respects privacy, e.g. doesn't save /etc/snapback/exclude.txt .
# ----------------------------------------------------------------------------

# dump-state [tar-file-name]: store $our_name's full state in tarball
dump-state() {
	local tar_file=${1-}

	set-date_time
	[[ $tar_file ]] || tar_file=$our_name_-$HOSTNAME-$date_time.tar
	tar_file=${tar_file%.xz}.xz
	[[ $tar_file == /* ]] || tar_file=$PWD/$tar_file

	cd_ /

	local libsnap_path=$(type -p libsnap.sh)
	if [[ $our_path != /usr/* ]]
	   then set -- usr/local/bin/{snapback,libsnap.sh}
		local installed_paths=$*
	   else local installed_paths=
	fi

	shopt -u nullglob
	$IfRun tar Jcvf $tar_file --exclude=*~ \
	     ${config_dir#/}/*.sh ${log_dir#/} ${status_dir#/} ${lock_dir#/} \
	     ${our_path#/} ${libsnap_path#/} $installed_paths
	local status=$?
	(( $status <= 1 )) ||		# non-fatal error?
	    abort "tarball probably bad, 'tar' returned $status"
	echo
	du -h $tar_file
}
readonly -f dump-state

# ----------------------------------------------------------------------------
# functions to calculate directory sizes for different FS parameters
# ----------------------------------------------------------------------------

set-total_dir_MB-avg_dir_KB() {
	local file=${1%.bz2}.bz2

	isize=$(echo $file | sed -r 's/.*-inode=([0-9]+)-.*/\1/')
	set -- $( bzcat $file |
		  awk -F K -v isize=$isize \
			'{ sub(/K$/, "", $1); space += ($1*1024) + isize;
			   count += 1 }
			 END { printf "%.1f %.2f\n",
					space/(1024*1024),
					space/(1024*count)}' )
	total_dir_MB=$1 avg_dir_KB=$2
}
readonly -f set-total_dir_MB-avg_dir_KB

# --------------------------------------------

# dir-sizes [-f | name]: generates stats for 'mkfs -b'; -f -> choose old file
dir-sizes() {
	set-drive_log_dir-file_for_logging-is_regression_test
	readonly sizes_dir=$log_dir/dir-sizes
	mkdir -p -m g+w,o-w $sizes_dir || abort "need to use sudo"
	cd_ $sizes_dir

	suffix=ls-s-d

	if [[ $# == 0 ]]
	   then echo -e "\nThe actual drive-space consumed by a directory is"
		echo -e "the size of: its directory block(s) plus its inode:\n"
		set -- *.$suffix.bz2
		[[ $# != 0 ]] ||
		   abort "no saved data files, you need to run: $our_name name"
		for file
		    do	set-total_dir_MB-avg_dir_KB $file || continue
			space="all dirs use $total_dir_MB MB/snapshot"
			  avg="$avg_dir_KB KB/dir"
			printf "%46s: %s\n" "$space ($avg)" ${file%%.*}
		done | sort -k4n	# sort by total size
		echo
		exit-normally
	fi

	if [[ $1 == -f && ${2-} =~ ^[0-9]+$ ]]
	   then index=$2
		set -- *.$suffix.bz2
		eval "file=\${$index}"
	elif [[ $1 == -f && ${2-} ]]
	   then set -- *$2*
		[[ $# == 1 ]] || abort "can't find a single file for $2"
		file=$1
	elif [[ $1 == -f ]]
	   then set -- $(/bin/ls *.$suffix.bz2 | sed 's/\.bz2//')
		[[ $# != 0 ]] || abort "don't have any old data files"
		PS3="specify file number: "
		select file
		   do	[[ $file ]] && break
		done || exit-normally 1
	   else file=  name=${1-}
		[[ $# == 1 && $name && $name != -* ]] ||
		   abort-with-action-Usage
		set-drive_name $1
	fi
	assert-not-option "${1-}"

	[[ $file ]] || {

	set-drive_dir-
	if [[ -d $drive_dir/latest ]]
	   then excludes=   dirs_to_backup=$drive_dir/latest/.  where=
	   else excludes="--exclude=$drive_dir_prefix*
			  --exclude-from=$exclude_file"
		   problem="missing '$drive_dir/latest' snapshot symlink"
		solution_1="you can hit CTRL-C, and either: create symlink"
		solution_2="use 'dirs_to_backup' variable to check root drive"
		warn "$problem: $solution_1, or $solution_2"
		where=-root
	fi

	dir=${dirs_to_backup%% *}
	set-FS_type--from-path $dir
	set-inode_size-data_block_size-dir_block_size--from-path $dir
	type=$FS_type dirblock=$dir_block_size inode=$inode_size
	file=$type-dirblock=$dirblock-inode=$inode-$drive_name$where.$suffix
	TraceV 1 dirs_to_backup file

	[[ ! $debug_opt ]] ||
	   abort "use '-T 1' or '-t' instead of '-d' (-d only works with -f)"
	[[ $UID == 0 ]] || abort "need to use sudo"

	rsync --dry-run --verbose --recursive --relative \
		  $excludes		      \
		--include='*/' --exclude='*'  \
		      $dirs_to_backup  /tmp/  |
	   grep '^/' |
	   # head -n 100 |		# uncomment to speedup debugging
	   tr '\n' '\0' | xargs -0 ls --block-size=K -sd |
	   sed -r 's/^ *([0-9]+K) +/\1|/' | # pipe-separate fields
	   sort -t '|' -k1n,1 -k2	  | # for histogram & compression
	   awk  -F '|' '{ printf "%6s\t%s\n", $1, $2 }' | # more readable
	   bzip2 -9 > $file.partial.bz2 && mv $file.partial.bz2 $file.bz2
	   [[ $? == 0 && ${PIPESTATUS[0]} == 0 ]] ||
	      abort "something bad happened"
	}

	file=${file%.bz2}
	header $file

	local -i dir_count=$(bzcat $file.bz2 | wc -l)
	local -i median_line=$dir_count/2
	printf "\n%7s directories.\n" $dir_count
	bzcat $file.bz2 |
	awk '    { KB += $1; count += 1 }
	     END { printf "Average directory size is %.1f KB\n",
				KB/count }'

	set -- $(bzcat $file.bz2 | sed -n ${median_line}p)
	echo -e " Median directory size is ${1%K} KB ...\n"
	$Trace
	(( $dir_count > 100 )) && {
	local -i decile_count=$(( ($dir_count + 5) / 10 )) i
	local -i decile_median_line=decile_count/2
	for i in {0..9}
	    do	set -- $(bzcat $file.bz2 | sed -n ${decile_median_line}p)
		echo "Decile $i has median directory size of ${1}B"
		let   decile_median_line+=decile_count
	done
	echo
	}

	echo "--> histogram of directory sizes <--"
	echo "  count size"
	echo "  ----- ----"
	bzcat $file.bz2 | cut -f1 | uniq -c | sort -nr | head
	echo -e "    ...\n"

	set-total_dir_MB-avg_dir_KB $file.bz2
	echo "BUT...  The actual drive-space consumed by a directory is"
	echo "the size of its directory block(s) plus the size of its inode:"
	space="$total_dir_MB MB/snapshot"
	  avg="$avg_dir_KB KB/dir"
	echo -e "\n  all directories consume $space ($avg)\n\n"
}
readonly -f dir-sizes

# ----------------------------------------------------------------------------

filesystem-geometry() {
	local drive_dirs
	set-drive_dirs--from-user-args "$@" ||
	    warn "No mounted backup drives found." ||
	    { quit-if-requested; return; }

	run-df    $drive_dirs
	run-lsblk $drive_dirs
	echo

	[[ $UID == 0 || $action == df ]] || return

	[[ $drive_dirs ]] || return
	local dash="------" dsh="---------------" # alternate header
	local dash="======" dsh="==============="
	local    format="%-15s   %-8s%8s %8s %8s %8s %8s %8s\n"
	local f=$format strp="stripe " wdth="width  "
      printf "$f" ""   ""	""	""	""	"dir " "$strp"  "$strp"
      printf "$f" Mount	FS-type	sector	inode	block	block  "unit  "	"$wdth"
      printf "$f" $dsh ==$dash	$dash	$dash	$dash	$dash	==$dash	==$dash
	format=${format/\%25s/%-15s  %8s}
	local drive_dir			# protect caller's value
	for drive_dir in $drive_dirs
	    do	set-FS_type--from-path $drive_dir
		set-FS_device--from-path $drive_dir
		[[ -L $FS_device ]] &&
		set-absolute_path $FS_device && FS_device=$absolute_path
		[[ $FS_device == /dev/mapper/* ]] && dev= ||
		dev=$(echo $FS_device | sed 's@.*/@@; /^[^-]*$/s/[0-9]*$//')
		case $FS_type in
		    ( ext? )
			# output _sometimes_ contains SPACEs (e.g. for inode=)
			sudo -n tune2fs -l $FS_device > $tmp_1 || return
			[[ ! $dev ]] && sector= ||
			sector=$(< /sys/block/$dev/queue/physical_block_size)
			inode=$(sed -n 's/^Inode size:.* //p' $tmp_1)
			block=$(sed -n 's/^Block size:.* //p' $tmp_1)
			dir_block=$block
			sunit=
			swidth=
			;;
		    ( xfs  )
			RunCmd xfs_info $drive_dir > $tmp # $tmp_1
		       sector=$(sed -nr '/at/s/.* sectsz=([^ ]+) .*/\1/p' $tmp)
			inode=$(sed -nr '/^m/ s/.* isize=([^ ]+) .*/\1/p' $tmp)
			block=$(sed -nr '/^d/ s/.* bsize=([^ ]+) .*/\1/p' $tmp)
		    dir_block=$(sed -nr '/^n/ s/.* bsize=([^ ]+) .*/\1/p' $tmp)
			sunit=$(sed -nr '/swi/s/.* sunit=([^ ]+) .*/\1/p' $tmp)
		       swidth=$(sed -nr '/^ /s/.* swidth=([^ ]+) .*/\1/p' $tmp)
			sunit="$sunit blks"
		       swidth="$swidth blks"
			;;
		    (  *   )
			printf "%-15s   %s is unknown FS type, email $coder\n"\
				$drive_dir $FS_type
			continue
			;;
		esac
		printf "$format" $drive_dir $FS_type \
		    "$sector" "$inode" "$block" "$dir_block" "$sunit" "$swidth"
	done
	rm -f $tmp_1
}
readonly -f filesystem-geometry

# ----------------------------------------------------------------------------
# miscellaneous functions for later functions
# ----------------------------------------------------------------------------

# for each name (can be 'all'), kill any backups/pruning/etc & unmount drive
function unmount-drives() {
	[[ $1 == -q  ]] && { local quiet_opt=$1; shift; } || local quiet_opt=
	assert-not-option "${1-}"
	[[ $* == all ]] && set -- $(list-drive-dirs)

	$Trace
	# do this early, since takes a while for processes to die
	for name
	    do	$IfRun kill-job-on-drives all $name
	done

	[[ $debug_opt ]] && local output=/dev/stdout || local output=$dev_null
	local name drive_name drive_dir status=0
	for name
	    do	set-drive_name $name
		set-drive_dir $quiet_opt $drive_name
		is-drive-mounted $drive_dir || continue
		sudo umount -h &> $dev_null || warn "need sudo privs" || break
		umount_cmd="$IfRun sudo umount -v $drive_dir"
		for _i in {1..99}	# wait for kill to finish
		    do	$umount_cmd && break
			$IfRun env sleep 0.15
		done &> $output
		is-drive-mounted $drive_dir || continue
		$umount_cmd || status=$? # this time, show the error message
	done
	return $status
}
readonly -f unmount-drives

# ----------------------------------------------------------------------------

is-set   FS_external_log_size || # can set custom value in $config_file
readonly FS_external_log_size=400M # max journal size for ext4

# Optional function to allocate an external filesystem log/journal
# on fast storage (SSD, or always-plugged-in flash memory stick),
# for use with rotational hard disks.
# Rewrite this function if you're not using LVM.
have-cmd set-FS_external_log ||	   # can define custom version in $config_file
function set-FS_external_log() {
	[[ ${1-} == -f ]] && { local force_opt=$1; shift; } || local force_opt=
	local FS_label=$1 VG=${2:-${FS_log_VG-}} # FS_log_VG in $config_file

	[[ $VG ]] &&
	[[ $do_want_external_log ||	# defined in $config_file
	   $force_opt               ]] || { FS_external_log= && return 1; }

	[[ $VG ]] ||
	   abort "must define set-FS_external_log or FS_log_VG in $config_file"

	       FS_external_log=/dev/$VG/${FS_label}_log
	[[ -b $FS_external_log ]] &&
	    $IfRun lvremove --yes $FS_external_log # in case size changed

	$IfRun \
	lvcreate --size $FS_external_log_size --name $FS_external_log $VG ||
	    FS_external_log=
	[[ $FS_external_log ]]
}
readonly -f set-FS_external_log

# ----------------------------------------------------------------------------

# add-extN-journal drive_name [FS_device [VG_name]]: fast external journal
function add-extN-journal() {
	[[ ${1-} == -M ]] && { local  do_mount=  ; shift; } || local do_mount=t
	[[ ${1-} == -f ]] && { local force_opt=$1; shift; } || local force_opt=
	[[ $# == [1-4] ]] ||
	   abort "{-l FS_label | drive_name} [device [VG-name]]"
	if [[ $1 == -l ]]
	   then shift;  local FS_label=$1
	   else local name=$1 FS_label=
	fi
	assert-not-option -o "${1-}"
	local FS_device=${2-} VG_name=${3-}

	[[ $UID == 0 ]] || $IfRun abort "run with sudo"

	[[ ! $FS_label ]] && {
	set-drive_name -q $1
	set-drive_dir $drive_name
	mount_dir=$drive_dir
	set-FS_label--from-mount_dir $mount_dir ; }
							[[ $FS_device ]] ||
	set-FS_device--from-FS-label $FS_label
	[[ ${mount_dir-} ]] ||
	   set-mount_dir--from-FS-label  $FS_label ||
	   set-mount_dir--from-FS-device $FS_device
	TraceV 1 force_opt FS_label FS_device VG_name mount_dir

	sudo tune2fs -l $FS_device | grep -q '^Journal ' &&	  {
	warn "removing internal journal can take many minutes"
	$IfRun tune2fs $force_opt -O ^has_journal $FS_device	; }

	set-FS_external_log $force_opt $FS_label $VG_name ||
	warn "invalid set-FS_external_log, or $config_file says log unwanted"||
	   { $IfRun tune2fs -j $FS_device; return $?; }
	label=${FS_external_log##*/}

	$Trace

	RunCmd mke2fs -v -b 4096 -O journal_dev -L $label $FS_external_log

	suspend-tracing
	RunCmd -d unmount-drives -q ${mount_dir:-$FS_device}
	restore-tracing
	mount | fgrep -w $FS_device && $IfRun abort "must: umount $FS_device"

	RunCmd tune2fs -J device=LABEL=$label $FS_device
	$IfRun tune2fs -l $FS_device | grep -i "journal [id]"
	local status=${PIPESTATUS[0]}

	[[ $do_mount ]] || return $status

	mount_options=$common_mount_options,$extN_mount_options
	RunCmd mount -v -t ext4 -o ${mount_options%,} $FS_device $mount_dir
}
readonly -f add-extN-journal

# ----------------------------------------------------------------------------

check-lost+found() {

	sudo -n ls &> $dev_null || return

	for dir in $(list-drive-dirs)
	    do	lost_found=$dir/lost+found
		[[ -d $lost_found ]] || continue
		set -- $(sudo ls $lost_found)
		[[ $# == 0 ]] && continue
		warn "$lost_found/ contains $# entries: mv to correct place,
	else delete them and run: $our_name_ redo $dir/*,??
	then rebuild snapshots with: $our_name_ update-drive ${dir##*/}"
	done
}
readonly -f check-lost+found

# ----------------------------------------------------------------------------
# functions leading up to mkfs-backup-drive
# ----------------------------------------------------------------------------

# Since most files are shared between many snapshots, most of our
# inodes are directories; so directory-size determines space-usage, so
# we should choose a block-size that will result in the smallest space
# usage by directories.

# To find your actual average directory size, see section E. in doc/Install.txt

declare -i block_size blocks_per_inode bytes_per_inode

_set-blocks_per_inode-bytes_per_inode--for-extN() {

	# On my Ubuntu laptop, and on HRDAG's server (when don't count our
	# large snap aka snapshot repo), 1 KB extN blocks only use 60% as much
	# space as 2 KB blocks: So the default extN block size is 1KB.  [When
	# we include HRDAG's large snap aka snapshot repo, 1 KB blocks use 70%
	# as much space as 2 KB blocks.]

	# Also, by making the block size smaller with extN, you'll be able to
	# have more inodes if you have a lot of small files, see:
	# https://askubuntu.com/a/1104944 .  Having small blocks might reduce
	# performance on a rotational disk (unless you're using extents and
	# rsync's --preallocate), but probably won't affect performance on an
	# SSD or flash memory stick (unless most files have indirect blocks??).

	block_size=1024			# optimal, see above comments
	set -f; set -- $opts; set +f
	while [[ $# != 0 ]]
	   do	[[ $1 == -b       ]] && block_size=${2-}
		[[ $1 == -b[0-9]* ]] && block_size=${1#-b}
		shift
	done

	local valid_block_sizes="1024 2048 4096"
	is-arg1-in-arg2 $block_size $valid_block_sizes ||
	   abort "extN block size must be one of: $valid_block_sizes"

	blocks_per_inode=1
	 bytes_per_inode=$blocks_per_inode*$block_size
	TraceV 2 block_size bytes_per_inode && echo
}
readonly -f _set-blocks_per_inode-bytes_per_inode--for-extN

# ---------------------------------

# There's no need to store small-files or file's extended-attributes in inodes:
# The extra blocks used for small-files or out-of-inode extended-attributes
# will be shared between snapshots, since file inodes are shared between
# snapshots.  So, we want small inodes.  EXCEPT: If most of the backed-up
# _directories_ have extended-attribute-blocks, then select an inode size that
# will hold the average set of extended-attributes.

_set-opts-log_opt-mount_opts--for-extN() {

	_set-blocks_per_inode-bytes_per_inode--for-extN

	# https://lwn.net/Articles/645722/ : 4/15: fixed ext4 extent corruption
	# https://en.wikipedia.org/wiki/Linux_kernel#Releases_4.x.y
	if [[ $FS_type == ext4 && $(uname -r) > 4.2.7 ]]
	   then local ext4_extent_opt="-O extent"
	   else local ext4_extent_opt=
	fi

	# If you want to backup nanosecond timestamps or file creation time,
	# use inode size >= 256; otherwise, use 128.

	opts+="-v "
	[[ $opts != *-T* ]] && {
	[[ $opts != *-b* ]]	&& opts+="-b $block_size "
	[[ $opts != *-i* ]]	&& opts+="-i $bytes_per_inode "
	[[ $opts != *-I* ]]	&& opts+="-I 128 "	; }
	[[ $opts != *-m* ]]	&& opts+="-m .1 "
	[[ $opts != *extent* ]] && opts+="$ext4_extent_opt "

	[[ $FS_type == ext4  ]] &&
	mount_opts="$extN_mount_options" || mount_opts=

	set-FS_external_log $FS_label &&
	local log_label=${FS_external_log##*/} &&
	$IfRun mke2fs -v -b $block_size -O journal_dev \
		      -L $log_label $FS_external_log &&
	log_opt="-J device=$FS_external_log" || log_opt=
}
readonly -f _set-opts-log_opt-mount_opts--for-extN

# -------------------------------------------------------

_set-opts-log_opt-mount_opts--for-xfs() {

	have-cmd mkfs.xfs || $IfRun abort "install xfsprogs"

	# On HRDAG's Ubuntu server, 1 KB blocks and 2 KB blocks result in the
	# same amount of directory space usage (and 4 KB results in 20% more),
	# since most directories need 0 drive blocks (because their contents
	# fit in the inode); so 2 KB blocks are optimal, since they'll result
	# in better performance ... unfortunately, 2 KB blocks are no longer
	# supported in Ubuntu 18.04.

	# The earlier long comment predicts isize=256; but CRCs need size=512,
	# and 90% of HRDAG's server's dirs fit in a size=512 inode
	# (using isize=1024 resulted in 8% more directory drive space;
	# we chose this, because XFS stores many things in inodes).
	# For servers with bigger dirs, experiment with different
	# mkfs opts (on your fastest drive) and the dir-sizes action (see
	# section E. in doc/Install.txt).

	[[ $force_opt		 ]] && opts+="$force_opt "

	[[ $opts == *"-b size="* ]] || opts+="-b size=4096 "
	[[ $opts == *"-n size="* ]] || opts+="-n size=4096 "
	[[ $opts == *"-i size="* ]] || opts+="-i size=512 "
	[[ $opts == *maxpct=*    ]] || opts+="-i maxpct=0 " # need lotsa inodes

	mount_opts="$XFS_mount_options"

	set-FS_external_log $FS_label &&
	logdev="logdev=$FS_external_log" &&
	log_opt="-l $logdev"  mount_opts=$mount_opts,$logdev || log_opt=
}
readonly -f _set-opts-log_opt-mount_opts--for-xfs

# -------------------------------------------------------

_set-device-drive_name-drive_dir-is_new_dev() {
	device=$1; local name=${2-} dir

	[[ $device = /* ]] ||
	for dir in /dev/mapper /dev
	    do	[[ -b  $dir/$device ]] || continue
		device=$dir/$device
		break
	done
	[[ -b $device ]] || $IfRun abort "'$device' is not a block device"

	if [[ $name ]]
	   then set-drive_name- $name
	   else name=${device##*/}
		local mount_dir
		set-mount_dir--from-FS-label $name
		[[ $mount_dir == $drive_dir_prefix* ]] ||
		   abort "can't derive name from device or label: specify name"
		set-drive_name- $mount_dir
	fi
	name=$drive_name
	[[ ${name,,} != all ]] ||
	    abort "drive_name '$name' is a reserved word"
	set-drive_dir-
	TraceV 2 mkfs_opts device drive_name drive_dir && echo

	if [[ $(df --output=source $device 2> $dev_null) != *$device ]]
	   then is_new_dev=$true
	   else	is_new_dev=$false
		$IfRun abort "$device is mounted; to *DESTROY* its contents,
		first run: sudo umount $device" && echo
	fi

	is-drive-mounted $drive_dir &&
	   $IfRun abort   "there's a filesystem mounted on $drive_dir" && echo

	[[ -d $drive_dir ]] &&
	   $IfRun abort "if '$name' not in use: sudo rmdir $drive_dir" && echo
}
readonly -f _set-device-drive_name-drive_dir-is_new_dev

# -------------------------------------------------------

_set-mkfs_debug_opt() {

	mkfs_debug_opt=
	[[ $debug_opt && $UID == 0 && $is_new_dev ]] || return

	case $FS_type in
	    ( ext? ) mkfs_debug_opt=-n ;;
	    ( xfs  ) mkfs_debug_opt=-N ;;
	    (  *   ) warn "don't know debug opt for $cmd, email $coder" ;;
	esac
	warn "running $cmd in debug mode ..."
}
readonly -f _set-mkfs_debug_opt

# -------------------------------------------------------

_create-and-mount-filesystem() {
	local cmd=$*

	[[ $UID == 0 ]] || $IfRun abort "run with sudo"

	[[ $mkfs_debug_opt ]] && local IfRun= # for RunCmd
	header "$cmd"
	RunCmd  $cmd
	set-drive_log_dir-file_for_logging-is_regression_test $drive_name
	archive-writer-stats-data
	[[ $mkfs_debug_opt ]] && IfRun=echo
	$IfRun mkdir -p $drive_dir
	RunCmd mount -v -t $FS_type -o $mount_opts $device $drive_dir
	fix-drive_dir-perms $drive_dir
	run-df $drive_dir
}
readonly -f _create-and-mount-filesystem

# -------------------------------------------------------

_create-fstab-record() {

	[[ $mount_opts ]] && mount_opts=,$mount_opts
	mount_opts=$common_mount_options$mount_opts
	rec="\n\n\tLABEL=$FS_label\t$drive_dir\t$FS_type\t$mount_opts 0 2"
	warn "sample record for /etc/fstab (optional with 'snapcrypt'):$rec"
}
readonly -f _create-fstab-record

# -------------------------------------------------------

_mkfs-warnings() {

	[[ ${mkfs_cmd_opts-} ]] ||
	    abort "need to set mkfs_cmd_opts= in $config_file"

	set-date_time
	line_1="if you're using a partition or LV that already has backups,"
	line_2="you can keep them, if you rename them as /Year-Mo-Da,Hr/ , "
	line_3="e.g. 'now' looks like /$date_time/ ; don't run 'mkfs',"
	line_4="just relabel the partition and change its record in /etc/fstab"
	line_5="(which is not needed if the partition is auto-mounted)."
	warn "$line_1\n   $line_2\n   $line_3\n   $line_4\n   $line_5"

	[[ $force_opt || $mkfs_cmd_opts != mkfs.ext* ]] || {
	   echo "If this is first or smallest drive, use -f option; otherwise,"
	   echo "if using ext4, use the very-fast 'copy-drive' action instead."
	   abort-with-action-Usage
	} >&2
}
readonly -f _mkfs-warnings

# -------------------------------------------------------

# For encrypting a drive/partition, see section D. in doc/Install.txt .

# mkfs [-f] [mkfs-opts] device-or-label [name]: mkfs drive (see comments)
function mkfs-backup-drive() {
	[[ ${1-} == -f ]] && { local force_opt=$1; shift; } || local force_opt=
	local mkfs_opts= opts_args=" $*"; set -f
	[[ " $*" =~ ^([^/]*)\ (/|[^\ ]*[_A-Z]) ]] &&
	    mkfs_opts=${BASH_REMATCH[1]}
	set -- ${opts_args#$mkfs_opts} ; set +f
	[[ $# == [12] ]] || abort-with-action-Usage
	local device=$1 name=${2-}
	_mkfs-warnings

	_set-device-drive_name-drive_dir-is_new_dev $device $name
	set-FS_label--from-mount_dir $drive_dir

	set -f; set -- $mkfs_cmd_opts $mkfs_opts; set +f
	local cmd=$1; shift; local opts="$* "  log_opt=
	[[ $cmd != mke2fs   ]] || abort "use mkfs.extN instead of mke2fs"
	FS_type=${cmd#*.}
	[[ $FS_type != $cmd ]] || abort "ask $coder to fix FS_type logic"
	case $FS_type in
	    ( ext? ) _set-opts-log_opt-mount_opts--for-extN ;;
	    ( xfs  ) _set-opts-log_opt-mount_opts--for-xfs  ;;
	    (  *   ) abort "don't support FS_type=$FS_type, email $coder" ;;
	esac

	_set-mkfs_debug_opt

	cmd="$cmd $opts $log_opt $mkfs_debug_opt -L $FS_label $device"
	_create-and-mount-filesystem $cmd

	_create-fstab-record

	[[ ! $debug_opt ]] || return 1

	set -- $(which -a $our_name_)
	[[ $# -gt 1 && $1 == $HOME/* ]] && shift # toss git workspace one
	local _our_path=$1
	echo -e "\nTo populate newly-created drive, run:\n
	nohup $_our_path backup-drive $drive_name	# creates new job
	nohup $_our_path update-drive $drive_name	# creates new job"

       warn "REMEMBER: add \`$drive_name' to drive_name_regex= in $config_file"
       return 0
}
readonly -f mkfs-backup-drive

# ----------------------------------------------------------------------------

_assert-dst-big-enough() {
	local src_device=${1:-$src_device}
	local dst_device=${2:-$dst_device}

	local FS_type msg
	set-FS_type--from-path $src_device
	if set-device_KB--from-block-device $src_device
	   then declare -i src_KB=$device_KB
		set-device_KB--from-block-device $dst_device
		local -i dst_KB=$device_KB
		local -i KB_missing=$(( src_KB - dst_KB ))
		(( KB_missing > 0 )) || return

		if [[ $FS_type == ext? ]]
		   then set -- $(tune2fs -l $src_device | grep '^Block size:')
			local -i block_KB=$(( ${!#} / 1024 ))

			$IfRun sync --file-system $src_device &> $dev_null

			# FIXME: might be more accurate than the following fsck
			set -- $(resize2fs -P $src_device)
			local -i min_blocks=${!#}

			set -f
			set -- $(fsck -n $src_device | sed 's/blocks$//')
			set +f
			local     used_total_blocks=${!#}
			local -i  used_blocks=${used_total_blocks%/*}
			local -i total_blocks=${used_total_blocks#*/}
			local -i  used_KB=$((  $used_blocks * $block_KB ))
			local -i total_KB=$(( $total_blocks * $block_KB ))
			(( total_KB < dst_KB )) && return
			((  used_KB < dst_KB )) &&
			    msg="$dst_device too small; but it's OK if" &&
			    abort "$msg you run: resize2fs -M -p $src_device"
		fi

		local -i MB=KB_missing/1024
		local -i GB=MB/1024 &&
		msg="$dst_name's $dst_device is too-small by $MB MB ($GB GB)"
		abort "$msg;\n  specify -D to *not* use 'dd' (use dump/retore)"
	   else msg="$dst_device MUST be as-large as $src_name's $src_device"
		warn "the new $msg"
	fi
}
readonly -f _assert-dst-big-enough

# --------------------------------------------

# these 3 variables are global variables initialized elsewhere
set-drive_name-FS_device-drive_dir-FS_label() {
	local name=$1 device=${2-}

	[[ $device$name ]] || abort "need 1 non-null argument"

	[[ $name == /dev/* ]] && device=$name && name=

	[[ $name ]] && set-drive_name $name && name=$drive_name
	if [[ ! $device ]]
	   then if set-decryption_dev $name
		   then device=$decryption_dev
		   else set-drive_dir- $name
			set-FS_label--from-mount_dir $drive_dir_prefix$name &&
			set-FS_device--from-FS-label $FS_label &&
			device=$FS_device
		fi
	fi
	[[ -b $device ]] || abort "$device is not a block device"

	if [[ ! $name ]]
	   then set-FS_label--from-FS-device $device
		name=$FS_label
	fi

	FS_device=$device
	set-drive_name- $name
	set-drive_dir-
	set-FS_label--from-mount_dir $drive_dir

	TraceV 1 device name drive_name FS_device drive_dir FS_label
}
readonly -f set-drive_name-FS_device-drive_dir-FS_label

# ---------------------------------

copy-backup-drive() {
	action_opts=
	while [[ ${1-} == -* ]] ; do action_opts+="$1 "; shift; done
	[[ $# != 0 ]] ||
	abort "[-f] [-D] [-M] [-F] {src_name | src_dev} {dst_name dst_dev | '' dst_dev | dst_name}"
	local src=$1 dst_name=$2 dst_device=${3-}

	[[ -t 1 ]] || $IfRun abort "don't use 'nohup', we'll run 'nohup'"

	$Trace
	set-drive_name-FS_device-drive_dir-FS_label $src
	local src_name=$drive_name
	local src_device=$FS_device
	local src_drive_dir=$drive_dir
	local src_FS_label=$FS_label

	set-drive_name-FS_device-drive_dir-FS_label "$dst_name" $dst_device
	local dst_name=$drive_name
	local dst_device=$FS_device
	local dst_drive_dir=$drive_dir
	local dst_FS_label=$FS_label

	set-FS_type--from-path $dst_device
	local dst_FS_type=$FS_type
	set-FS_type--from-path $src_device
	local src_FS_type=$FS_type
	[[ $src_FS_type == $dst_FS_type ]] ||
	    abort "different filesystem types, must use update-drive instead"
	if [[ $FS_type == xfs ]] || is-arg1-in-arg2 -D $action_opts # not dd?
	   then warn "'dump | restore' can take weeks; it's probably better to run another 'mkfs', then enable backups plus run 'update-drive $dst_name'"
	   else _assert-dst-big-enough
		# show the user a sample fstab record
		IfRun=echo mkfs-backup-drive -f $dst_device $dst_name |&
		  # search for the last two fields in the fstab record
		  egrep -B 3 "[[:space:]][0-9]+[[:space:]]+[0-9]+[[:space:]]*$"
	fi

	set -f; set --	$our_path $our_opts finish-$action $action_opts \
			$src_device $src_drive_dir \
			$dst_device $dst_drive_dir	; set +f
	local cmd=$*

	if [[ $debug_opt ]]
	   then header "$our_name_ ${cmd#* }"
		exec $cmd || abort "$cmd -> $?"
	fi

	local output_file=$dst_FS_label.out
	echo -e "
	nohup'ing commands to copy partition '$src_name' to '$dst_name';
	this takes about a day per TB of drive space.  Now running
	'exec tail -f $output_file'; you can hit CTRL-C when you get bored.
	"
	nohup $cmd > $output_file &
	local copy_PID=$!
	env sleep 0.2; set -x; exec tail --pid=$copy_PID -f $output_file
}
readonly -f copy-backup-drive

# ------------------------------------------------------------------

_prepare-for-dump-restore() {
	if [[ ${1-} == -S ]]		# src doesn't need to be mounted?
	   then is-drive-mounted $src_drive_dir || local src_name=
		local src_drive_dir=
	fi

	local FS_type src_FS_type
	set-FS_type--from-path $src_device
	src_FS_type=$FS_type
	set-FS_type--from-path $dst_device
	[[ $src_FS_type == $FS_type ]] ||
	   $IfRun abort "FS_type of $dst_device must be '$src_FS_type'"

	assert-not-in-cron-jobs $src_name $dst_name

	local drive
	for drive in $src_drive_dir $dst_drive_dir
	    do	is-drive-mounted $drive || $IfRun abort "mount drive $drive"
	done

	kill-job-on-drives all {$src_name,$dst_name}

	if [[ ${drive_name_regex-} ]]
	   then local where=drive_name_regex=
	   else local where=cron
	fi
	warn "as soon as dump finishes, you can add it back to $where"
}
readonly -f _prepare-for-dump-restore

# ---------------------------------

show-iostat() {
	local device=$1

	$IfRun iostat -y -m -d $device | grep -v -e '^Linux' -e '^$'
}
readonly -f show-iostat

# ---------------------------------

function _dump-restore-xfs-backup-drives {

	abort "dump-restore is VERY slow, better to use action update-drive"

	_prepare-for-dump-restore

	$IfRun set -x

	$IfRun xfs_freeze -f $src_drive_dir

	if [[ -d $dst_drive_dir/xfsrestorehousekeepingdir ]]
	   then local restore_opt=-R
	   else local restore_opt=
	fi

	trap '' INT			# don't interrupt xfsdump or xfsrestore
	show-iostat $dst_device
	time $IfRun    xfsdump -J -p 600       - $src_drive_dir |
	     $IfRun xfsrestore -J $restore_opt - $dst_drive_dir
	local status=$?
	show-iostat $dst_device

	$IfRun xfs_freeze -u $src_drive_dir

	return $status
}
readonly -f _dump-restore-xfs-backup-drives

# ---------------------------------

function _dump-restore-extN-backup-drives {

	abort "dump-restore is VERY slow, better to use action update-drive"

	_prepare-for-dump-restore -S

	have-cmd dump || abort "need to install the 'dump' command"

	$IfRun set -x

	# https://stackoverflow.com/questions/37488629/how-to-use-dump-and-restore-to-clone-a-linux-os-drive
	cd_ $dst_drive_dir
	trap '' INT			# don't interrupt dump or restore
	show-iostat $dst_device
	time $IfRun   dump -a0f - $src_device |
	     $IfRun restore -rf -
	local status=$?
	show-iostat $dst_device

	return $status
}
readonly -f _dump-restore-extN-backup-drives

# --------------------------------------------

readonly all_drives_go_offline_msg='
	There are no other backup partitions mounted besides the ones used to
        copy $src_drive_dir to $dst_drive_dir ; if you let me unmount these
	partition(s), no new backups will be made for many hours (or days).

	You might instead run "$our_name_ mkfs" on the new drive, leave the old
	drive mounted, and run action update-drive.

	To instead unmount both drives and do a fast "dd"'

_copy-extN-backup-drive() {

	is-arg1-in-arg2 -f $action_opts ||
	for drive_dir in $src_drive_dir $dst_drive_dir; do
	if is-drive-mounted $drive_dir
	   then set -- $(list-drive-dirs |
			 fgrep -v -w -e $src_drive_dir -e $dst_drive_dir)
		if [[ $# == 0 ]]
		   then eval "msg=\"$all_drives_go_offline_msg\","
		   else msg="\n\t$src_drive_dir is mounted;"
		fi
		abort "\n$msg re-run copy-drive with -f to Force unmount."
	fi; done

	unmount-drives -q $src_drive_dir $dst_drive_dir ||
	   $IfRun abort "unmount the drive that failed to 'umount'"

	# -------------------------------------------------------

	$IfRun set -x
	time RunCmd dd if=$src_device of=$dst_device bs=1M
	[[ $Trace ]] || set +x

	$IfRun tune2fs -U $(uuidgen) $dst_device

	label-drive $dst_device $dst_drive_dir

	if sudo tune2fs -l $src_device | grep -q "^Journal dev" || # external?
	   [[ $do_want_external_log ]]
	   then add-extN-journal -M $dst_name $dst_device ||
		   abort "need to fix journal on $src_device: $our_name_ aej"
	fi

	local mount_options=$common_mount_options,$extN_mount_options
	mount_options=${mount_options%,}

	is-arg1-in-arg2 -M $action_opts || # don't want to re-Mount src?
	RunCmd mount -v -t $FS_type -o$mount_options $src_device $src_drive_dir

	is-arg1-in-arg2 -F $action_opts || # don't want Fsck?
	time RunCmd -m "better check $src_device ?!" \
	e2fsck -f -p -t -t $dst_device

	$IfRun mkdir -p $dst_drive_dir
	RunCmd -m "make mount happen, then run resize2fs" \
	mount -v -t $FS_type -o $mount_options $dst_device $dst_drive_dir

	RunCmd resize2fs $dst_device	# do this _after_ mount, for speed
}
readonly -f _copy-extN-backup-drive

# --------------------------------------------

# finish-copy-drive: copy, label & UUID, replace journal, fsck, mount, resize
function finish-copy-backup-drive() {
	action_opts=
	while [[ ${1-} == -* ]] ; do action_opts+="$1 "; shift; done
	local cmd=$(echo "$Usage" |
		    grep copy-drive | sed "s/^ */$our_name_ -d /; s/:.*//")
	[[ $# == 4 ]] || abort "to see args, run: $cmd"

	local src_device=$1 src_drive_dir=$2
	local dst_device=$3 dst_drive_dir=$4

	local src_name=${src_drive_dir#$drive_dir_prefix}
	local dst_name=${dst_drive_dir#$drive_dir_prefix}

	customize-and-validate-configuration-variables $dst_name

	[[ $UID == 0 ]] || $IfRun abort "run with sudo"

	set-FS_type--from-path $src_device
	case $FS_type in
	   ( ext?) if is-arg1-in-arg2 -D $action_opts
		      then _dump-restore-extN-backup-drives
		      else _copy-extN-backup-drive
		   fi ;;
	   ( xfs ) _dump-restore-xfs-backup-drives  ;;
	   (  *  ) abort "write FS function call for $FUNCNAME, email $coder";;
	esac ||
	   abort "the copy seems to have failed with $?, check .out file"
	set +x

	local var=drive_name_regex
	warn "DON'T FORGET: add $src_name & $dst_name to $var= in $config_file"
	return 0
}
readonly -f finish-copy-backup-drive

# ----------------------------------------------------------------------------
# check syslog for big swapout rates.  This assumes you're running 'pmie',
# contained in the 'pcp' (i.e. Performance Co-Pilot) package on Debian/Ubuntu.
# ----------------------------------------------------------------------------

is-set   big_swapout_string ||		# can set custom value in $config_file
readonly big_swapout_string="Severe demand for real memory"

big_swapout_str=$big_swapout_string
is-set   big_swapouts_regex ||		# can set custom value in $config_file
readonly big_swapouts_regex=".* $big_swapout_str ([1-9][0-9]+)(\.[0-9]*)?pgs.*"

_set-big_swapouts_record--from-syslog-file() {
	local log=${1:-$syslog_path}

	local cat_cmd regex=$big_swapouts_regex
	  set-cat_cmd $log
	set -- $($cat_cmd $log | sed -n -r "s/$regex/\1/p" | sort -nr)
	big_swapouts_record=$*
}
readonly -f _set-big_swapouts_record--from-syslog-file

# -------------------------------------------------------

readonly big_swapouts_file=$syslog_errors_dir/big-swapouts.txt

search-syslog-for-big-swapouts() {
	local log=${1:-$syslog_search_results_file}

	[[ ! $is_regression_test ]] || return

	_set-big_swapouts_record--from-syslog-file $log

	create-status_dir
	[[ ! $big_swapouts_record ]]  &&  > $big_swapouts_file && return
	echo-to-file "$big_swapouts_record" $big_swapouts_file
}
readonly -f search-syslog-for-big-swapouts

# ------------------------------------------------------------------

function print-big-swapouts-file() {
	[[ ${1-} == -a ]] && { shift; local is_action=$true; }
	local  file=${1:-$big_swapouts_file}
	[[ -s $file ]] || return 1

	if [[ ${is_action-} ]]
	   then	local prefix=$(basename $file); prefix=${prefix%.txt}
	   else local prefix="big swapouts"
	fi

	local values= is_first_value=$true
	local -i pages_per_sec
	for pages_per_sec in $(< $file)
	    do	local -i MBps=$(( ( ($pages_per_sec * 4) + 512 ) / 1024 ))
		(( $MBps > 0 )) || break
		if [[ ${max_swapout_MBps-} ]]
		   then local -i percent=$(( 100*$MBps / $max_swapout_MBps ))
		   else local -i percent=0
		fi
		if [[  $is_first_value && ${max_swapout_MBps-} ]]
		   then is_first_value=$false
			values+="$MBps ($percent% of swap dev), "
		   else values+="$MBps, "
		fi
	done
	values=${values%, }
	set --  $values
	[[ $# != 0 ]] || return 1

	local record
	if [[ ${is_action-} ]]
	   then printf -v record "%8s:%3s: %s" "$prefix" $# "$values"
	   else printf -v record   "%s %s: %s" $# "$prefix" "$values"
	fi
	local -i record_len=${#record}
	(( $record_len > $columns - 6 )) &&
	    record="${record:0:$columns-10}" &&
	    record="${record%,*}, ..."

	[[ ! ${is_action-} ]] && echo
	echo "${record%,} MBps"

	return 0
}
readonly -f print-big-swapouts-file

# --------------------------------------------

readonly monitor_dir=$log_dir/monitor
readonly big_swapouts_dir=$monitor_dir/big-swapouts

find-and-print-big-swapouts() {

	[[ -d $big_swapouts_dir ]] || mkdir -p $big_swapouts_dir

	set-rows-columns-COLUMNS

	local log regex=$big_swapouts_regex
	for log in $syslog_path-* $syslog_path
	    do	local date=${log##*-}; date=${date%.*}
		[[ $date == /* ]] && date=today

		local  cache_file=$big_swapouts_dir/$date.txt
		[[ -f $cache_file && $cache_file -nt $log ]] || {
		set-cat_cmd $log
		set -- $($cat_cmd $log | sed -n -r "s/$regex/\1/p" | sort -nr)
		[[ $# != 0 ]] && echo $*
		} | echo-to-file - $cache_file
		print-big-swapouts-file -a $cache_file
	done
}
readonly -f find-and-print-big-swapouts

# ----------------------------------------------------------------------------

measure-swapout-MBps() {
	local swap_dev=${1-}
	[[ $# == 1 && ( -b $swap_dev || -s $swap_dev ) ]] ||
	    abort-function swap-device

	for cmd in swapon swapoff mkswap
	    do	have-cmd $cmd && continue
		$IfRun \
		abort "only works with Linux, but run with -d option for clues"
	done

	shopt -u nullglob		# so can use ? in debug mode
	set -f				# won't do any globbing

	local swapon_args="--raw --bytes --show=name,size,used,uuid,label"
	if have-cmd swapon || [[ ! $debug_opt ]]
	   then swapon $swapon_args > $tmp_1 ||
		   abort "need a 'swapon' that supports $swapon_args"
	   else echo swapon $swapon_args
	fi
	#
	if [[ -s $tmp_1 || ! $debug_opt ]]
	   then set -- $(grep "^$swap_dev " $tmp_1)
		(( $# >= 2 )) || abort "must first run: sudo swapon $swap_dev"
		local size_B=$2 used_B=$3 UUID=$4 label=${5-}
		local -i size_MB=$size_B/1024/1024   used_MB=$used_B/1024/1024
		local -i size_MB_1=size_MB-1
		(( $size_MB_1 >   0 )) || size_MB_1=1
		(( $size_MB_1 > 999 )) && size_MB_1=999
	   else local size_MB=? size_MB_1=?
		local UUID=UUID label=label
		cat $tmp_1
	fi

	$IfRun sudo swapoff $swap_dev || 
	    abort "add temporary swap: 'dd', 'mkswap', 'chmod', 'swapon'"
	$IfRun \
	sudo dd if=/dev/zero of=$swap_dev bs=1M count=$size_MB_1 &> $tmp_1
	if [[ ! $debug_opt ]]
	   then local bw=$(sed -n '$s/.*, *//p' $tmp_1)
		warn "swapout bandwidth is $bw"
	   else cat $tmp_1
	fi

	[[ $label ]] && label_opt="--label $label"
	local args="${label_opt-} --uuid $UUID $swap_dev"
	$IfRun mkswap $args || abort "mkswap $args -> $?"

	$IfRun sudo swapon $swap_dev
	echo; swapon --show=${swapon_args/*--show=/},prio

	set +x
}
readonly -f measure-swapout-MBps

# ----------------------------------------------------------------------------
# check syslog for FS and OS errors
# ----------------------------------------------------------------------------

is-set   OS_ignorable_error_strings ||  # can set custom value in $config_file
# first is google-chrome error
readonly OS_ignorable_error_strings="\
:ERROR:mcs_client.cc
[AppIndicatorSupport-WARN] Attempting to re-register"

is-set   OS_error_strings || 		# can set custom value in $config_file
readonly OS_error_strings="\
I/O error
Failed to connect stdout to the journal socket, ignoring: "

is-set   USB_error_strings || 		# can set custom value in $config_file
readonly USB_error_strings="\
abort
FAILED Result:
rejecting I/O to
reset
Synchronize Cache(10) failed"

is-set   XFS_error_strings || 		# can set custom value in $config_file
readonly XFS_error_strings="\
Internal error
xfs_do_force_shutdown
Shutting down filesystem"

is-set   extN_error_strings || 		# can set custom value in $config_file
readonly extN_error_strings="\
Corrupted index cache file
EXT4-fs error
group descriptors corrupted!"

is-set syslog_search_string_var_names || # can set custom value in $config_file
readonly syslog_search_string_var_names="
     OS_error_strings
    USB_error_strings
    XFS_error_strings
   extN_error_strings
  big_swapout_string
"

readonly syslog_search_results_file=$syslog_errors_dir/_errors.txt

search-syslog-for-errors() {
	local  syslog_file=${1:-$syslog_path}
	local  search_file=${2:-$syslog_search_results_file}
	local cnt_msg_file=${3:-$syslog_errors_count_msg_file}

	local search_str_file=$tmp_1 ignorable_str_file=$tmp_2
	local var_name
	for var_name in $syslog_search_string_var_names
	    do	echo "${!var_name}"
	done | echo-to-file - $search_str_file
	echo "$OS_ignorable_error_strings" | echo-to-file - $ignorable_str_file

	# in case /etc/logrotate.conf contains 'dateext' & 'delaycompress'
	set -- $syslog_path-????????	# have yesterday's file?
	[[ $syslog_file == $syslog_path && $# != 0 && -s $1 ]] &&
	    syslog_file+=" $1"
	create-status_dir
	fgrep --text -f    $search_str_file $syslog_file |
	    fgrep -v -f $ignorable_str_file | echo-to-file - $search_file
	rm $search_str_file $ignorable_str_file

	# blk_update_request: I/O error, dev sda, sector B op 0x1:(WRITE) ...
	#    print_req_error: I/O error, dev sda, sector B
	# metadata I/O error: block B ("xfs_...") error 5 numblks N
	#   Buffer I/O error on dev dm-30, logical block B, async page read
	local file=$search_file
	set -- $(sed -r -n 's/.* sector +([0-9]+)[^0-9]*/\1/p' $file| sort -nu)
	local sectors="$# sectors: $*"

	local service_string="service: Failed to connect stdout to the journal"
	set -- $(sed -r -n "s/.* ([^ ]*)\\.$service_string.*/\\1/p" $file |
		 sort -u)
	local services=$*
	(( $# > 1 )) && services="systemd service failures: {${services// /,}}"

	sed 's/.*[0-9]\][: ] *//' $search_file |
	    fgrep -v "$big_swapout_string" |
	    sed -r -e 's/ tag#[0-9]+/ tag#M/; s/-tag [0-9]+/-tag N/' \
		   -e 's/( inflight):.*$//' \
		   -e '/uas_eh_abort_handler/s/^sd /scrzz /' \
		   -e    '/Result: hostbyte=/s/^sd /scrzzz /' \
		   -e  's/(blocks? +)[xa-f0-9]+/\1B/' \
		   -e 's/( error 5 numblks? )[0-9]+/\1N/' \
		   -e "s/(sectors? +)[0-9]+.*/$sectors/" \
		   -e "s/^.*(\\.$service_string)/$services\\1/" |
	    sort | sed 's/scrzz* /sd /' | # undo hack to group UAS msgs
	    uniq -c | echo-to-file - $cnt_msg_file ||
		          { ls -ld . $cnt_msg_file*; print-call-stack; }
}
readonly -f search-syslog-for-errors

# -------------------------------------------------------

check-logs() {

	search-syslog-for-errors
	search-syslog-for-big-swapouts
}
readonly -f check-logs

##############################################################################
##############################################################################
# Random maintenance functions.
##############################################################################
##############################################################################

set-sudo--if-pwd-not-writable() {

	local test_file=.test-file.$BASHPID
	if touch $test_file &> $dev_null
	   then rm $test_file
		sudo=
	   else sudo=sudo
	fi
}
readonly -f set-sudo--if-pwd-not-writable

# ----------------------------------------------------------------------------

function check-snapshot-hard-links() {
	local name=$1

	[[ ${very_old_immutable_files-} ]] ||
	   abort "setup very_old_immutable_files= in $config_file"

	set-drive_name $name
	set-drive_dir  $drive_name
	cd_ $drive_dir

	set-inum() {
		[[ -r $1 ]] || abort "run with sudo"
		set -- $(ls -i -d $1 2>$dev_null)
		inum=$1
		[[ $inum ]]
	}

	set -- $snapshot_glob*

	local -A file2inum
	for old_file in $very_old_immutable_files
	    do	$IfRun sudo -n chattr +i $old_file &> $dev_null # optional
		file=$1$old_file
		set-inum $file ||
		  abort "$drive_name: $file missing from oldest snapshot $1"
		file2inum[$old_file]=$inum
	done
	$Trace
	partials=
	while [[ $# != 0 ]]
	    do	found_good_link=$false
		for old_file in $very_old_immutable_files
		    do	old_inum=${file2inum[$old_file]}
			set-inum $1$old_file
			[[ $old_inum == $inum ]] || continue
			found_good_link=$true
			break
		done
		[[ $found_good_link ]] && partials= && shift && continue
		[[ $1 == *.partial  ]] && partials+="$1 " &&
						       shift && continue

		$IfRun mkdir -p .rm
		set -- $partials $*
		warn "$drive_name: the following have broken hard-links: $*"
		return 1
	done
	echo "$drive_name: no broken hard-links!"
}
readonly -f check-snapshot-hard-links

# ----------------------------------------------------------------------------
# regression tests for "old" (installed) vs "tst" (workspace) snapback
# ----------------------------------------------------------------------------

chroot-backup() {
	local date_time=$1; shift; local command=${*-}

	local drive_dir snapshots=
	[[ $date_time == /* ]] && snapshots=$date_time ||
	for drive_dir in $(list-drive-dirs -a)
	    do	local  snapshot=$drive_dir/$date_time
		[[ -d $snapshot ]] && snapshots+="$snapshot "
	done
	[[ $snapshots ]] || abort "can't find snapshot matching $date_time"

	set -- $snapshots
	[[ $# == 1 ]] || set -- $(fastest-snapshots -f $snapshots)
	local chroot_dir=$1

	# $Trace
	have-proc && {
	$IfRun sudo mount -o bind /proc    "$chroot_dir/proc"
	$IfRun sudo mount -o bind /dev     "$chroot_dir/dev"
	$IfRun sudo mount -o bind /dev/pts "$chroot_dir/dev/pts"
	$IfRun sudo mount -t tmpfs tmpfs   "$chroot_dir/dev/shm"
	$IfRun sudo mount -t tmpfs tmpfs   "$chroot_dir/run"
	$IfRun sudo mount -t sysfs sys     "$chroot_dir/sys"	; true
	} ||
	$IfRun sudo mount -t devfs devfs   "$chroot_dir/dev" # Darwin/BSD

	drive_dir=${chroot_dir%/*}
	[[ ! $is_cron ]] &&
	echo -n "remounting $drive_dir, might take a minute ... "
	$IfRun sudo mount -o remount,dev,suid	  "$drive_dir"; echo; $Trace
	# shellcheck disable=SC2086
	$IfRun sudo chroot $chroot_dir $command			  ; set +x
	$IfRun sudo mount -o remount,nodev,nosuid "$drive_dir"

	have-proc && {
	for dir in proc dev/pts dev/shm dev run sys
	    do	$IfRun sudo umount "$chroot_dir/$dir"
	done							; true
	} ||    $IfRun sudo umount "$chroot_dir/dev" # Darwin/BSD
}
readonly -f chroot-backup

# ----------------------------------------------------------------------------

_show-test-header() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	header "$* (first number is md5sum of sorted data, second is unsorted)"
	$xtrace
}
readonly -f _show-test-header

# ---------------------------------

_show-test-results() {
	[[ -o xtrace ]] && { set +x; local xtrace="set -x"; } || local xtrace=
	local output_file=$1

	[[ -s $output_file ]] &&
	echo "$(sort "$output_file" | md5sum) $(md5sum "$output_file")"
	$xtrace
}
readonly -f _show-test-results

# --------------------------------------------

_run-debug-cmds() {
	local test=$1; shift
	local args=$*

	local tmp_o=$tmp_dir/o$test	# holds output from "old" cmd
	local tmp_t=$tmp_dir/t$test	# holds output from "tst" cmd

	# shellcheck disable=SC2154
	local old_cmd_="$old_cmd -C -d  $trace_opt               $args"
	# shellcheck disable=SC2154
	local tst_cmd_="$tst_cmd -C -d ${trace_opt:-$_trace_opt} $args"

	if [[ $debug_opt ]]
	   then echo "$old_cmd_ &> $tmp_o"
		echo "$tst_cmd_ &> $tmp_t"
		return
	fi

	$Trace
					     _show-test-results "$tmp_o"
	$tst_cmd_ &> "$tmp_t" || abort tst ; _show-test-results "$tmp_t"
	# shellcheck disable=SC2086
	[[ $test == u ]] && set-srcs_dst_file && cp $srcs_dst_file $tmp_t.args
	cmp -s "$tmp_o" "$tmp_t" && { set +x; echo "-- same results!";return; }

	echo "
	Since different results, regenerate data cached from installed cmd ..."
	PATH=${old_cmd%/*}:$PATH \
	$old_cmd_ &> "$tmp_o" || abort old ; _show-test-results "$tmp_o"
					     _show-test-results "$tmp_t"
	# shellcheck disable=SC2086
	[[ $test == u ]] && set-srcs_dst_file && cp $srcs_dst_file $tmp_o.args
	cmp -s "$tmp_o" "$tmp_t" && { set +x; echo "-- same results!";return; }

	set +x
	set-warning_string error DIFFERENT results
	echo "-- $warning_string, compare with: diff -u $tmp_o $tmp_t | less"
	[[ $test != u ]] || cmp -s "$tmp_o.args" "$tmp_t.args" ||
	echo "... also check copy args: diff -u $tmp_o.args $tmp_t.args | less"

	failed_tests+="$test "
}
readonly -f _run-debug-cmds

# ---------------------------------

readonly regression_tests="b c z p u"

function regression-test() {
	[[ ${1-} == -t ]] && { _trace_opt=-t; shift; } || _trace_opt=
	local tests=${*:-$regression_tests}
	# can exclude one test (especially useful to exclude the slow 'u' test)
	[[ $tests == [A-Z]* ]] && tests=${regression_tests//[${tests,,}]/}

	[[ $tests == *[zpu]* ]] && validate-prune_globs

	[[ -x $old_cmd ]] || abort "fix old_cmd= in $config_file"
	[[ -x $tst_cmd ]] || abort "fix tst_cmd= in $config_file"

	echo -e "\nComparing $old_cmd to $tst_cmd"

	local failed_tests=

	# --------------------------------------------

	# shellcheck disable=SC2086
	is-arg1-in-arg2 b $tests && {
	_show-test-header backup all
	_run-debug-cmds b backup-drive all
	}

	# --------------------------------------------

	# shellcheck disable=SC2086
	is-arg1-in-arg2 c $tests && {
	_show-test-header copy to Z
	# shellcheck disable=SC2086
	set -- $drive_dir_prefix*/$snapshot_day_glob,00
	[[ $# != 0 ]] || abort "copy test needs at least one snapshot"
	src_snapshots=$1
	[[ -d $2 ]] && src_snapshots+=" $2"
	# shellcheck disable=SC2086
	_run-debug-cmds c copy-snapshot $src_snapshots Z
	}

	# --------------------------------------------

	# shellcheck disable=SC2086
	is-arg1-in-arg2 z $tests && {
	set -- ${drive_dir_prefix}Z/$snapshot_glob
	(( $# > 10 )) || $our_path test-prune || abort "can't setup Z"
	_show-test-header prune Z
	_run-debug-cmds z prune-drive Z
	}

	# --------------------------------------------

	set-drive_dirs

	# shellcheck disable=SC2086
	is-arg1-in-arg2 p $tests && [[ $drive_dirs ]] && {
	_show-test-header prune all
	_run-debug-cmds p prune-drives all
	}

	# --------------------------------------------

	# shellcheck disable=SC2086
	is-arg1-in-arg2 u $tests && [[ $drive_dirs == *' '* ]] && {
	local args=${update_test_args-}
	[[ $args ]] || abort "$config_file needs update_test_args= for 'u'"
	# shellcheck disable=SC2086
	set -- $args
	local dst=${!#}
	_show-test-header update "$dst"

	set-drive_name- "$dst"
	set-drive_dir-
	suspend-jobs backup prune
	have-job copy &&
	$our_path kill copy "$dst" &> $dev_null && killed_dst=$dst && {
	    warn "killed update-drive (or copy) on drive $dst"
	    cd_ "$drive_dir"
	    $IfRun sudo rm -f ./*.partial/.keep
	    $IfRun sudo rmdir ./*.partial &> $dev_null
	}

	# shellcheck disable=SC2086
	_run-debug-cmds u update-drive $args

	# shellcheck disable=SC2119
	reset-priority			# will continue only one job
	continue-jobs backup
	[[ ${killed_dst-} ]] &&
	warn "remember to restart your copy/update job on drive $killed_dst"
	true
	} || tests=${tests/ u/}

	if [[ $failed_tests ]]
	   then warn "ERROR: regressions in these tests: ${failed_tests% }"
	   else	set-warning_string ok \
		   "all the (specified) tests passed: $tests"
		echo -e "\n$warning_string\n"
	fi
}
readonly -f regression-test

#############################################################################
#############################################################################
# Process the requested action with the above functions & global variables. #
#############################################################################
#############################################################################

[[ $# != 0 ]] || abort "specify an action to perform\n$Usage"

action=$1; shift
our_name_="$our_name"
 our_name="$our_name $action"
undo-action-abbrev() { readonly action=$1 our_name="$our_name_ $1" our_name_; }

# ---------------------------------

process-action() {

case $action in
   ###########################################################################
   # main actions, to create new jobs
   ###########################################################################

   # backup-drives   names: backup names ('all' for every mounted backup drive)
   ( b*k*p*dr*v* | bd* | r*b* ) undo-action-abbrev backup-drives
	[[ $# != 0  ]] || abort-with-action-Usage
	[[ $1 != -r ]] && assert-not-option "$1"
	[[ $# != 0  ]] || abort-with-action-Usage
	create-jobs backup "$@"
	if [[ $is_cron ]]
	   then wait			# want to stay in 'ps'
	   else true
	fi
	;;
  #  prune-drives names: prune  names ('all' same as above); see configure.sh
   ( pr*n*dr*v* | pd* ) undo-action-abbrev prune-drives
	[[ $# != 0  ]] || abort-with-action-Usage
	[[ $1 == -f ]] && { final_prune_type=$2; shift 2; } ||final_prune_type=
	[[ $# != 0  ]] || abort-with-action-Usage
	[[ $1 != -r ]] && assert-not-option "$1"
	create-jobs prune "$@"
	[[ ! $is_cron ]] || wait	# so see master cron job in ps
	;;
   # update-drives  [-s src-names-glob] dst-names: copy missing snapshots
   ( upd*dr*v* | ud ) undo-action-abbrev update-drives
	[[ $# != 0  ]] || abort-with-action-Usage
	[[ $1 == -S ]] && {     ignore_slow_sources_opt=$1    ; shift  ; }
	[[ $1 == -s ]] && {          src_names_glob_opt="$1$2"; shift 2; }
	[[ $1 == -e ]] && { excluded_src_names_glob_opt="$1$2"; shift 2; }
	[[ $1 != -r ]] && assert-not-option "$1"
	[[ $# != 0  ]] || abort-with-action-Usage
	opts="${ignore_slow_sources_opt-} ${src_names_glob_opt-}
				 ${excluded_src_names_glob_opt-}"
	# shellcheck disable=SC2086
	create-jobs update $opts "$@"
	# [[ ! $is_cron ]] || wait	# so see master cron job in ps
	;;
   # copy-snapshots [-B] [-q] snapshots name: copy to 'name' mounted drive
   ( c*p*s*s* | cs | cp* ) undo-action-abbrev copy-snapshots # cpss
	[[ $# != 0  ]] || abort-with-action-Usage
	is-arg1-in-arg2 -r "$@" && { create-jobs copy "$@"; exit-normally $?; }

	local opts=
	while [[ ${1-} == -* ]] ; do opts+="$1 "; shift; done
	(( $# >= 2 )) || abort-with-action-Usage
	set-drive_name   "${!#}"
	src_snapshots=${*#${!#}}
	src_snapshots=${src_snapshots% }
	# shellcheck disable=SC2086
	create-jobs copy -s${src_snapshots// / -s} $opts $drive_name
	;;

   # rm snapshots: rename snapshots to *.rm, so they'll be pruned (rm -rf)
   ( rm | del* ) undo-action-abbrev rm
	for snapshot
	    do	[[ $snapshot != *.rm ]] || continue
		$IfRun sudo mv -v "$snapshot" "$snapshot.rm"
	done
	;;
   # unrm snapshots: rename *.rm snapshots to *.partial (update-drive restores)
   ( unrm | undel* ) undo-action-abbrev unrm
	for snapshot
	    do	[[ $snapshot == *.rm ]] || warn "$snapshot not *.rm" ||continue
		if  [[ $snapshot == *.partial.rm ]]
		   then $IfRun sudo mv -v "$snapshot" "${snapshot%.rm}"
		   else $IfRun sudo mv -v "$snapshot" "${snapshot%.rm}.partial"
		fi
	done
	;;
   # redo snapshots: rename      snapshots to *.partial (update-drive restores)
   ( redo | undo )
	for snapshot
	    do	[[ $snapshot != *.rm ]] || warn "can't redo *.rm; see unrm" ||
		    continue
		[[ $snapshot == *,[0-2][0-9] ]] || continue
		$IfRun sudo mv -v "$snapshot" "$snapshot.partial"
	done
	;;

   ###########################################################################
   # actions to study existing jobs and drives
   ###########################################################################

   # w: show full details on all jobs and drives
   # watch [-f][-C][-N names] [watch-opts]: dashboard (-f: wide; -C: cron jobs)
   ( watch | wa* | wt* | w ) [[ $action != w ]] && undo-action-abbrev watch
	watch "$@"
	;;

   # big-swapouts: search syslog files for warnings about high swapout rates
   ( big*swapouts | bs | so ) undo-action-abbrev big-swapouts
	find-and-print-big-swapouts
	;;
   # measure-swapout-bandwith swap-dev: measure bandwidth of swap-dev
   ( m*swap*b*w* ) undo-action-abbrev measure-swapout-bandwith
	measure-swapout-MBps "$@"
	;;

   # check-logs: update error cache: run this if dashboard fails with I/O error
   ( check*logs | cl ) undo-action-abbrev check-logs
	check-logs
	;;

   # list-drives [-a]: list mounted backup drives; -a adds drives cron ignores
   # df [-A]: show filesystem details; -A adds non-backup drives
   ( l*s*dr*v* | ld | ll | ls | lw | df )
	case $action in
	    ( lw | df )	[[ ${1-} == -[aA] ]] || set -- -a "$@"
			filesystem-geometry "$@" ;;
	    ( * )	list-drive-dirs     "$@" ;;
	esac
	;;

   ###########################################################################
   # actions to manage existing jobs
   ###########################################################################

   # kill [-signal] job-type-glob  name-glob: job-types are backup, copy, prune
   ( kil* | k ) undo-action-abbrev kill
	[[ ${1-} == -* ]] && { signal=$1; shift; }
	[[ $# == 2 || $1 == m* ]] || abort-with-action-Usage
	$Trace
	# shellcheck disable=SC2086
	kill-job-on-drives ${signal-} "$@"
	;;
   # continue	   job-type-glob  name-glob: as above, but -CONT signal
   ( con* | c ) undo-action-abbrev continue
	[[ $# == 2 ]] || abort-with-action-Usage
	$Trace
	kill-job-on-drives -c "$@"
	;;
   # suspend	   job-type-glob  name-glob: as above, but -STOP signal
   # stop	   job-type-glob  name-glob: as above, but -STOP signal
   ( sus* | st*p | s ) undo-action-abbrev suspend
	[[ $1 == -l ]] && { shift; local do_loop=$true; } || local do_loop=
	[[ $# ==  2 ]] || abort-with-action-Usage
	if [[ $do_loop ]]
	   then $Trace
		while true
		    do	kill-job-on-drives -s "$@"
			set +x
			env sleep 1
		done
	   else $Trace
		kill-job-on-drives -s "$@"
	fi
	;;
   # ps [ps-opts] [type-glob [name-glob]]: show holders of lock(s)
   ( ps )
	ps-locks "$@"
	;;

   # reset-priority [names]: reset job priorities on drives (defaults to all)
   ( r*p* ) undo-action-abbrev reset-priority
	set-drive_names--from-user-args "$@"

	$Trace
	for drive_name in $drive_names
	    do	set-drive_dir- "$drive_name"
		reset-priority "$drive_name"
	done
	;;

   ###########################################################################
   # filesystem maintenance actions
   ###########################################################################

   # update-monitor-drive: configure.sh's drive_response_averaging_window_secs
   ( mon*u* | mu | um* ) undo-action-abbrev update-monitor-drive-config; $Trace
	update-monitor-drive-config
	;;
   # monitor-drives: start run-forever monitor of drive response time
   ( mon* | m ) undo-action-abbrev monitor-drives
	if [[ ${1-} == -r ]]
	   then shift
		$IfRun monitor-drives "$@"
	   else	# shellcheck disable=SC2046
		set -- $(list-drive-dirs -a)
		if [[ $# == 0 ]]
		   then [[ -t 1 ]] &&
			echo "No mounted backup drives, won't start $action"
			exit-normally 1
		fi
		[[ $UID == 0 ]] || abort "run with sudo"
		trap '' HUP
		PATH=/usr/local/bin:$PATH \
		setsid "$our_name_" $debug_opt $trace_opt "$action" -r &
	fi
	;;

   ( predict*prune | pp ) undo-action-abbrev predict-prune
     predict-prune "$@"
	;;

   ( dump*state | dump | tb ) undo-action-abbrev dump-state # dir-sizes gets ds
     dump-state "$@"
	;;

   ( dir*sizes | ds ) undo-action-abbrev dir-sizes
     dir-sizes "$@"
	;;

   ( add*extN*journal | aej ) undo-action-abbrev add-extN-journal
     add-extN-journal "$@"
	;;

   # mkfs [-f] [mkfs-opts] device-or-label [name]: mkfs drive (see comments)
   ( mkfs | mf* ) undo-action-abbrev mkfs
     mkfs-backup-drive "$@"
	;;
   # copy-drive {src_name | src_dev} dst_name [dst_dev]: duplicate backup drive
   ( c*p**dr*v* | cpd ) undo-action-abbrev copy-drive
     copy-backup-drive "$@"
	;;
   # finish-copy-drive: only used internally
   ( f*c*p*dr*v* | f*c*p*d* | fcd ) undo-action-abbrev finish-copy-drive
     finish-copy-backup-drive "$@"
	;;

   # filesystem-geometry [-a|-A|drive-dirs]: show sector, inode, block, etc
   ( f*g* | f*s* | *geo* ) undo-action-abbrev filesystem-geometry
     filesystem-geometry "$@"
	;;

  # snapshot-size dir: size of non-hard-linked files (ie in no other snapshots)
   ( snapshot*size | ss ) undo-action-abbrev snapshot-size
	[[ $# == 1 ]] || abort-with-action-Usage
	dir=$1
	[[ -d $dir ]] || abort "dir '$dir' doesn't exist"
	warn "this could take hours"
	$Trace
	KB=$(sudo find "$dir" -links 1 -printf '%k\n' |
		awk '{ total += $1 } ; END { print total }')
	set-readable_du_size "$KB"
	du_size=$readable_du_size
	echo "$dir contains >= $du_size of files in no other directories"
	;;

   ###########################################################################
   # Actions for regression tests.
   ###########################################################################

   # NOTE: this must appear before copy-snapshots (it has 'cs' as a shortcut)
   # check-snapshot-hard-links names: find snapshots with broken hard links
   ( c*s*h*l* ) undo-action-abbrev check-snapshot-hard-links
	[[ $# != 0  ]] || abort-with-action-Usage
	[[ $1 != -r  ]] && assert-not-option "$1"
	[[ $# != 0   ]] || abort-with-action-Usage
	set-drive_names--from-user-args "$@"

	status=0
	for name in $drive_names
	    do	check-snapshot-hard-links "$name" || status=$?
	done
	exit-normally $status
	;;

   # mk-Z [date [period]]: create mostly-empty snapshot dirs in Z mount-point
   ( mk*[Zz] | mkz ) undo-action-abbrev mk-Z
	[[ $1 == -q ]] && { is_quiet=$true; shift; } || is_quiet=$false
	[[ $1 != -* ]] || abort "unknown option $1"

	# The following designed to work with (custom) configure.sh span of 1,
	#    and are memorialized in action test-prune.
	# Test pruning of hours: snapback mk-Z 12/22/2099 0..23 # 0, 2 seconds
	#    ...  days & months: snapback mk-Z 1/1/2094   0	# 5,14 seconds
	#    ... months & years: snapback mk-Z 1/1/2010   month # 58,8 seconds

	# 1/1/2010 is earliest day, earlier days (e.g. 091231) look like octal
     readonly end_date="1/1/2100"	# keep constant, so can compare
	    start_date=${1:-12/22/2099}	# tests hours with ...
	        period=${2:-0..23}	# sequence of hours, else 'month'

	set-drive_dir Z
	cd_ "$drive_dir"
	[[ $debug_opt ]] ||
	rm -rf ./*

	hours=00 is_months=$false
	case $period in
	    ( 0 ) ;;
	    ( month* ) is_months=$true ;;
	    ( * ) eval "set -- {$period}" ; hours=$* ;;
	esac

	# shellcheck disable=SC2155
	local -i start_secs=$(date -d "$start_date" '+%s')
	# shellcheck disable=SC2155
	local -i   end_secs=$(date -d   "$end_date" '+%s')
	local -i secs=start_secs  secs_per_day=$(( 24*60*60 ))
	let end_secs-=3600		# end at 11 PM on previous day
	while  ((  secs < end_secs ))
	   do	set-day--from-secs $secs
		let secs+=secs_per_day
		[[ $day == *01 || ! $is_months ]] || continue
		[[ $day != 0* ]] || abort "start date must be after 1/1/2010"
		for hour in $hours
		    do	[[ $hour == ? ]] && hour=0$hour
			snapshot=$day,$hour
			[[ -d $snapshot ]] || echo "$snapshot"
		done
	done | xargs -r $IfRun mkdir || abort mkdir

	# setup partial snapshots mid-date, to test pruning
	local -i mid_secs="start_secs+(end_secs-start_secs)/2"
	set-day--from-secs $mid_secs; mid_day=$day
	TraceV 7 start_date mid_day end_date
	for hour in 00 02 04 08 09 12
	    do	for ext in links partial
		    do	snapshot=$mid_day,$hour.$ext
			$IfRun mkdir -p "$snapshot"
		done
	done

	set-day--from-secs "$start_secs"
	snapshot=$day,00
	for subdir in /var/repos/snap.test ~/{tmp,git/pylint}
	    do	bad_dir=$snapshot$subdir/deleteme
		$IfRun mkdir -p "$bad_dir"
		$IfRun touch    "$bad_dir/deleteme.txt"
	done
	[[ $is_quiet ]] ||
	Trace 0 "created excludable-junk in $snapshot"

	# there was something else that needed to be tested??
	for file in
	    do	true
	done

	$IfRun rm -rf .mk-Z
	$IfRun mkdir  .mk-Z	; [[ $debug_opt ]] ||
	cp -al ./*    .mk-Z/
	;;

   # test-prune: use mk-Z to run pruning regression test in the Z pseudo-drive
   ( test*prune | tp ) undo-action-abbrev test-prune
	[[ $# == 0 ]] || abort-with-action-Usage

	[[ $UID != 0 ]] || abort "do not run this as root"

	customize-and-validate-configuration-variables Z

	[[ -x $old_cmd ]] || abort "fix old_cmd= in $config_file"
	[[ -x $tst_cmd ]] || abort "fix tst_cmd= in $config_file"
	echo -e "\nComparing $old_cmd to $tst_cmd"

	set-drive_dir Z

	# see the comment at the top of the mk-Z option, above
	local -A prune_type2mk_Z_args=(
	      [hour]="12/22/2099 0..23"
	 [month-day]="1/1/2094 0"
	[year-month]="1/1/2010 month"
	)

	clone-stashed-mk-Z() {
		local type=$1 stash=.mk-Z.$1
		suspend-tracing
		# shellcheck disable=SC2086
		rm -rf $snapshot_glob* la* && cp -al $stash/* . ||
		   abort "failed to clone $stash"
		restore-tracing
	}

	$Trace
	cd_ "$drive_dir"
	# shellcheck disable=SC2086
	for type in $(echo ${!prune_type2mk_Z_args[*]} | tr ' ' '\n' | sort)
	    do	mk_Z_args=${prune_type2mk_Z_args[$type]}
		header "prune '$type' snapshots, created by: mk-Z $mk_Z_args"
		stash=.mk-Z.$type
		$IfRun rm -rf "$stash".*.ls
		[[ ! -d $stash ]] && {
		# shellcheck disable=SC2086
		$IfRun $our_path mk-Z -q $mk_Z_args &&
		   $IfRun mv .mk-Z "$stash" && $IfRun rm -f "$stash/latest" ||
			abort "couldn't populate $stash"; }
		for cmd in $old_cmd $tst_cmd
		    do	$IfRun clone-stashed-mk-Z "$type"
			# shellcheck disable=SC2086
			$IfRun $cmd $our_opts prune-drive Z |&
			   fgrep -v ' prune-drive Z: pruned '
			[[ $cmd == "$old_cmd" ]] && which=old || which=new
			ls > "$stash.$which.ls"
		done
		# shellcheck disable=SC2086
		set-reversed_words $stash.*.ls; set -- $reversed_words
		# shellcheck disable=SC2086
		diff -d -q "$@" && mv $stash.new.ls $stash.pruned.ls &&
				   rm $stash.old.ls &&
		   echo -e "\nSame results, see $stash*" && continue
		warn "regression, see: diff -u $*"
	done

	clone-stashed-mk-Z hour
	echo -e "\nLeft a lot of unpruned snapshots in Z, for other testing."
	;;

   # regression-test [tests]: check functionality, see $tmp_dir/?? for results
   ( regression-test | rt ) undo-action-abbrev regression-test
	# $Trace
	regression-test "$@"
	;;
   # chroot-backup date,time [command]: chroot to snapshot on fastest drive
   ( chr* | cb ) undo-action-abbrev chroot-backup
	chroot-backup "$@"
	;;

   ###########################################################################
   # actions for snapcrypt to call
   ###########################################################################

   # WARNING: this should only be called by "snapcrypt close"
   # unmount names: for each name (can be 'all'), kill backup & unmount drive
   ( u*mount | u ) undo-action-abbrev unmount # umount
	[[ $# != 0 ]] || abort "pass drive names"
     unmount-drives "$@"
	;;
   # for "snapcrypt close": don't eject if didn't get any backups today
   ( has*new*snapshots | hsn ) undo-action-abbrev has-new-snapshots
	drive=$1
	[[ $drive == *[zZ] ]] && exit-normally 0	# for debugging

	$Trace
	is-drive-mounted "$drive" || exit-normally 0
	suspend-tracing
	# shellcheck disable=SC2086
	set -- $drive/$snapshot_glob	# all the _successful_ snapshots
	restore-tracing
	latest_snapshot=${!#}
	[[ $# != 0 && -d $latest_snapshot ]] ||
	    abort "$drive has no (successful) snapshots"
	latest_date_time=$(basename "$latest_snapshot")
	latest_day=${latest_date_time%,??}
	# let latest_day=latest_day-1		# uncomment to debug
	set-date_time
	day=${date_time%,??}
	[[ $latest_day == "$day" ]] ||
	    abort "$drive has no (successful) backups since $latest_day"
	;;
   # for "snapcrypt close": find drive with max # snapshots since last mounted
   ( max*drive | max*backup* | md | mb ) undo-action-abbrev max-drive
	if [[ $# == 1 ]]
	   then  set-drive_name- "$1" &&
		 set-drive_dir- &&
		echo "$drive_dir" && exit-normally 0
	fi

	# shellcheck disable=SC2086
	set -- ${*:-$(list-drive-dirs)}	# for debugging: | tac
	[[ $# != 0 ]] || abort "no backup drives are mounted"

	local -i secs_per_day=$(( 24*60*60 ))
	$Trace
	max_drive=$1; shift
	while [[ $# != 0 ]]
	    do	new_drive=$1
		for (( secs=$(date '+%s'); 1; secs-=secs_per_day ))
		    do	set-day--from-secs $secs

			set -- "$new_drive/$day",??*
			[[ $# != 0 ]] || break

			set -- "$max_drive/$day",??*
			[[ $# != 0 ]] && continue
			max_drive=$new_drive
			break
		done
		shift
	done
	echo "$max_drive"
	;;
   # for "snapcrypt": echo drive mountpoint
   ( drive )
	[[ $# == 1 ]] || abort "specify a name for a drive"
	 set-drive_name- "$1" || abort "$1 is not a valid backup drive name"
	 set-drive_dir-
	echo "$drive_dir"
	;;

   ( shellcheck | sc ) undo-action-abbrev shellcheck
	have-cmd shellcheck ||
	 abort "https://github.com/koalaman/shellcheck#user-content-installing"
	tmp_cmd="$tmp_dir/$our_name_"
	lib_path=$(which libsnap.sh)
	# make it easier for shellcheck to source our config file
	sed -e "s@^source .config_file @source $config_file @" \
	    -e "s@^source   .lib @source $lib_path @" "$our_path" > "$tmp_cmd"
	# diff -u $our_path $tmp_cmd; false && # uncomment to debug the above
	$IfRun shellcheck "$tmp_cmd"
	rm "$tmp_cmd"
	;;

   # run [-v var-names] func-name [args]: run func-name, echo var-names values;
   ( run | r ) undo-action-abbrev run
	local cmd=$1
	$Trace
	run-function -p "$@" # can pass: -v "var-name(s)" # vars to be echo'ed
	echo status=$?
	set +x
	[[ $cmd =~ ^_?(set|update|(append|prepend)-to)- ]] || exit-normally
	cmd_prefix=${BASH_REMATCH[0]}

	header "variables set by $cmd"
	var_names=${cmd#$cmd_prefix} ; var_names=${var_names%%--*}
	var_names=${var_names//-/ }
	declare -i max_name_width=0
	for var_name in $var_names
	    do	(( max_name_width <= ${#var_name} )) || continue
		   max_name_width=${#var_name}
	done
	for var_name in $var_names
	    do	set-var_value--from-var_name "$var_name"
		# shellcheck disable=SC2154
		printf "%${max_name_width}s=%s\n" "$var_name" "$var_value"
	done
	;;
   ( true )				# used to test for needed options
	true ;;
   ( test | t ) undo-action-abbrev test; $Trace
	# shellcheck disable=SC1090
	source "$our_name_-test.sh" || exit-normally $?
	;;

   ( * )
	warn "'$action' is not a recognized action, run: $our_name_ -h"
	exit-normally 1
	;;
esac
local status=$?

[[ -t 1 ]] && check-lost+found

return $status
}
readonly -f process-action

# ----------------------

process-action "$@"
exit-normally $?
